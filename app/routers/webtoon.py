
from fastapi import APIRouter, Request, HTTPException, UploadFile, File, Form, Body
from typing import List, Dict
from fastapi.templating import Jinja2Templates
from fastapi.responses import HTMLResponse, JSONResponse
import os
import shutil
import json
import base64
import re
import io
import time
import httpx
import urllib.parse
from PIL import Image
import numpy as np
from config import config
import database as db
from services.gemini_service import gemini_service
from services.autopilot_service import autopilot_service
from services.tts_service import tts_service
from pydantic import BaseModel
from typing import List, List as PyList, Optional

import unicodedata
from services.i18n import Translator
from services.auth_service import auth_service

def finalize_scene_analysis(scene: Dict, voice_consistency_map: Dict, eleven_voices: List = None) -> Dict:
    """
    AI ë¶„ì„ ê²°ê³¼ì— ì¼ê´€ì„±ì„ ë¶€ì—¬í•˜ê³ , ìœ ì‹¤ëœ ë°ì´í„°(ì„±ìš°, íš¨ê³¼ìŒ ë“±)ë¥¼ ë³´ì •í•˜ëŠ” ìµœì¢… ë‹¨ê³„.
    """
    analysis = scene.get('analysis', {})
    
    # 1. ìºë¦­í„° ì´ë¦„ ì •ê·œí™” ë° ì„±ìš° ë°°ì •
    raw_char = str(analysis.get('character', 'Unknown')).strip()
    if raw_char.lower() in ["none", "null", "undefined", "", "none "]: raw_char = "Unknown"
    
    # Narrator variants + Defaulting Unknown speech to Narration
    char_lower = raw_char.lower()
    dialogue = str(analysis.get('dialogue', '')).strip()
    
    narrator_keywords = ['narrator', 'narration', 'ë‚´ë ˆì´ì…˜', 'í•´ì„¤', 'unknown', 'none', '', 'undefined']
    if any(char_lower == kw for kw in narrator_keywords):
        if dialogue:
            norm_char = "ë‚´ë ˆì´ì…˜"
        else:
            norm_char = "Unknown"
    else:
        norm_char = raw_char.replace("'", "").replace('"', "")

    # Sync to analysis
    analysis['character'] = norm_char
    
    # 2. Voice ID/Name ë°°ì • (ì¼ê´€ì„± ìœ ì§€ê°€ 1ìˆœìœ„)
    suggested_voice = analysis.get('voice_recommendation') or {}
    final_voice_id = str(suggested_voice.get('id', '')).strip()
    final_voice_name = str(suggested_voice.get('name', '')).strip()
    
    # "None" ë¬¸ìì—´ í•„í„°ë§
    if final_voice_id.lower() in ["none", "null", "", "unknown"]: final_voice_id = None
    if final_voice_name.lower() in ["none", "null", "", "unknown voice"]: final_voice_name = None

    # ì¼ê´€ì„± ë§µ í™•ì¸
    if norm_char != "Unknown" and norm_char in voice_consistency_map:
        existing = voice_consistency_map[norm_char]
        if isinstance(existing, dict):
            final_voice_id = existing.get("id")
            final_voice_name = existing.get("name")
        else:
            final_voice_id = existing # legacy string
    
    # [MODIFIED] ë‚´ë ˆì´ì…˜(Narrator) ì¼ê´€ì„± ê°•ì œ: ë¬´ì¡°ê±´ Brian ì„±ìš° ì‚¬ìš©
    if norm_char == "ë‚´ë ˆì´ì…˜":
        final_voice_id = "nPczCjzI2devNBz1zQrb"
        final_voice_name = "Brian"

    # [NEW] ì‹ ê·œ ìºë¦­í„° ìë™ ì„±ìš° í• ë‹¹ (ë§µì— ì—†ê³  ë‚´ë ˆì´ì…˜ë„ ì•„ë‹Œ ê²½ìš°)
    if not final_voice_id and norm_char != "Unknown":
        # ì„±ë³„ ë° ë‚˜ì´ ê°ì§€ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)
        lower_char = norm_char.lower()
        is_female = any(x in lower_char for x in ['girl', 'woman', 'female', 'ì—„ë§ˆ', 'ê·¸ë…€', 'ì†Œë…€', 'ì—¬ì', 'ëˆ„ë‚˜', 'ì–¸ë‹ˆ', 'lady', 'miss', 'wife', 'rachel', 'bella', 'nicole'])
        
        # ê¸°ë³¸ í’€ (ë°±ì—”ë“œ í•˜ë“œì½”ë”©ëœ ì•ˆì •ì ì¸ ì„±ìš°ë“¤)
        female_pool = ["21m00Tcm4TlvDq8ikWAM", "EXAVITQu4vr4xnSDxMaL", "AZnzlk1XhkbcUvJdpS9D", "z9fAnlkUCjS8Inj9L65X"] # Rachel, Bella, Nicole, Dorothy
        male_pool = ["ErXwobaYiN019PkySvjV", "TxGEqnHWrfWFTfGW9XjX", "bIHbv24qawwzYvFyYv6f", "N2lVS1wzCLPce5hNBy94"] # Antoni, Josh, Adam, Josh (alt)

        # ì‹¤ì œ ElevenLabs ë°ì´í„°ê°€ ìˆìœ¼ë©´ í™œìš©
        if eleven_voices:
            f_list = [v['voice_id'] for v in eleven_voices if v.get('labels', {}).get('gender') == 'female']
            m_list = [v['voice_id'] for v in eleven_voices if v.get('labels', {}).get('gender') == 'male']
            if f_list: female_pool = f_list
            if m_list: male_pool = m_list

        # ê²°ì •ì  í• ë‹¹ (ìºë¦­í„° ì´ë¦„ í•´ì‹œê°’ ì‚¬ìš©)
        import hashlib
        h = int(hashlib.md5(norm_char.encode()).hexdigest(), 16)
        if is_female:
            final_voice_id = female_pool[h % len(female_pool)]
        else:
            final_voice_id = male_pool[h % len(male_pool)]

    # 2.5 voice_consistency_map ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ì”¬ì—ì„œ ë™ì¼ ìºë¦­í„°ê°€ ë‚˜ì˜¤ë©´ ê°™ì€ ì„±ìš° ì‚¬ìš©)
    if norm_char != "Unknown" and final_voice_id:
        voice_consistency_map[norm_char] = {"id": final_voice_id, "name": final_voice_name or "Assigning..."}

    # 3. ë³´ì´ìŠ¤ ì´ë¦„ ìœ ì‹¤ ë³µêµ¬ (ElevenLabs ê¸°ë°˜)
    # final_voice_nameì´ ë¹„ì–´ìˆê±°ë‚˜ "None"ì¸ ê²½ìš° ê°•ì œ ë³µêµ¬
    if not final_voice_name or str(final_voice_name).lower() in ["none", "null", "unknown voice", "unknown", "generic description"]:
        if eleven_voices and final_voice_id and final_voice_id not in ["unknown", "None"]:
            for v in eleven_voices:
                if v.get("voice_id") == final_voice_id:
                    final_voice_name = v.get("name")
                    break
        
        if not final_voice_name or str(final_voice_name).lower() in ["none", "null"]:
            fallback_names = {
                "ErXwobaYiN019PkySvjV": "Antoni (Male)",
                "TxGEqnHWrfWFTfGW9XjX": "Josh (Male)",
                "21m00Tcm4TlvDq8ikWAM": "Rachel (Female)",
                "EXAVITQu4vr4xnSDxMaL": "Bella (Female)",
                "nPczCjzI2devNBz1zQrb": "Brian (Narrator)"
            }
            final_voice_name = fallback_names.get(final_voice_id, "Default Character Voice")

    # Update Scene Root and Analysis
    scene['voice_id'] = final_voice_id or "unknown"
    scene['voice_name'] = str(final_voice_name or "Default Character Voice")
    
    if 'voice_recommendation' not in analysis: analysis['voice_recommendation'] = {}
    analysis['voice_recommendation']['id'] = final_voice_id or "unknown"
    analysis['voice_recommendation']['name'] = str(final_voice_name or "Default Character Voice")

    # [NEW] Final "Nuclear" anti-None check for UI strings
    if str(scene.get('voice_name','')).lower() in ["none", "null", "unknown", "", "undefined"]:
        scene['voice_name'] = "Default Character Voice"
        analysis['voice_recommendation']['name'] = "Default Character Voice"
    
    # Final cleanup for voice_id to avoid "null" in JSON
    if not scene['voice_id'] or str(scene['voice_id']).lower() in ["none", "null"]:
        scene['voice_id'] = "unknown"

    # 4. ì˜¤ë””ì˜¤ ë””ë ‰ì…˜ (íš¨ê³¼ìŒ/ë°°ê²½ìŒ) ìŠ¤ë§ˆíŠ¸ ë³´ì •
    aud = scene.get('audio_direction') or analysis.get('audio_direction') or {}
    sfx_val = str(aud.get('sfx_prompt', '')).strip()
    bgm_val = str(aud.get('bgm_mood', '')).strip()
    atmosphere = str(analysis.get('atmosphere', '')).lower()
    dialogue = str(analysis.get('dialogue', '')).lower()
    visual = str(analysis.get('visual_desc', '')).lower()
    
    # [NEW] ì˜ì–´ ë¬˜ì‚¬(Visual Desc)ë„ í‚¤ì›Œë“œ ê²€ì‚¬ì— í™œìš© (ë” ë„“ì€ ë²”ìœ„ì˜ ê°ì§€)
    combined_desc = f"{dialogue} {visual}"

    # SFX ë³´ì •: 'None' ë¬¸ìì—´ì´ê±°ë‚˜ ë¹„ì–´ìˆì„ ë•Œë§Œ ê²€ì‚¬
    if not sfx_val or sfx_val.lower() in ['none', 'null', '', 'no sound', 'silence']:
        sfx = ""
        # ëª…í™•í•œ ì†Œë¦¬ ìœ ë°œ í‚¤ì›Œë“œê°€ ìˆì„ ë•Œë§Œ ë³´ì¶©
        if any(x in combined_desc for x in ["ì¾…", "í­ë°œ", "bang", "boom", "explosion", "clash", "sword", "impact", "ê²€ìˆ ", "ë¶€ë”ªíˆëŠ”"]): sfx = "Cinematic impact and clashing"
        elif any(x in combined_desc for x in ["ìŠˆ", "woosh", "wind", "í”¼ìœµ", "fly", "motion blur"]): sfx = "Fast whoosh motion"
        elif any(x in combined_desc for x in ["í„°ë²…", "step", "ë°œìêµ­", "walk", "running"]): sfx = "Footsteps"
        elif any(x in combined_desc for x in ["ì›ƒìŒ", "laugh", "chuckle", "smile"]): sfx = "Subtle background laughter"
        
        if sfx:
            aud['sfx_prompt'] = sfx
            aud['has_sfx'] = True
        else:
            # ì‹¤íš¨ì„± ì—†ëŠ” SilenceëŠ” ë¹ˆì¹¸ìœ¼ë¡œ ìœ ì§€í•˜ì—¬ "ì˜ë„ëœ ì¹¨ë¬µ" í—ˆìš©
            aud['sfx_prompt'] = ""
            aud['has_sfx'] = False
    else:
        # ì´ë¯¸ ê°’ì´ ìˆìœ¼ë©´ (AIê°€ ì§ì ‘ ì ì€ ê²½ìš°) ìœ ì§€
        aud['has_sfx'] = True

    # BGM ë³´ì •: ë¶„ìœ„ê¸°ê°€ ì •ë§ ìˆì„ ë•Œë§Œ ì¶”ì²œ
    if not bgm_val or bgm_val.lower() in ['none', 'null', 'silence', '']:
        # ë¬´ì¡°ê±´ Cinematicì„ ë„£ì§€ ì•Šê³ , ì˜ë¯¸ ìˆëŠ” ë¶„ìœ„ê¸°ì¼ ë•Œë§Œ ë°˜ì˜
        meaningful_atm = atmosphere and atmosphere not in ["none", "unknown", "static", "blank", "neutral"]
        if meaningful_atm:
            aud['bgm_mood'] = atmosphere.capitalize()
        # ì‹œê°ì  ë¬˜ì‚¬ì— ê°•í•œ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ì¶”ê°€ ì¶”ì²œ
        elif any(x in visual for x in ["clash", "fight", "war", "battle", "sword"]):
             aud['bgm_mood'] = "Epic Battle"
        else:
            aud['bgm_mood'] = "" # í‰ë²”í•œ ì¥ë©´ì€ ë¹„ì›Œë‘  (ì¹¨ë¬µ í—ˆìš©)

    scene['audio_direction'] = aud
    analysis['audio_direction'] = aud

    # 5. ì„±ìš° ì„¤ì • (í†¤/ì´ìœ ) ìŠ¤ë§ˆíŠ¸ ë³´ì •
    vs = scene.get('voice_settings') or analysis.get('voice_settings') or {}
    if not vs or not vs.get('reason') or str(vs.get('reason')).lower() in ["none", "null", "why this tone?", ""]:
        # [NEW] ë” êµ¬ì²´ì ì¸ ì´ìœ  ìƒì„±
        atm_reason = atmosphere.capitalize() if atmosphere not in ["none", "unknown"] else "natural"
        vs_reason = f"Matching {norm_char}'s {atm_reason} tone in this scene."
        if not vs or not isinstance(vs, dict): vs = {"stability": 0.5, "similarity_boost": 0.75, "speed": 1.0}
        vs['reason'] = vs_reason
    
    scene['voice_settings'] = vs
    analysis['voice_settings'] = vs
    scene['analysis'] = analysis # Ensure synced
    
    # [NEW] Final "Nuclear" anti-None check for UI
    if str(scene.get('voice_name')).lower() in ["none", "null", "unknown", ""]:
        scene['voice_name'] = "Default Character Voice"
        analysis['voice_recommendation']['name'] = "Default Character Voice"

    return scene

router = APIRouter(prefix="/webtoon", tags=["Webtoon Studio"])
templates = Jinja2Templates(directory="templates")

# i18n ë° ì „ì—­ ë³€ìˆ˜ ì„¤ì • (base.html í˜¸í™˜ì„±)
app_lang = os.environ.get("APP_LANG", "ko")
LANG_FILE = "language.pref"
if os.path.exists(LANG_FILE):
    try:
        with open(LANG_FILE, "r") as f:
            saved_lang = f.read().strip()
            if saved_lang in ['ko', 'en', 'vi']:
                app_lang = saved_lang
    except: pass

translator = Translator(app_lang)
templates.env.globals['t'] = translator.t
templates.env.globals['current_lang'] = app_lang
templates.env.globals['membership'] = auth_service.get_membership()
templates.env.globals['is_independent'] = auth_service.is_independent()

@router.get("", response_class=HTMLResponse)
async def webtoon_studio_page(request: Request):
    """ì›¹íˆ° ìŠ¤íŠœë””ì˜¤ ë©”ì¸ í˜ì´ì§€"""
    return templates.TemplateResponse("pages/webtoon_studio.html", {
        "request": request,
        "title": "Webtoon Studio",
        "page": "webtoon-studio"
    })

@router.post("/fetch-url")
async def fetch_webtoon_url(
    project_id: int = Form(...),
    url: str = Form(...)
):
    """ë„¤ì´ë²„ ì›¹íˆ° URLì—ì„œ ì´ë¯¸ì§€ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì €ì¥"""
    try:
        if "comic.naver.com" not in url:
            raise HTTPException(400, "Only Naver Webtoon URLs are supported currently.")

        # 1. í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸°
        async with httpx.AsyncClient() as client:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            }
            res = await client.get(url, headers=headers)
            if res.status_code != 200:
                raise HTTPException(500, f"Failed to fetch page: {res.status_code}")
            
            html = res.text
            
            # 2. ì´ë¯¸ì§€ URL ì¶”ì¶œ (ë„¤ì´ë²„ ì›¹íˆ°ì€ img_tag ë˜ëŠ” script ë‚´ì— ì¡´ì¬)
            # ë³´í†µ <div class="wt_viewer"> ë‚´ì˜ <img> íƒœê·¸ë‚˜ data-srcì— ìˆìŒ
            img_urls = re.findall(r'src="(https://image-comic\.pstatic\.net/webtoon/[^"]+)"', html)
            if not img_urls:
                # data-src íŒ¨í„´ ì‹œë„
                img_urls = re.findall(r'data-src="(https://image-comic\.pstatic\.net/webtoon/[^"]+)"', html)
            
            if not img_urls:
                raise HTTPException(404, "No webtoon images found in the provided URL.")

            # ì¤‘ë³µ ì œê±° ë° ìˆœì„œ ìœ ì§€
            seen = set()
            img_urls = [x for x in img_urls if not (x in seen or seen.add(x))]

            # 3. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ë³‘í•© (Vertical Stitching)
            project_dir = os.path.join(config.OUTPUT_DIR, str(project_id))
            webtoon_dir = os.path.join(project_dir, "webtoon_originals")
            os.makedirs(webtoon_dir, exist_ok=True)
            
            downloaded_images = []
            
            # Naver image servers check Referer
            img_headers = headers.copy()
            img_headers["Referer"] = "https://comic.naver.com/"

            for i, img_url in enumerate(img_urls):
                img_res = await client.get(img_url, headers=img_headers)
                if img_res.status_code == 200:
                    img_data = Image.open(io.BytesIO(img_res.content))
                    downloaded_images.append(img_data)
                
            if not downloaded_images:
                raise HTTPException(500, "Failed to download any images.")

            # 4. ì´ë¯¸ì§€ ì„¸ë¡œë¡œ í•©ì¹˜ê¸°
            total_width = max(img.width for img in downloaded_images)
            total_height = sum(img.height for img in downloaded_images)
            
            merged_img = Image.new('RGB', (total_width, total_height), (255, 255, 255))
            y_offset = 0
            for img in downloaded_images:
                # ê°€ë¹„ í˜¸í™˜ì„ ìœ„í•´ RGB ë³€í™˜
                if img.mode != 'RGB':
                    img = img.convert('RGB')
                merged_img.paste(img, (0, y_offset))
                y_offset += img.height

            # 5. ì €ì¥
            filename = f"webtoon_merged_{int(time.time())}.jpg"
            file_path = os.path.join(webtoon_dir, filename)
            merged_img.save(file_path, "JPEG", quality=90)
            
            return {
                "status": "ok",
                "filename": filename,
                "path": file_path,
                "url": f"/api/media/view?path={file_path}"
            }
            
    except Exception as e:
        print(f"Fetch URL error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(500, str(e))

import urllib.parse

@router.post("/upload")
async def upload_webtoon(
    project_id: int = Form(...),
    file: UploadFile = File(...)
):
    """ì›¹íˆ° ì´ë¯¸ì§€ ì—…ë¡œë“œ (JPG, PNG, WEBP, PSD ì§€ì›)"""
    try:
        # í”„ë¡œì íŠ¸ í´ë” ìƒì„±
        project_dir = os.path.join(config.OUTPUT_DIR, str(project_id))
        webtoon_dir = os.path.join(project_dir, "webtoon_originals")
        os.makedirs(webtoon_dir, exist_ok=True)
        
        original_filename = file.filename
        file_ext = os.path.splitext(original_filename)[1].lower()
        
        # PSD íŒŒì¼ ì²˜ë¦¬
        if file_ext == '.psd':
            from psd_tools import PSDImage
            
            # 1. ì›ë³¸ PSD ì €ì¥
            psd_path = os.path.join(webtoon_dir, original_filename)
            with open(psd_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
            
            # 2. ë¯¸ë¦¬ë³´ê¸° ë° ë¶„ì„ìš© PNG ë³€í™˜
            # PSD ë¡œë“œ
            psd = PSDImage.open(psd_path)
            
            # ë³‘í•©ëœ ì´ë¯¸ì§€ ì¶”ì¶œ (Composite)
            composite_img = psd.composite()
            
            # PNG íŒŒì¼ëª… ìƒì„±
            png_filename = os.path.splitext(original_filename)[0] + ".png"
            png_path = os.path.join(webtoon_dir, png_filename)
            
            # ì €ì¥
            if composite_img:
                composite_img.save(png_path)
            else:
                # í•©ì³ì§„ ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° (ë§¤ìš° ë“œë¬¾), ê°•ì œë¡œ í•©ì¹˜ê¸° ì‹œë„
                composite_img = psd.numpy() # numpy ë°°ì—´ë¡œ ë³€í™˜
                Image.fromarray(composite_img).save(png_path)

            return {
                "status": "ok",
                "filename": png_filename, # ë¶„ì„ ë‹¨ê³„ì—ì„œëŠ” ì´ PNGë¥¼ ì‚¬ìš©í•˜ê²Œ ë¨
                "original_filename": original_filename,
                "path": png_path,
                "url": f"/api/media/view?path={urllib.parse.quote(png_path)}"
            }
            
        else:
            # ì¼ë°˜ ì´ë¯¸ì§€ ì²˜ë¦¬
            file_path = os.path.join(webtoon_dir, original_filename)
            with open(file_path, "wb") as buffer:
                shutil.copyfileobj(file.file, buffer)
                
            return {
                "status": "ok",
                "filename": original_filename,
                "path": file_path,
                "url": f"/api/media/view?path={urllib.parse.quote(file_path)}"
            }
            
    except Exception as e:
        print(f"Upload error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(500, str(e))

@router.post("/analyze")
async def analyze_webtoon(
    project_id: int = Form(...),
    filename: str = Form(...),
    psd_exclude_layer: Optional[str] = Form(None)
):
    """ì›¹íˆ° ì´ë¯¸ì§€ ìŠ¬ë¼ì´ì‹± ë° AI ë¶„ì„ (OCR + Scene Description)"""
    try:
        project_dir = os.path.join(config.OUTPUT_DIR, str(project_id))
        webtoon_path = os.path.join(project_dir, "webtoon_originals", filename)
        sliced_dir = os.path.join(project_dir, "webtoon_sliced")
        
        # [CRITICAL] ì´ì „ ë¶„ì„ ê²°ê³¼ ë¬¼ë¦¬ì ìœ¼ë¡œ ì‚­ì œí•˜ì—¬ ìºì‹œ ë° ì°Œêº¼ê¸° ë°©ì§€
        if os.path.exists(sliced_dir):
            shutil.rmtree(sliced_dir)
        os.makedirs(sliced_dir, exist_ok=True)
        
        if not os.path.exists(webtoon_path):
            raise HTTPException(404, "Webtoon file not found")
            
        def normalize_name(s):
            if not s: return ""
            # NFC/NFKC í†µí•©
            s = unicodedata.normalize('NFKC', str(s))
            # ê³µë°± ë° ì œì–´ë¬¸ì ì œê±°, ì†Œë¬¸ìí™” (í•œê¸€/ì˜ë¬¸/ìˆ«ì/ì¼ë¶€íŠ¹ìˆ˜ë¬¸ì ìœ ì§€)
            s = "".join(c for c in s if not c.isspace() and ord(c) > 31).lower()
            return s

        layer_trace = []
        debug_all_layers = {}

        # 1. Image Slicing (PSD handling for clean images)
        analysis_image_path = webtoon_path
        clean_image_path = None
        ext = os.path.splitext(filename)[1].lower()
        temp_dir = os.path.join(config.MEDIA_DIR, "temp")
        os.makedirs(temp_dir, exist_ok=True)
        
        if ext == '.psd':
            from psd_tools import PSDImage
            import uuid
            
            try:
                # 1. ë¶„ì„ìš© (ì „ì²´ ë ˆì´ì–´)
                psd_ana = PSDImage.open(webtoon_path)
                ana_png = os.path.join(temp_dir, f"ana_{uuid.uuid4().hex}.png")
                comp_ana = psd_ana.composite()
                if not comp_ana: comp_ana = Image.fromarray(psd_ana.numpy())
                comp_ana.save(ana_png)
                analysis_image_path = ana_png
                
                # 2. ì˜ìƒìš© (ì§€ì • ë ˆì´ì–´ ì œì™¸)
                clean_image_path = ana_png # Default
                matched_layers = []
                
                # PSDì¸ ê²½ìš° ëª¨ë“  ë ˆì´ì–´ êµ¬ì¡°ë¥¼ í•­ìƒ ë””ë²„ê·¸ ì •ë³´ì— í¬í•¨
                all_layers_list = [l.name for l in psd_ana.descendants() if l.name][:100]
                debug_all_layers = {
                    "layers": all_layers_list,
                    "matched": [],
                    "keywords": [],
                    "method": "analysis_only"
                }

                if psd_exclude_layer:
                    psd_cln = PSDImage.open(webtoon_path)
                    raw_keywords = [k.strip() for k in re.split(r'[,ï¼Œ\s\n]+', psd_exclude_layer) if k.strip()]
                    keywords = [normalize_name(k) for k in raw_keywords]
                    print(f"ğŸ” [PSD Match] Keywords: {keywords}")
                    
                    found_any = False
                    for layer in psd_cln.descendants():
                        if not layer.name: continue
                        name_norm = normalize_name(layer.name)
                        
                        if any(k in name_norm for k in keywords):
                            if layer.visible: # ì´ë¯¸ êº¼ì§„ ê±´ ë¬´ì‹œ
                                print(f"ğŸ‘‰ [PSD Filter] Hiding: '{layer.name}' (norm: {name_norm})")
                                layer.visible = False
                                layer_trace.append(layer.name)
                                matched_layers.append(layer.name)
                                # í•˜ìœ„ ë ˆì´ì–´ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ê°•ì œ ì€ë‹‰
                                if hasattr(layer, 'descendants'):
                                    for child in layer.descendants():
                                        child.visible = False
                                found_any = True
                    
                    if found_any:
                        cln_png = os.path.join(temp_dir, f"cln_{uuid.uuid4().hex}.png")
                        try:
                            comp_cln = psd_cln.composite()
                        except:
                            comp_cln = None

                        method = "composite"
                        if not comp_cln:
                            method = "manual_merge"
                            print("   [PSD] Main composite failed. Starting Manual Merge Fallback...")
                            # ë°”íƒ•ì„ í°ìƒ‰(solid)ìœ¼ë¡œ ì‹œì‘
                            canvas = Image.new("RGBA", psd_cln.size, (255, 255, 255, 255))
                            for l in psd_cln:
                                if l.visible:
                                    try:
                                        l_img = l.composite()
                                        if l_img:
                                            canvas.alpha_composite(l_img.convert("RGBA"))
                                    except:
                                        pass
                            comp_cln = canvas.convert("RGB")
                        
                        if comp_cln.mode != 'RGB':
                            comp_cln = comp_cln.convert('RGB')
                        comp_cln.save(cln_png)
                        clean_image_path = cln_png
                        debug_all_layers = {
                            "layers": [l.name for l in psd_cln.descendants() if l.name][:100],
                            "matched": matched_layers,
                            "keywords": keywords,
                            "method": method
                        }
                    else:
                        print(f"   [PSD] No layer matched from {keywords}")
                        all_names = [l.name for l in psd_cln.descendants() if l.name][:50]
                        debug_all_layers = {
                            "layers": all_names,
                            "matched": [],
                            "keywords": keywords,
                            "method": "none_matched"
                        }
                
            except Exception as e:
                print(f"PSD PROCESS ERROR: {e}")
                import traceback
                traceback.print_exc()
                clean_image_path = webtoon_path
        else:
            clean_image_path = webtoon_path

        cuts = slice_webtoon(analysis_image_path, sliced_dir, clean_image_path=clean_image_path)
        
        # Temp PNG cleanup
        if ext == '.psd':
            for p in [analysis_image_path, clean_image_path]:
                if p and p.startswith(temp_dir) and os.path.exists(p):
                    try: os.remove(p)
                    except: pass
        
        # [NEW] Prepare Voice Options for AI Recommendation
        voice_options_str = None
        try:
            voices = await tts_service.get_elevenlabs_voices()
            if voices:
                v_list = []
                # Limit to top 40 to avoid token overflow
                for v in voices[:40]:
                    labels = v.get('labels', {})
                    # Simplify labels
                    traits = []
                    if 'gender' in labels: traits.append(labels['gender'])
                    if 'age' in labels: traits.append(labels['age'])
                    if 'accent' in labels: traits.append(labels['accent'])
                    if 'description' in labels: traits.append(labels['description']) # Some use description
                    
                    trait_str = ", ".join(traits) if traits else "General"
                    v_list.append(f"- Name: {v['name']} (ID: {v['voice_id']}) - {trait_str}")
                
                voice_options_str = "\n".join(v_list)
        except Exception as e:
            print(f"âš ï¸ Failed to load voices for recommendation: {str(e)}")

        # [NEW] Pre-fetch context and voices
        eleven_voices = []
        try: eleven_voices = await tts_service.get_elevenlabs_voices()
        except: pass

        voice_consistency_map = {}
        try:
            p_set = db.get_project_settings(project_id) if project_id else {}
            if p_set and p_set.get('voice_mapping_json'):
                raw_map = json.loads(p_set.get('voice_mapping_json'))
                # Normalize format to dict
                for k, v in raw_map.items():
                    if isinstance(v, dict): voice_consistency_map[k] = v
                    else: voice_consistency_map[k] = {"id": v, "name": "Unknown Voice"}
        except: pass

        # 2. AI Analysis for each cut with context passing
        scenes = []
        context = ""
        for i, cut_info in enumerate(cuts):
            video_path = cut_info["video"]
            analysis_path = cut_info["analysis"]
            
            try:
                analysis = await gemini_service.analyze_webtoon_panel(analysis_path, context=context, voice_options=voice_options_str)
                
                # Skip meaningless panels (copyright, blank, etc.)
                is_meaningless = analysis.get('is_meaningless') is True
                dialogue = analysis.get('dialogue', '').strip()
                visual = analysis.get('visual_desc', '').lower()
                
                # Extra safety: check for copyright keywords if dialogue is provided
                copyright_keywords = [
                    "ì €ì‘ê¶Œ", "ë¬´ë‹¨ ì „ì¬", "illegal copy", "all rights reserved", "ë¬´ë‹¨ ë³µì œ", "RK STUDIO",
                    "studio", "webtoon", "episode", "next time", "to be continued", "copyright", "scan", "watermark"
                ]
                
                if "completely dark" in visual or "completely black" in visual or "blank panel" in visual:
                    if not dialogue:
                        is_meaningless = True

                if any(k in dialogue for k in copyright_keywords) and len(dialogue) < 150:
                    is_meaningless = True

                if is_meaningless:
                    print(f"Skipping meaningless panel {i} (Visual: {visual})")
                    continue

                import time
                ts = int(time.time())
                scene = {
                    "scene_number": len(scenes) + 1,
                    "image_path": video_path,
                    "image_url": f"/api/media/view?path={urllib.parse.quote(video_path)}&t={ts}",
                    "analysis": analysis,
                    "focal_point_y": analysis.get("focal_point_y", 0.5)
                }

                # [REF ACTOR] Use centralized helper for consistency & fallbacks
                finalize_scene_analysis(scene, voice_consistency_map, eleven_voices)
                
                # Update map and save to DB for future consistency
                norm_char = scene['analysis']['character']
                if norm_char != "Unknown":
                    voice_consistency_map[norm_char] = {"id": scene['voice_id'], "name": scene['voice_name']}
                    try:
                        db.update_project_setting(project_id, "voice_mapping_json", json.dumps(voice_consistency_map, ensure_ascii=False))
                    except: pass

                # Update context for next panel
                if dialogue:
                    context = f"Last seen: {norm_char} said \"{dialogue[:100]}\"."
                
                scenes.append(scene)

            except Exception as e:
                print(f"Gemini evaluation failed for cut {i}: {e}")
                import time
                ts = int(time.time())
                scenes.append({
                    "scene_number": len(scenes) + 1,
                    "image_path": video_path,
                    "image_url": f"/api/media/view?path={urllib.parse.quote(video_path)}&t={ts}",
                    "analysis": {"dialogue": "", "character": "Unknown", "visual_desc": "Error during analysis", "atmosphere": "Error"}
                })
            
        response_data = {
            "status": "ok",
            "scenes": scenes,
            "layer_debug": {
                "trace": layer_trace,
                "all": debug_all_layers # Removed slice [:100] as it can be a dict
            }
        }
        return response_data
    except Exception as e:
        print(f"Analyze error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(500, str(e))

def slice_webtoon(image_path: str, output_dir: str, min_padding=30, start_idx=1, clean_image_path: str = None):
    """
    ì›¹íˆ° ê¸´ ì´ë¯¸ì§€ë¥¼ ì¹¸ë³„ë¡œ ë¶„í• .
    clean_image_pathê°€ ì œê³µë˜ë©´, image_path(ì›ë³¸)ë¡œ ì ˆë‹¨ì ì„ ì°¾ê³  ë‘ ì´ë¯¸ì§€ ëª¨ë‘ë¥¼ ì˜ë¼ëƒ…ë‹ˆë‹¤.
    """
    try:
        img = Image.open(image_path)
        clean_img = Image.open(clean_image_path) if clean_image_path else None
    except Exception as e:
        print(f"Error opening images: {e}")
        return []

    if img.mode != 'RGB':
        img = img.convert('RGB')
    if clean_img and clean_img.mode != 'RGB':
        clean_img = clean_img.convert('RGB')
        
    img_np = np.array(img.convert('L')) # Grayscale
    h, w = img_np.shape
    
    # [IMPROVED] ì—¬ë°± ê°ì§€ ë¡œì§ ê°œì„ 
    # ë‹¨ìˆœ stdë§Œ ë³´ëŠ” ê²Œ ì•„ë‹ˆë¼, í‰ê·  ë°ê¸°ê°€ ë§¤ìš° ë†’ê±°ë‚˜(í°ìƒ‰) ë§¤ìš° ë‚®ì€(ê²€ì€ìƒ‰) ê²½ìš°ë„ ê³ ë ¤
    row_stds = np.std(img_np, axis=1)
    row_means = np.mean(img_np, axis=1)
    
    # ì—¬ë°± ì¡°ê±´: (í‘œì¤€í¸ì°¨ê°€ ë§¤ìš° ë‚®ìŒ) AND (ë°ê¸°ê°€ ì•„ì£¼ ë°ê±°ë‚˜ ì•„ì£¼ ì–´ë‘ì›€)
    # std < 5 (ì¢€ ë” ì—¬ìœ ìˆê²Œ)
    # mean > 240 (í°ìƒ‰) or mean < 15 (ê²€ì€ìƒ‰)
    is_blank = (row_stds < 5) & ((row_means > 240) | (row_means < 15))
    
    # ì—¬ë°± êµ¬ê°„ íƒì§€
    blank_threshold = 30 # ìµœì†Œ 30í”½ì…€ ì´ìƒì´ì–´ì•¼ ì—¬ë°±ìœ¼ë¡œ ì¸ì •
    blank_runs = []
    run_start = -1
    
    for y in range(h):
        if is_blank[y]:
            if run_start == -1: run_start = y
        else:
            if run_start != -1:
                if y - run_start >= blank_threshold:
                    blank_runs.append((run_start, y))
                run_start = -1
    if run_start != -1 and h - run_start >= blank_threshold:
        blank_runs.append((run_start, h))

    # ì ˆë‹¨ì ì„ ê¸°ì¤€ìœ¼ë¡œ ì¡°ê° ë²”ìœ„ ê²°ì •
    panel_ranges = []
    if not blank_runs:
        # ì—¬ë°±ì´ ì•„ì˜ˆ ì—†ìœ¼ë©´ í†µìœ¼ë¡œ 1ì¥
        panel_ranges = [(0, h)]
    else:
        last_y = 0
        for start, end in blank_runs:
            # ì—¬ë°± ì‹œì‘ì (start)ê¹Œì§€ê°€ í•˜ë‚˜ì˜ ì»·
            # ë‹¨, ì»·ì˜ ë†’ì´ê°€ ìµœì†Œ 50pxì€ ë˜ì–´ì•¼ í•¨
            if start - last_y > 50:
                panel_ranges.append((last_y, start))
            last_y = end # ì—¬ë°± ëì (end)ë¶€í„° ë‹¤ìŒ ì»· ì‹œì‘
            
        # ë§ˆì§€ë§‰ ë‚¨ì€ ë¶€ë¶„ ì²˜ë¦¬
        if h - last_y > 50:
            panel_ranges.append((last_y, h))

    cuts = []
    for i, (p_start, p_end) in enumerate(panel_ranges):
        # ì•½ê°„ì˜ ì—¬ë°± í¬í•¨ (ìœ„ì•„ë˜ 5px) - ë‹¨ ì´ë¯¸ì§€ ë²”ìœ„ ë‚´ì—ì„œ
        p_start = max(0, p_start - 5)
        p_end = min(h, p_end + 5)
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì˜ë¼ë‚´ê¸° (ë¶„ì„ìš©)
        cut_full = img.crop((0, p_start, w, p_end))
        
        # [REFINED] ì •ë°€ í•„í„°ë§ ê°•í™” (ì§œíˆ¬ë¦¬ ì œê±°)
        cut_gray = np.array(cut_full.convert('L'))
        std_val = np.std(cut_gray)
        mean_val = np.mean(cut_gray)
        h_cut, w_cut = float(cut_gray.shape[0]), float(cut_gray.shape[1])
        
        # 1. ë„ˆë¬´ ì‘ì€ ì¡°ê° ì œê±° (ë†’ì´ 100px ë¯¸ë§Œ)
        if h_cut < 100:
            print(f"      - Skipping too small panel (h={h_cut})")
            continue

        # 2. ë‹¨ìƒ‰(ê²€ì€ìƒ‰/í°ìƒ‰) ë°°ê²½ ì œê±°
        # stdê°€ ì ë‹¹íˆ ë‚®ìœ¼ë©´ì„œ(10 ë¯¸ë§Œ), í‰ê·  ë°ê¸°ê°€ ì–‘ê·¹ë‹¨(ì–´ë‘¡ê±°ë‚˜ ë°ìŒ)ì¸ ê²½ìš°
        is_dark_junk = (mean_val < 30) and (std_val < 10)  # ê²€ì€ìƒ‰ ë 
        is_light_junk = (mean_val > 225) and (std_val < 10) # í°ìƒ‰ ì—¬ë°±
        
        # 3. ê±°ì˜ ì™„ë²½í•œ ë‹¨ìƒ‰ (ë…¸ì´ì¦ˆ í¬í•¨)
        is_flat = std_val < 3.0
        
        if is_dark_junk or is_light_junk or is_flat:
            print(f"      - Skipping junk panel (std={std_val:.2f}, mean={mean_val:.2f})")
            continue
            
        current_idx = start_idx + len(cuts)
        
        # íŒŒì¼ ì €ì¥
        analysis_filename = f"scene_{current_idx:03d}_ana.jpg"
        analysis_path = os.path.join(output_dir, analysis_filename)
        cut_full.save(analysis_path, "JPEG", quality=95)
        
        video_path = analysis_path # ê¸°ë³¸ê°’
        
        if clean_img:
            # í´ë¦° ì´ë¯¸ì§€ ì˜ë¼ë‚´ê¸° (ì˜ìƒìš©)
            # ì¢Œí‘œëŠ” ì›ë³¸ê³¼ ë™ì¼í•˜ê²Œ ì‚¬ìš©
            cut_clean = clean_img.crop((0, p_start, w, p_end))
            video_filename = f"scene_{current_idx:03d}.jpg"
            video_path = os.path.join(output_dir, video_filename)
            cut_clean.save(video_path, "JPEG", quality=95)
        
        cuts.append({
            "video": video_path,
            "analysis": analysis_path
        })
                
    if not cuts:
         print("âš ï¸ No cuts found after slicing. Fallback to using the whole image.")
         # ì „ì²´ ì´ë¯¸ì§€ë¥¼ í•˜ë‚˜ë¡œ ì €ì¥í•´ì„œë¼ë„ ë°˜í™˜
         full_ana_path = os.path.join(output_dir, "scene_001_ana.jpg")
         img.save(full_ana_path, "JPEG")
         cuts.append({"video": full_ana_path, "analysis": full_ana_path})
         
    return cuts

class WebtoonScene(BaseModel):
    scene_number: int
    character: str
    dialogue: str
    visual_desc: str
    image_path: str
    voice_id: Optional[str] = None
    atmosphere: Optional[str] = None
    sound_effects: Optional[str] = None
    focal_point_y: Optional[float] = 0.5
    engine_override: Optional[str] = None
    effect_override: Optional[str] = None
    motion_desc: Optional[str] = None
    voice_settings: Optional[dict] = None
    audio_direction: Optional[dict] = None

class ScanRequest(BaseModel):
    path: str

class AnalyzeDirRequest(BaseModel):
    project_id: int
    files: List[str]
    psd_exclude_layer: Optional[str] = None

class WebtoonAutomateRequest(BaseModel):
    project_id: int
    scenes: List[WebtoonScene]
    use_lipsync: bool = True
    use_subtitles: bool = True
    character_map: Optional[dict] = None

class WebtoonPlanRequest(BaseModel):
    project_id: int
    scenes: List[dict]

@router.post("/generate-plan")
async def generate_webtoon_plan(req: WebtoonPlanRequest):
    """ì¥ë©´ë³„ ëŒ€ì‚¬/ë¬˜ì‚¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ë””ì˜¤ ì œì‘ ê¸°íšì„œ(ê¸°ìˆ  ì‚¬ì–‘) ìƒì„±"""
    try:
        plan = await gemini_service.generate_webtoon_plan(req.scenes)
        return {"status": "ok", "plan": plan}
    except Exception as e:
        print(f"Plan Gen Error: {e}")
        raise HTTPException(500, str(e))

@router.post("/automate")
async def automate_webtoon(req: WebtoonAutomateRequest):
    """ë¶„ì„ëœ ë°ì´í„°ë¥¼ í”„ë¡œì íŠ¸ ì„¤ì •ì— ì €ì¥í•˜ê³  ëŒ€ê¸°ì—´ë¡œ ì „ì†¡"""
    try:
        project_id = req.project_id
        
        # 1. ìŠ¤í¬ë¦½íŠ¸ ê²°í•© (ë©€í‹°ë³´ì´ìŠ¤ í˜•ì‹ ì¤€ìˆ˜)
        full_script = ""
        for s in req.scenes:
            speaker = s.character if s.character and s.character != "None" else "ë‚˜ë ˆì´ì…˜"
            full_script += f"{speaker}: {s.dialogue}\n\n"
            
        # 2. ì´ë¯¸ì§€ ì—ì…‹ ì¼ê´„ ì´ë™ ë° ë§¤ì¹­ ì„¤ì •
        asset_dir = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "image")
        os.makedirs(asset_dir, exist_ok=True)
        # SFX dir
        sfx_dir = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "sound")
        os.makedirs(sfx_dir, exist_ok=True)
        
        image_prompts = []
        for i, s in enumerate(req.scenes):
            filename = f"scene_{i+1:03d}.jpg"
            dest_path = os.path.join(asset_dir, filename)
            shutil.copy2(s.image_path, dest_path)
            
            # ë§¤ì¹­ ì •ë³´ ì €ì¥ (Project Settings - Legacy)
            db.update_project_setting(project_id, f"scene_{i+1}_image", filename)
            
            # Use overrides if present, else default to zoom_in
            motion = s.effect_override or "zoom_in"
            db.update_project_setting(project_id, f"scene_{i+1}_motion", motion)
            db.update_project_setting(project_id, f"scene_{i+1}_motion_speed", "3.3")
            
            # Engine override per scene (if supported by autopilot_service later)
            if s.engine_override:
                db.update_project_setting(project_id, f"scene_{i+1}_engine", s.engine_override)
            
            # [NEW] Save special motion description for Wan engine
            if s.motion_desc:
                db.update_project_setting(project_id, f"scene_{i+1}_motion_desc", s.motion_desc)
            
            # [NEW] Save Scene Voice
            if s.voice_id and s.voice_id != "None":
                db.update_project_setting(project_id, f"scene_{i+1}_voice", s.voice_id)

            # [NEW] Save Voice Settings (Tone/Speed)
            if s.voice_settings:
                # Ensure it's JSON string for DB storage
                try:
                    vs_json = json.dumps(s.voice_settings)
                    db.update_project_setting(project_id, f"scene_{i+1}_voice_settings", vs_json)
                except:
                    pass


            # --- Auto SFX Generation (ElevenLabs) ---
            if s.sound_effects and s.sound_effects not in ['None', 'Unknown'] and len(s.sound_effects) > 2:
                try:
                    # Clean up text for better prompt
                    sfx_prompt = re.sub(r'[^\w\s,]', '', s.sound_effects)
                    # Generate SFX using ElevenLabs
                    print(f"Generating SFX for scene {i+1}: {sfx_prompt}")
                    sfx_data = await tts_service.generate_sound_effect(sfx_prompt[:100], duration_seconds=None)
                    
                    if sfx_data:
                        sfx_filename = f"sfx_scene_{i+1:03d}.mp3"
                        sfx_path = os.path.join(sfx_dir, sfx_filename)
                        with open(sfx_path, "wb") as f:
                            f.write(sfx_data)
                        
                        db.update_project_setting(project_id, f"scene_{i+1}_sfx", sfx_filename)
                        print(f"âœ… SFX Saved: {sfx_filename}")
                except Exception as e:
                    print(f"âŒ SFX Generation failed for scene {i+1}: {e}")

            # [í•µì‹¬] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í…Œì´ë¸” ì €ì¥ (AutoPilot í•„ìˆ˜ ë°ì´í„°)
            # [í•µì‹¬] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í…Œì´ë¸” ì €ì¥ (AutoPilot í•„ìˆ˜ ë°ì´í„°)
            image_prompts.append({
                "scene_number": i + 1,
                "scene_text": s.dialogue,
                "prompt_en": f"{s.visual_desc}", 
                "image_url": f"/output/{str(project_id)}/assets/image/{filename}",
                "narrative": s.dialogue,
                "focal_point_y": s.focal_point_y,
                "motion_desc": s.motion_desc # [NEW] Store motion description
            })

            # [NEW] Save motion desc to settings for direct access by Autopilot
            if s.motion_desc:
                db.update_project_setting(project_id, f"scene_{i+1}_motion_desc", s.motion_desc)
            
        # 3. ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í…Œì´ë¸” ì¼ê´„ ì €ì¥
        db.save_image_prompts(project_id, image_prompts)

        # 4. í”„ë¡œì íŠ¸ ì„¤ì • ë° ì˜¤í† íŒŒì¼ëŸ¿ í”Œë˜ê·¸ ì—…ë°ì´íŠ¸
        db.update_project(project_id, status="queued") # ë°”ë¡œ ëŒ€ê¸°ì—´ë¡œ!
        db.update_project_setting(project_id, "script", full_script)
        db.update_project_setting(project_id, "auto_plan", False)
        db.update_project_setting(project_id, "app_mode", "shorts") 
        db.update_project_setting(project_id, "auto_tts", 1)      # TTS ìë™ ìƒì„± í™œì„±í™”
        db.update_project_setting(project_id, "auto_render", 1)   # ë Œë”ë§ ìë™ ì‹œì‘ í™œì„±í™”
        
        # [NEW] ë¦½ì‹±í¬(Akool) ë° ë™ì˜ìƒ(Wan) ì—”ì§„ ì„¤ì •
        if req.use_lipsync:
            db.update_project_setting(project_id, "video_engine", "akool")
            db.update_project_setting(project_id, "all_video", 1) # ëª¨ë“  ì¥ë©´ì„ ë¹„ë””ì˜¤(ë¦½ì‹±í¬)í™”
        else:
            db.update_project_setting(project_id, "video_engine", "wan") # ê¸°ë³¸ ëª¨ì…˜ ì—”ì§„
            db.update_project_setting(project_id, "all_video", 1) # [FIX] ì›¹íˆ° ëª¨ë“œì—ì„œëŠ” ëª¨ë“  ì¥ë©´ì„ ë¹„ë””ì˜¤(Wan/Motion)í™” í•˜ë„ë¡ ê°•ì œ
        
        # 4. ì„¤ì • ì €ì¥ (ë¦½ì‹±í¬ ë° ìë§‰ ì—¬ë¶€)
        db.update_project_setting(project_id, "use_lipsync", req.use_lipsync)
        db.update_project_setting(project_id, "use_subtitles", req.use_subtitles)

        # [NEW] Save Voice Mapping for future consistency
        if req.character_map:
            db.update_project_setting(project_id, "voice_mapping_json", json.dumps(req.character_map, ensure_ascii=False))
        
        # 5. ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ê°€ ê°ì§€í•  ìˆ˜ ìˆë„ë¡ ë³´ì¥
        autopilot_service.add_to_queue(project_id)
        
        return {"status": "ok", "message": "Project added to queue for automation"}
        
    except Exception as e:
        print(f"Automate error: {e}")
        raise HTTPException(500, str(e))

@router.post("/scan")
async def scan_directory(req: ScanRequest):
    """ë¡œì»¬ ë””ë ‰í† ë¦¬ì˜ ì›¹íˆ° íŒŒì¼ ìŠ¤ìº”"""
    if not os.path.exists(req.path):
        return JSONResponse({"status": "error", "error": "Path does not exist"}, status_code=404)
    
    files = []
    try:
        # íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ (1í™”_001, 1í™”_002 ìˆœì„œ ë³´ì¥)
        file_list = sorted(os.listdir(req.path))
        
        for f in file_list:
            full_path = os.path.join(req.path, f)
            if os.path.isfile(full_path):
                ext = os.path.splitext(f)[1].lower()
                if ext in ['.psd', '.png', '.jpg', '.jpeg', '.webp']:
                    files.append({
                        "filename": f,
                        "path": full_path,
                        "size": os.path.getsize(full_path)
                    })
    except Exception as e:
         return JSONResponse({"status": "error", "error": str(e)}, status_code=500)
    
    return {"status": "ok", "files": files}

@router.post("/analyze-dir")
async def analyze_directory(req: AnalyzeDirRequest):
    """ë¡œì»¬ íŒŒì¼ ë¦¬ìŠ¤íŠ¸ë¥¼ ì…ë ¥ë°›ì•„ ì¼ê´„ ë¶„ì„ (Direct Access)"""
    try:
        project_dir = os.path.join(config.OUTPUT_DIR, str(req.project_id))
        sliced_base_dir = os.path.join(project_dir, "webtoon_sliced")
        
        # [CRITICAL] ì¼ê´„ ë¶„ì„ ì‹œì—ë„ ê¸°ì¡´ ìë¥¸ ì´ë¯¸ì§€ í´ë”ë¥¼ ë¹„ì›Œì„œ ìºì‹œ ê¼¬ì„ ë°©ì§€
        if os.path.exists(sliced_base_dir):
            shutil.rmtree(sliced_base_dir)
        os.makedirs(sliced_base_dir, exist_ok=True)
        
        # Temp dir for PSD conversion
        temp_dir = os.path.join(project_dir, "temp_psd_conversion")
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)
        os.makedirs(temp_dir, exist_ok=True)
        
        print(f"ğŸš€ [Webtoon Dir] Start analysis for {len(req.files)} files. Project: {req.project_id}")

        layer_trace = [] # Initialize layer_trace for the entire batch
        debug_all_layers = {} # íŒŒì¼ë³„ ë ˆì´ì–´ ëª©ë¡
        
        def normalize_name(s):
            if not s: return ""
            # NFC/NFKC í†µí•©
            s = unicodedata.normalize('NFKC', str(s))
            # ê³µë°± ë° ì œì–´ë¬¸ì ì œê±°, ì†Œë¬¸ìí™” (í•œê¸€/ì˜ë¬¸/ìˆ«ì/ì¼ë¶€íŠ¹ìˆ˜ë¬¸ì ìœ ì§€)
            s = "".join(c for c in s if not c.isspace() and ord(c) > 31).lower()
            return s
        
        all_scenes = []
        global_scene_counter = 1
        current_context = "" # Initialize context for Gemini
        current_project = db.get_project(req.project_id)
        if current_project and current_project.get("topic"):
            topic = current_project["topic"]
            conn = db.get_db()
            cursor = conn.cursor()
            cursor.execute("SELECT id FROM projects WHERE topic = ? AND id != ? ORDER BY id DESC LIMIT 1", (topic, req.project_id))
            row = cursor.fetchone()
            if row:
                prev_id = row["id"]
                cursor.execute("SELECT full_script FROM scripts WHERE project_id = ?", (prev_id,))
                script_row = cursor.fetchone()
                if script_row and script_row["full_script"]:
                     current_context = script_row["full_script"][-500:] # Last 500 chars (Previous episode context)
            conn.close()
            if current_context:
                print(f"ğŸ“– [Webtoon] Loaded context from previous episode: {len(current_context)} chars")
        
        # [NEW] Prepare Voice Options for AI Recommendation
        voice_options_str = None
        try:
            voices = await tts_service.get_elevenlabs_voices()
            if voices:
                v_list = []
                # Limit to top 40 to avoid token overflow
                for v in voices[:40]:
                    labels = v.get('labels', {})
                    # Simplify labels
                    traits = []
                    if 'gender' in labels: traits.append(labels['gender'])
                    if 'age' in labels: traits.append(labels['age'])
                    if 'accent' in labels: traits.append(labels['accent'])
                    if 'description' in labels: traits.append(labels['description']) # Some use description
                    
                    trait_str = ", ".join(traits) if traits else "General"
                    v_list.append(f"- Name: {v['name']} (ID: {v['voice_id']}) - {trait_str}")
                
                voice_options_str = "\n".join(v_list)
                print(f"ğŸ¤ [Webtoon] Loaded {len(v_list)} voices for recommendation.")
        except Exception as e:
            print(f"âš ï¸ Failed to load voices for recommendation: {e}")

        # [NEW] Load Voice Consistency Map ONCE for the batch
        voice_consistency_map = {}
        try:
            p_set = db.get_project_settings(req.project_id) if req.project_id else {}
            if p_set and p_set.get('voice_mapping_json'):
                start_map = json.loads(p_set.get('voice_mapping_json'))
                # Validate format (id vs dict)
                for k, v in start_map.items():
                    if isinstance(v, dict) and "id" in v:
                        voice_consistency_map[k] = v
                    elif isinstance(v, str):
                        # Convert legacy format (id string) to dict
                        voice_consistency_map[k] = {"id": v, "name": "Unknown Voice"}
        except Exception as e:
            print(f"âš ï¸ Failed to load voice map: {e}")

        for file_path in req.files:
            print(f"  - Processing file: {file_path}")
            if not os.path.exists(file_path):
                print(f"    âš ï¸ File NOT found: {file_path}")
                continue
                
            ext = os.path.splitext(file_path)[1].lower()
            analysis_image_path = file_path
            clean_image_path = None
            
            print(f"    Ext: {ext}")
            if ext == '.psd':
                try:
                    from psd_tools import PSDImage
                    import uuid
                    
                    # 1. Full Image (Analysis)
                    psd_ana = PSDImage.open(file_path)
                    full_png_path = os.path.join(temp_dir, f"ana_{uuid.uuid4().hex}.png")
                    comp_ana = psd_ana.composite()
                    if not comp_ana: comp_ana = Image.fromarray(psd_ana.numpy())
                    comp_ana.save(full_png_path)
                    analysis_image_path = full_png_path
                    
                    # PSDì¸ ê²½ìš° ëª¨ë“  ë ˆì´ì–´ êµ¬ì¡°ë¥¼ í•­ìƒ ë””ë²„ê·¸ ì •ë³´ì— í¬í•¨
                    all_layers_batch = [l.name for l in psd_ana.descendants() if l.name][:50]
                    debug_all_layers[os.path.basename(file_path)] = {
                        "layers": all_layers_batch,
                        "matched": [],
                        "keywords": [],
                        "method": "analysis_only"
                    }

                    # 2. Clean Image (Filtered)
                    clean_image_path = full_png_path # Default
                    if req.psd_exclude_layer:
                        psd_cln = PSDImage.open(file_path) # Fresh open for clean image
                        raw_keywords = [k.strip() for k in re.split(r'[,ï¼Œ\s\n]+', req.psd_exclude_layer) if k.strip()]
                        keywords = [normalize_name(k) for k in raw_keywords]
                        
                        found_any = False
                        keywords_debug = keywords
                        matched_trace = []
                        
                        for layer in psd_cln.descendants():
                            if not layer.name: continue
                            name_norm = normalize_name(layer.name)
                            if any(k in name_norm for k in keywords):
                                if layer.visible:
                                    print(f"ğŸ‘‰ [PSD Dir Filter] Hiding: '{layer.name}' (norm: {name_norm})")
                                    layer.visible = False
                                    layer_trace.append(f"{os.path.basename(file_path)}: {layer.name}") 
                                    matched_trace.append(layer.name)
                                    # í•˜ìœ„ ë ˆì´ì–´ê¹Œì§€ ì¬ê·€ì ìœ¼ë¡œ ê°•ì œ ì€ë‹‰
                                    if hasattr(layer, 'descendants'):
                                        for child in layer.descendants():
                                            child.visible = False
                                    found_any = True
                        
                        if found_any:
                            clean_png_path = os.path.join(temp_dir, f"cln_{uuid.uuid4().hex}.png")
                            try:
                                comp_cln = psd_cln.composite()
                            except:
                                comp_cln = None

                            method = "composite"
                            if not comp_cln:
                                method = "manual_merge"
                                print(f"   [PSD Dir] Main composite failed for {file_path}. Manual Merge started...")
                                # í°ìƒ‰ ë°°ê²½ìœ¼ë¡œ ì‹œì‘ (255 alpha)
                                canvas = Image.new("RGBA", psd_cln.size, (255, 255, 255, 255))
                                for l in psd_cln:
                                    if l.visible:
                                        try:
                                            l_img = l.composite()
                                            if l_img:
                                                canvas.alpha_composite(l_img.convert("RGBA"))
                                        except:
                                            pass
                                comp_cln = canvas.convert("RGB")
                                
                            if comp_cln.mode != 'RGB': comp_cln = comp_cln.convert('RGB')
                            comp_cln.save(clean_png_path)
                            clean_image_path = clean_png_path
                            debug_all_layers[os.path.basename(file_path)] = {
                                "layers": [l.name for l in psd_cln.descendants() if l.name][:50],
                                "matched": matched_trace,
                                "keywords": keywords_debug,
                                "method": method
                            }
                        else:
                            print(f"   [PSD Dir] No layer matched from {keywords} in {file_path}")
                            all_names = [l.name for l in psd_cln.descendants() if l.name][:20]
                            debug_all_layers[os.path.basename(file_path)] = {
                                "layers": all_names,
                                "matched": [],
                                "keywords": keywords,
                                "method": "none_matched"
                            }
                            clean_image_path = full_png_path
                    else:
                         clean_image_path = full_png_path
                        
                except Exception as e:
                    print(f"Failed to process PSD {file_path}: {e}")
                    import traceback
                    traceback.print_exc()
                    continue
            else: # For non-PSD files, analysis and clean image are the same
                clean_image_path = file_path
                debug_all_layers[os.path.basename(file_path)] = {
                    "layers": ["(Not a PSD file - flattened image)"],
                    "matched": [],
                    "keywords": [],
                    "method": "flattened_image"
                }
            
            # --- 2. Slicing ---
            print(f"    âœ‚ï¸ Slicing: {analysis_image_path}")
            cuts = slice_webtoon(analysis_image_path, sliced_base_dir, start_idx=global_scene_counter, clean_image_path=clean_image_path)
            print(f"    âœ… Found {len(cuts)} scenes in this file.")
            
            # [CRITICAL FIX] ê¸€ë¡œë²Œ ì¹´ìš´í„° ì—…ë°ì´íŠ¸ - ì´ ì‘ì—…ì´ ì—†ìœ¼ë©´ ë‹¤ìŒ íŒŒì¼ì´ ì´ì „ íŒŒì¼ì„ ë®ì–´ì”€
            global_scene_counter += len(cuts)
            
            # --- 3. Analysis with dynamic context tracking ---
            for cut_info in cuts:
                v_path = cut_info["video"]
                a_path = cut_info["analysis"]
                
                print(f"    ğŸ” Analyzing scene {len(all_scenes) + 1}...")
                print(f"      - Context length: {len(current_context) if current_context else 0}")
                print(f"      - Voice options available: {'Yes' if voice_options_str else 'NO'}")
                try:
                    # [NEW] Prepare Known Characters context
                    known_chars_str = ""
                    if voice_consistency_map:
                        known_chars_list = []
                        for name, data in voice_consistency_map.items():
                            voice_name = data.get("name", "Unknown Voice")
                            known_chars_list.append(f"- {name} (Voice: {voice_name})")
                        if known_chars_list:
                            known_chars_str = "\n[KNOWN CHARACTERS IN THIS EPISODE]\n" + "\n".join(known_chars_list) + "\nTry to reuse these character names if they appear.\n"
                    
                    final_context = (current_context or "") + known_chars_str

                    # Pass running context to Gemini (Analyze the one WITH text)
                    analysis = await gemini_service.analyze_webtoon_panel(a_path, context=final_context, voice_options=voice_options_str)
                    print(f"DEBUG: Analyzed scene. Keys present: {list(analysis.keys())}")
                    print(f"DEBUG: audio_direction: {analysis.get('audio_direction')}")
                    print(f"DEBUG: voice_recommendation: {analysis.get('voice_recommendation')}")

                    
                    # Skip meaningless panels (copyright, blank, logos, etc.)
                    is_meaningless = analysis.get('is_meaningless') is True
                    dialogue = analysis.get('dialogue', '').strip()
                    visual = analysis.get('visual_desc', '').lower()
                    
                    # Safer keyword filtering
                    copyright_keywords = [
                        "ì €ì‘ê¶Œ", "ë¬´ë‹¨ ì „ì¬", "illegal copy", "all rights reserved", "ë¬´ë‹¨ ë³µì œ", "RK STUDIO", 
                        "studio", "webtoon", "episode", "next time", "to be continued", "copyright", "scan", "watermark"
                    ]
                    
                    # ì¶”ê°€ì ì¸ ì‹œê°ì  íŒë³„ (ì™„ì „ ì–´ë‘ìš´ ë°°ê²½ ë“±)
                    if "completely dark" in visual or "completely black" in visual or "blank panel" in visual:
                        if not dialogue: # ëŒ€ì‚¬ê°€ ì—†ìœ¼ë©´ ì§„ì§œ ì§œíˆ¬ë¦¬
                            is_meaningless = True

                    if any(k in dialogue for k in copyright_keywords) and len(dialogue) < 150:
                        is_meaningless = True
                    
                    if is_meaningless:
                        print(f"Skipping meaningless panel (Visual: {visual})")
                        continue

                    import time
                    ts = int(time.time())
                    all_scenes.append({
                        "scene_number": len(all_scenes) + 1,
                        "image_path": v_path,
                        "image_url": f"/api/media/view?path={urllib.parse.quote(v_path)}&t={ts}",
                        "analysis": analysis,
                        "focal_point_y": analysis.get("focal_point_y", 0.5)
                    })
                    
                    print(f"    âœ… Scene {len(all_scenes)} analysis complete.")

                except Exception as e:
                    print(f"Gemini failed for {a_path}: {e}")
                    import time
                    ts = int(time.time())
                    all_scenes.append({
                        "scene_number": len(all_scenes) + 1,
                        "image_path": v_path,
                        "image_url": f"/api/media/view?path={urllib.parse.quote(v_path)}&t={ts}",
                        "analysis": {"dialogue": "", "character": "Unknown", "visual_desc": "Analysis failed", "atmosphere": "Error"}
                    })
            
            # Clean up temp PNGs
            for p in [analysis_image_path, clean_image_path]:
                if p and p.startswith(temp_dir) and os.path.exists(p):
                    try: os.remove(p)
                    except: pass
        # --- 4. Auto Voice Assignment (ElevenLabs API Integrated) ---
        from services.tts_service import tts_service
        
        # 1. Fetch ElevenLabs Voices
        try:
            eleven_voices = await tts_service.get_elevenlabs_voices()
        except:
            eleven_voices = []
        
        # 2. Categorize Voices
        male_pool = []
        female_pool = []
        default_pool = [] # Mixed
        
        for v in eleven_voices:
            vid = v.get("voice_id")
            labels = v.get("labels", {})
            gender = labels.get("gender", "").lower()
            
            # Add to pools
            default_pool.append(vid)
            if gender == "male": 
                male_pool.append(vid)
            elif gender == "female":
                female_pool.append(vid)
        
        # Fallbacks (Antoni, Rachel, Josh, etc.) if API fails or empty
        # These are standard ElevenLabs pre-made voices
        if not male_pool: male_pool = ["ErXwobaYiN019PkySvjV", "TxGEqnHWrfWFTfGW9XjX"] 
        if not female_pool: female_pool = ["21m00Tcm4TlvDq8ikWAM", "EXAVITQu4vr4xnSDxMaL"]
        if not default_pool: default_pool = male_pool + female_pool

        if not default_pool: default_pool = male_pool + female_pool

        char_voice_map = {}
        
        # [NEW] Load previous character voices for consistency
        current_project = db.get_project(req.project_id)
        if current_project and current_project.get("topic"):
            topic = current_project["topic"]
            # Find recent project with same topic
            conn = db.get_db()
            cursor = conn.cursor()
            cursor.execute("SELECT id FROM projects WHERE topic = ? AND id != ? ORDER BY id DESC LIMIT 1", (topic, req.project_id))
            row = cursor.fetchone()
            conn.close()
            
            if row:
                prev_id = row["id"]
                prev_settings = db.get_project_settings(prev_id) or {}
                if prev_settings.get("voice_mapping_json"):
                    try:
                        loaded_map = json.loads(prev_settings["voice_mapping_json"])
                        char_voice_map.update(loaded_map)
                        print(f"ğŸ“– [Webtoon] Loaded {len(loaded_map)} character voices from Project {prev_id}")
                    except: pass

        male_idx = 0
        female_idx = 0
        misc_idx = 0
        
        char_normalization = {
            "Narrator": "ë‚´ë ˆì´ì…˜", "narrator": "ë‚´ë ˆì´ì…˜", "Unknown": "Unknown", "None": "Unknown"
        }

        all_scenes_result = [] # Rebuild list to ensure order
        
        # 2. Finalize all scenes using the enriched map
        for sc in all_scenes:
            # [REF ACTOR] Centralized finalization (Character Normalization, Consistency, Fallbacks)
            finalize_scene_analysis(sc, char_voice_map, eleven_voices)
            
            # [NEW] Persist map updates back to DB (important for consistency across project)
            norm_char = sc['analysis'].get('character')
            if norm_char and norm_char != "Unknown":
                char_voice_map[norm_char] = {"id": sc['voice_id'], "name": sc['voice_name']}
                try:
                    db.update_project_setting(req.project_id, "voice_mapping_json", json.dumps(char_voice_map, ensure_ascii=False))
                except: pass

            all_scenes_result.append(sc)

        # Clean up temp dir
        try:
            shutil.rmtree(temp_dir)
        except: pass
            
        return {
            "status": "ok",
            "scenes": all_scenes_result,
            "total_scenes": len(all_scenes_result),
            "filename": "batch_process",
            "character_map": char_voice_map,
            "layer_debug": {
                "trace": layer_trace,
                "all_files": debug_all_layers
            }
        }
    except Exception as e:
        print(f"Analyze Directory Error: {e}")
        import traceback
        traceback.print_exc()
        raise HTTPException(500, str(e))

@router.post("/save-analysis")
async def save_webtoon_analysis(
    project_id: int = Body(...),
    scenes: List[Dict] = Body(...)
):
    """ë¶„ì„ ê²°ê³¼(ì¥ë©´) ì €ì¥"""
    try:
        scenes_json = json.dumps(scenes, ensure_ascii=False)
        db.update_project_setting(project_id, "webtoon_scenes_json", scenes_json)
        return {"status": "ok"}
    except Exception as e:
        return {"status": "error", "message": str(e)}

@router.get("/get-analysis/{project_id}")
async def get_webtoon_analysis(project_id: int):
    """ì €ì¥ëœ ë¶„ì„ ê²°ê³¼(ì¥ë©´) ì¡°íšŒ (ìœ ì‹¤ ë°ì´í„° ë³´ì • í¬í•¨)"""
    try:
        settings = db.get_project_settings(project_id)
        if settings and settings.get("webtoon_scenes_json"):
            scenes = json.loads(settings["webtoon_scenes_json"])
            
            # [HEAL] ë³´ì´ìŠ¤ ì¼ê´€ì„± ë§µ ë¡œë“œ
            char_voice_map = {}
            if settings.get("voice_mapping_json"):
                try: char_voice_map = json.loads(settings["voice_mapping_json"])
                except: pass
            
            # ElevenLabs ë°ì´í„° (ë³´ì •ìš©)
            try: eleven_voices = await tts_service.get_elevenlabs_voices()
            except: eleven_voices = []
            
            # ë¡œë“œëœ ëª¨ë“  ì¥ë©´ì— ëŒ€í•´ ì¼ê´€ì„± ë° ìœ ì‹¤ ë°ì´í„° ë³´ì • ì‹¤í–‰
            for sc in scenes:
                # [REF ACTOR] Centralized finalization (Character Normalization, Consistency, Fallbacks)
                finalize_scene_analysis(sc, char_voice_map, eleven_voices)
                
                # ë§µ ì—…ë°ì´íŠ¸ (ìƒˆë¡œìš´ ìºë¦­í„° ë°œê²¬ ì‹œ ëŒ€ë¹„)
                norm_char = sc['analysis'].get('character')
                if norm_char and norm_char != "Unknown":
                    char_voice_map[norm_char] = {"id": sc['voice_id'], "name": sc['voice_name']}

            return {"status": "ok", "scenes": scenes}
        return {"status": "ok", "scenes": []}
    except Exception as e:
        print(f"Get Analysis Error: {e}")
        return {"status": "error", "message": str(e)}
