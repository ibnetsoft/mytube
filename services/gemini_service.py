"""
Gemini API ì„œë¹„ìŠ¤
- í…ìŠ¤íŠ¸ ìƒì„± (ëŒ€ë³¸, ë¶„ì„ ë“±)
- ì´ë¯¸ì§€ ìƒì„± (Imagen 3)
- ì˜ìƒ ìƒì„± (Veo)
"""
import httpx
from typing import Optional, List
import base64
import os
import json
import re

from config import config
from services.prompts import prompts


class GeminiService:
    def __init__(self):
        self.api_key = config.GEMINI_API_KEY
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"

    async def generate_text(self, prompt: str, temperature: float = 0.7) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        url = f"{self.base_url}/models/gemini-2.0-flash:generateContent?key={self.api_key}"

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": 8192
            }
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(url, json=payload)
            result = response.json()

            if "candidates" in result:
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                raise Exception(f"Gemini API ì˜¤ë¥˜: {result}")

    async def generate_text_from_image(self, prompt: str, image_bytes: bytes, mime_type: str = "image/png") -> str:
        """ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ìƒì„± (Vision)"""
        url = f"{self.base_url}/models/gemini-2.0-flash:generateContent?key={self.api_key}"

        encoded_image = base64.b64encode(image_bytes).decode("utf-8")

        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": encoded_image
                        }
                    }
                ]
            }],
            "generationConfig": {
                "temperature": 0.4, # Lower temperature for accurate description
                "maxOutputTokens": 2048
            }
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(url, json=payload)
            result = response.json()

            if "candidates" in result:
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                error_msg = result.get('error', {}).get('message', str(result))
                raise Exception(f"Gemini Vision API ì˜¤ë¥˜: {error_msg}")

    async def generate_image(
        self,
        prompt: str,
        aspect_ratio: str = "16:9",
        num_images: int = 1
    ) -> List[bytes]:
        """ì´ë¯¸ì§€ ìƒì„± (Imagen 3 ìš°ì„ , ì‹¤íŒ¨ ì‹œ Imagen 2ë¡œ í´ë°±)"""
        
        # Only use verified working models (confirmed by test_imagen.py)
        models = [
            "imagen-4.0-generate-001",      # Imagen 4 (Verified Working)
            "imagen-4.0-fast-generate-001", # Imagen 4 Fast (Available in API)
        ]
        
        last_error = None
        
        for model_name in models:
            try:
                url = f"{self.base_url}/models/{model_name}:predict?key={self.api_key}"
                print(f"ğŸ¨ [Imagen] Trying model: {model_name}")
                
                payload = {
                    "instances": [{"prompt": prompt}],
                    "parameters": {
                        "sampleCount": num_images,
                        "aspectRatio": aspect_ratio,
                        "safetySetting": "block_low_and_above"
                    }
                }
                
                async with httpx.AsyncClient(timeout=120.0) as client:
                    response = await client.post(url, json=payload)
                    
                    # 404 ì—ëŸ¬ë©´ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                    if response.status_code == 404:
                        print(f"âš ï¸ [Imagen] Model {model_name} not found (404), trying next...")
                        last_error = f"Model {model_name} not found"
                        continue
                    
                    # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì‹¤íŒ¨
                    if response.status_code != 200:
                        error_info = response.text
                        print(f"âŒ [Imagen] Error ({response.status_code}): {error_info}")
                        raise Exception(f"API Error ({response.status_code}): {error_info}")
                    
                    result = response.json()
                    print(f"ğŸ” [Imagen] Response from {model_name}:")
                    print(f"   Keys: {list(result.keys())}")
                    
                    images = []
                    if "predictions" in result:
                        print(f"   Predictions count: {len(result['predictions'])}")
                        for idx, pred in enumerate(result["predictions"]):
                            print(f"   Prediction {idx} keys: {list(pred.keys())}")
                            if "bytesBase64Encoded" in pred:
                                img_bytes = base64.b64decode(pred["bytesBase64Encoded"])
                                images.append(img_bytes)
                                print(f"   âœ… Decoded image {idx}, size: {len(img_bytes)} bytes")
                            # Add check for other formats if needed
                            elif "mimeType" in pred and "bytesBase64Encoded" in pred: # Some versions
                                 img_bytes = base64.b64decode(pred["bytesBase64Encoded"])
                                 images.append(img_bytes)
                                 print(f"   âœ… Decoded image {idx} (alt format), size: {len(img_bytes)} bytes")
                            else:
                                print(f"âš ï¸ [Imagen] Unknown prediction format: {pred.keys()}")
                                print(f"   Full prediction content: {pred}")
                                # Check if there's a safety/filter reason
                                if "error" in pred:
                                    print(f"   âŒ Error in prediction: {pred['error']}")
                                if "safetyRatings" in pred:
                                    print(f"   ğŸš« Safety ratings: {pred['safetyRatings']}")
                    else:
                        print(f"âš ï¸ [Imagen] No 'predictions' key in response. Keys: {result.keys()}")
                        print(f"   Full response: {str(result)[:500]}")

                    # Check if we got images (MOVED OUTSIDE else block!)
                    if images:
                        print(f"âœ… [Imagen] Successfully generated {len(images)} image(s) with {model_name}")
                        return images
                    
                    # No images generated - try next model or fail
                    error_msg = result.get('error', {}).get('message', 'No image data in response')
                    print(f"âš ï¸ [Imagen] No images from {model_name}: {error_msg}")
                    last_error = f"No images: {error_msg}"
                    continue
                    
            except httpx.TimeoutException:
                print(f"â±ï¸ [Imagen] Timeout with {model_name}, trying next...")
                last_error = f"Timeout with {model_name}"
                continue
            except Exception as e:
                # 404ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì‹¤íŒ¨
                if "404" not in str(e):
                    raise
                print(f"âš ï¸ [Imagen] Error with {model_name}: {e}, trying next...")
                last_error = str(e)
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹œë„ ì‹¤íŒ¨
        raise Exception(f"All Imagen models failed. Last error: {last_error}")


    async def generate_video(
        self,
        prompt: str,
        image_path: Optional[str] = None,
        duration_seconds: int = 6, 
        aspect_ratio: str = "16:9"
    ) -> Optional[bytes]:
        """ì˜ìƒ ìƒì„± (Veo) - Text-to-Video or Image-to-Video"""
        model_name = "veo-3.0-fast-generate-001"
        url = f"{self.base_url}/models/{model_name}:predict?key={self.api_key}"
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë³´ê°•
        enhanced_prompt = f"{prompt}, cinematic movement, 4k, fluid motion"

        instance_data = {"prompt": enhanced_prompt}

        # ì´ë¯¸ì§€ ì…ë ¥ì´ ìˆëŠ” ê²½ìš° (Image-to-Video)
        if image_path and os.path.exists(image_path):
            try:
                with open(image_path, "rb") as f:
                    img_bytes = f.read()
                    encoded_img = base64.b64encode(img_bytes).decode("utf-8")
                    instance_data["image"] = {"bytesBase64Encoded": encoded_img}
            except Exception as e:
                print(f"Image read error: {e}")

        payload = {
            "instances": [instance_data],
            "parameters": {
                "sampleCount": 1,
                "aspectRatio": aspect_ratio  # [NEW] Pass Aspect Ratio
            }
        }

        async with httpx.AsyncClient(timeout=300.0) as client:
            try:
                response = await client.post(url, json=payload)
                
                if response.status_code != 200:
                    print(f"Video Gen Error ({response.status_code}): {response.text}")
                    return None
                    
                result = response.json()

                if "predictions" in result:
                    pred = result["predictions"][0]
                    # ì‘ë‹µ í¬ë§· ì²´í¬
                    if "video" in pred and "bytesBase64Encoded" in pred["video"]:
                         return base64.b64decode(pred["video"]["bytesBase64Encoded"])
                    if "bytesBase64Encoded" in pred:
                        return base64.b64decode(pred["bytesBase64Encoded"])
                        
                print(f"Video Gen Unexpected Response: {result}")
                return None
                
            except Exception as e:
                print(f"Video Gen Exception: {e}")
                return None

    async def analyze_comments(self, comments: List[str], video_title: str, transcript: Optional[str] = None) -> dict:
        """ëŒ“ê¸€ ë° ëŒ€ë³¸ ë¶„ì„"""
        
        script_section = ""
        if transcript:
            # í† í° ì œí•œ ê³ ë ¤í•˜ì—¬ ì•ë¶€ë¶„ 5000ìë§Œ ì‚¬ìš©
            script_preview = transcript[:5000]
            script_section = f"""
[ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ (ì•ë¶€ë¶„ ë°œì·Œ)]
{script_preview}
... (í›„ëµ)
"""

        prompt = prompts.GEMINI_ANALYZE_COMMENTS.format(
            script_indicator=('ê³¼ ìŠ¤í¬ë¦½íŠ¸' if transcript else ''),
            video_title=video_title,
            script_section=script_section,
            comments_text=chr(10).join(comments[:50])
        )

        text = await self.generate_text(prompt, temperature=0.3)

        # JSON íŒŒì‹±
        import json
        import re

        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            return json.loads(json_match.group())
        return {"error": "íŒŒì‹± ì‹¤íŒ¨", "raw": text}

    async def extract_success_strategy(self, analysis_data: dict) -> List[dict]:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ì¼ë°˜í™”ëœ ì„±ê³µ ì „ëµ(Knowledge) ì¶”ì¶œ"""
        analysis_json = json.dumps(analysis_data, ensure_ascii=False)
        
        prompt = prompts.GEMINI_EXTRACT_STRATEGY.format(
            analysis_json=analysis_json
        )

        try:
            text = await self.generate_text(prompt, temperature=0.3)
            json_match = re.search(r'\[[\s\S]*\]', text)
            if json_match:
                return json.loads(json_match.group())
        except Exception as e:
            print(f"[Gemini] Strategy extraction failed: {e}")
            
        return []

    async def generate_script_structure(self, analysis_data: dict, recent_titles: List[str] = None, target_language: str = "ko", style_prompt: str = "", accumulated_knowledge: List[dict] = None) -> dict:
        """ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ë³¸ êµ¬ì¡° ìë™ ìƒì„± (ë‚´ìš©ê³¼ ì „ëµì˜ ë¶„ë¦¬ + ëˆ„ì  ì§€ì‹ í™œìš©)"""
        
        # [NEW] ë¶„ì„ ë°ì´í„° ë¶„ë¦¬ (ë‚´ìš© vs ì „ëµ)
        topic_keyword = analysis_data.get('topic', 'ì£¼ì œ ì—†ìŒ')
        success_strategy = analysis_data.get('success_analysis', {})
        script_style = analysis_data.get('script_style', 'story')

        # [NEW] ìŠ¤íƒ€ì¼ë³„ íŠ¹í™” ì§€ì¹¨ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        specialized_instruction = ""
        if script_style == "story":
            specialized_instruction = f"""
[EXTREMELY IMPORTANT: CREATIVE STORYTELLING]
- **CONTENT DECOUPLING**: You are NOT a summarizer. DO NOT use names (e.g., channel names like 'Dolby', guest names like 'Asra'), specific places, or the exact plot from the benchmarked video.
- **ZERO PLAGIARISM**: If you copy the benchmark video's story, you FAIL.
- **ACTUAL TASK**: Create a 100% ORIGINAL horror story based only on the keyword "{topic_keyword}".
- **HOW TO USE BENCHMARK**: Only look at the *technique*. (e.g., 'The way it built tension at 15s', 'The use of a specific psychological hook') - but use a DIFFERENT scare to do it.
"""
        else:
            specialized_instruction = f"[STYLE: INFORMATIONAL] Focus on '{topic_keyword}'."

        # [NEW] ëˆ„ì  ì§€ì‹ í™œìš© ì§€ì¹¨
        knowledge_instruction = ""
        if accumulated_knowledge:
            knowledge_list = "\n".join([f"- [{k['category']}] {k['pattern']}: {k['insight']}" for k in accumulated_knowledge])
            knowledge_instruction = f"""
### 3. ëˆ„ì ëœ ì„±ê³µ ì „ëµ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ (Success Knowledge DB)
ì•„ë˜ëŠ” ê³¼ê±°ì— ì„±ê³µí–ˆë˜ ë‹¤ë¥¸ ì˜ìƒë“¤ë¡œë¶€í„° ë‹¹ì‹ ì´ ì§ì ‘ ì¶”ì¶œí•˜ì—¬ í•™ìŠµí•œ 'ì„±ê³µ ë¬¸ë²•' ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ë²ˆ ê¸°íšì— ì ê·¹ í™œìš©í•˜ì„¸ìš”:
{knowledge_list}
"""

        # [NEW] ì–¸ì–´/ë¬¸í™”ì  ë§¥ë½ ì„¤ì •
        context_instruction = "Korean context."
        if target_language == "ja": context_instruction = "Japanese context."
        elif target_language == "en": context_instruction = "Global context."
        
        # [NEW] ëª©í‘œ ê¸¸ì´ì— ë”°ë¥¸ ìµœì†Œ ì„¹ì…˜ ìˆ˜ ê³„ì‚°
        duration_seconds = analysis_data.get('duration', 60)
        if isinstance(analysis_data.get('duration_category'), str):
            try:
                duration_seconds = int(re.search(r'\d+', analysis_data['duration_category']).group())
            except: pass
        
        min_sections = 4
        if duration_seconds > 300: min_sections = max(8, duration_seconds // 45)
        if duration_seconds > 1800: min_sections = max(20, duration_seconds // 60)
        if duration_seconds > 3600: min_sections = max(40, duration_seconds // 70)

        history_instruction = ""
        if recent_titles:
            history_list = "\n".join([f"- {t}" for t in recent_titles])
            history_instruction = f"Avoid repeating these topics: {history_list}"

        prompt = prompts.GEMINI_SCRIPT_STRUCTURE.format(
            topic_keyword=topic_keyword,
            user_notes=analysis_data.get('user_notes', 'ì—†ìŒ'),
            specialized_instruction=specialized_instruction,
            duration_seconds=duration_seconds,
            min_sections=min_sections,
            custom_prompt_section=f"[Custom Prompt]: {style_prompt}" if style_prompt else "",
            knowledge_instruction=knowledge_instruction,
            success_strategy_json=json.dumps(success_strategy, ensure_ascii=False),
            target_language_context=context_instruction,
            history_instruction=history_instruction
        )

        text = await self.generate_text(prompt, temperature=0.5)
        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            try:
                return json.loads(json_match.group())
            except:
                pass
        return {"error": "êµ¬ì¡° ìƒì„± ì‹¤íŒ¨", "raw": text}
    async def generate_title_recommendations(self, keyword: str, topic: str = "", language: str = "ko") -> List[str]:
        """ì¶”ì²œ ì œëª© 5ê°œ ìƒì„±"""
        prompt = f"""
        ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì½˜í…ì¸  ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í´ë¦­ë¥ (CTR)ì´ ë†’ì€ ë¡±í¼/ì‡¼ì¸  ìœ íŠœë¸Œ ì œëª© 5ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

        [ì •ë³´]
        - í‚¤ì›Œë“œ: {keyword}
        - ì£¼ì œ/ì„¤ëª…: {topic}
        - ì–¸ì–´: {language}

        [ìš”êµ¬ì‚¬í•­]
        1. 5ê°œì˜ ì œëª©ì„ ìƒì„±í•˜ì„¸ìš”.
        2. ì–´ê·¸ë¡œì„±ë³´ë‹¤ëŠ” í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ê±°ë‚˜, í˜œíƒì„ ëª…í™•íˆ í•˜ê±°ë‚˜, ê°ì •ì„ ìê·¹í•˜ëŠ” ì œëª©ì„ ë§Œë“œì„¸ìš”.
        3. 50ì ì´ë‚´ë¡œ ì§§ê³  ê°•ë ¬í•˜ê²Œ.
        4. ë²ˆí˜¸ ë¶™ì´ì§€ ë§ê³  ì˜¤ì§ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”. ì˜ˆ: ["ì œëª©1", "ì œëª©2", ...]
        """

        try:
            response_text = await self.generate_text(prompt, temperature=0.8)
            cleaned_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
            match = re.search(r'\[.*\]', cleaned_text, re.DOTALL)
            
            if match:
                titles = json.loads(match.group(0))
                return titles[:5]
            else:
                # Fallback
                return [line.strip().lstrip('-').lstrip('1.').strip() for line in cleaned_text.split('\n') if line.strip()][:5]
        except Exception as e:
            print(f"Title Gen Error: {e}")
            return []


    async def generate_trending_keywords(self, language: str = "ko", period: str = "now", age: str = "all") -> list:
        """
        ì–¸ì–´/ê¸°ê°„/ì—°ë ¹ë³„ ì¸ê¸° ìœ íŠœë¸Œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ìƒì„± (Search Volume ì‹œë®¬ë ˆì´ì…˜)
        """
        lang_name = ""
        if language == "ko": lang_name = "South Korea (Korean)"
        elif language == "ja": lang_name = "Japan (Japanese)"
        elif language == "en": lang_name = "USA/International (English)"
        elif language == "es": lang_name = "Spain/Latin America (Spanish)"
        else: lang_name = "South Korea (Korean)"

        # ê¸°ê°„ í…ìŠ¤íŠ¸
        period_text = "REAL-TIME / NOW"
        if period == "week": period_text = "THIS WEEK (Last 7 days)"
        elif period == "month": period_text = "THIS MONTH (Last 30 days)"

        # ì—°ë ¹ í…ìŠ¤íŠ¸
        age_text = "ALL Ages"
        if age == "10s": age_text = "Teenagers (10-19)"
        elif age == "20s": age_text = "Young Adults (20-29)"
        elif age == "30s": age_text = "Adults (30-39)"
        elif age == "40s": age_text = "Middle-aged (40-49)"
        elif age == "50s": age_text = "Seniors (50+)"

        prompt = prompts.GEMINI_TRENDING_KEYWORDS.format(
            lang_name=lang_name,
            period_text=period_text,
            age_text=age_text,
            language=language
        )
        
        try:
            text = await self.generate_text(prompt, temperature=0.9)
            
            import json
            import re
            
            match = re.search(r'\[[\s\S]*\]', text)
            if match:
                json_str = match.group(0)
                return json.loads(json_str)
            else:
                # Fallback data if parse fails
                return []
                
        except Exception as e:
            print(f"Trend keywords generation failed: {e}")
            return []

    async def generate_character_prompts_from_script(self, script: str) -> List[dict]:
        """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë“±ì¥ì¸ë¬¼ ì •ë³´ ë° ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompt = prompts.GEMINI_CHARACTER_PROMPTS.format(script=script[:8000])  # í† í° ì œí•œ ê³ ë ¤
        
        text = await self.generate_text(prompt, temperature=0.5)
        
        # JSON íŒŒì‹±
        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            try:
                data = json.loads(json_match.group())
                return data.get("characters", [])
            except Exception as e:
                print(f"Character prompt JSON parse error: {e}")
                pass
        return []

    async def generate_image_prompts_from_script(self, script: str, duration_seconds: int, style_prompt: str = None) -> List[dict]:
        """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì¥ë©´ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê°€ë³€ í˜ì´ì‹± ì ìš©)"""
        
        # [NEW] ê°€ë³€ í˜ì´ì‹±(Dynamic Pacing) ë¡œì§ - ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ ì •ë°€ ì¡°ì •
        # 0 ~ 2ë¶„ (120s): 8ì´ˆë‹¹ 1ì¥ (15ì¥)
        # 2 ~ 5ë¶„ (180s): 20ì´ˆë‹¹ 1ì¥ (9ì¥)
        # 5 ~ 7ë¶„ (120s): 40ì´ˆë‹¹ 1ì¥ (3ì¥)
        # 7 ~ 10ë¶„ (180s): 60ì´ˆë‹¹ 1ì¥ (3ì¥)
        # 10 ~ 20ë¶„ (600s): 120ì´ˆë‹¹ 1ì¥ (5ì¥)
        # 20ë¶„ ì´í›„: 600ì´ˆë‹¹ 1ì¥
        
        num_scenes = 0
        if duration_seconds <= 120:
            num_scenes = duration_seconds // 8
        elif duration_seconds <= 300:
            num_scenes = 15 + (duration_seconds - 120) // 20
        elif duration_seconds <= 420:
            num_scenes = 15 + 9 + (duration_seconds - 300) // 40
        elif duration_seconds <= 600:
            num_scenes = 15 + 9 + 3 + (duration_seconds - 420) // 60
        elif duration_seconds <= 1200:
            num_scenes = 30 + (duration_seconds - 600) // 120
        else:
            num_scenes = 35 + (duration_seconds - 1200) // 600
        
        num_scenes = max(3, int(num_scenes))
        
        style_instruction = ""
        if style_prompt:
            style_instruction = f"""
[ìŠ¤íƒ€ì¼ ì§€ì¹¨ - ë§¤ìš° ì¤‘ìš”]
ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ì— ë‹¤ìŒ ìŠ¤íƒ€ì¼ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”:
"{style_prompt}"

ëª¨ë“  prompt_enì˜ ì‹œì‘ ë¶€ë¶„ì— ì´ ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œë¥¼ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
ì˜ˆ: "{style_prompt}, ..."
"""

        # [NEW] ì¥ì‹œê°„ ì˜ìƒ í˜ì´ì‹± ì§€ì¹¨ (ì‚¬ìš©ì ìš”ì²­ ì„¸ë¶„í™” ë°˜ì˜)
        limit_instruction = ""
        if duration_seconds > 0: # ì§§ì€ ì˜ìƒë„ ì¼ê´€ëœ ì§€ì¹¨ ì ìš©
            limit_instruction = f"""
[ì¤‘ìš”: ì˜ìƒ í˜ì´ì‹± ì •ì±…]
ì‚¬ìš©ìì˜ ëª°ì…ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì œì‘ íš¨ìœ¨ì„ ë†’ì´ê¸° ìœ„í•´ ë‹¤ìŒ êµ¬ê°„ë³„ í˜ì´ì‹±ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”:
1. **ì´ˆë°˜ 2ë¶„ (0~2ë¶„)**: 8ì´ˆë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ ë§¤ìš° ì—­ë™ì ì¸ ì‹œê° ë³€í™”ë¥¼ ì£¼ì–´ í›„í‚¹í•˜ì„¸ìš”.
2. **ëª°ì… ë‹¨ê³„ (2~5ë¶„)**: 20ì´ˆë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ í•µì‹¬ ì¥ë©´ ìœ„ì£¼ë¡œ ì „í™˜í•˜ì„¸ìš”.
3. **ì•ˆì • ë‹¨ê³„ (5~7ë¶„)**: 40ì´ˆë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ ì „ê°œ ì†ë„ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.
4. **ìœ ì§€ ë‹¨ê³„ (7~10ë¶„)**: 1ë¶„ë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
5. **ê·¸ ì´í›„ (10ë¶„~20ë¶„)**: 2ë¶„ë‹¹ 1ì¥, **(20ë¶„ ì´í›„)**: 10ë¶„ë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ í° íë¦„ë§Œ ì§šì–´ì£¼ì„¸ìš”.
- ìœ„ í˜ì´ì‹±ì— ë§ì¶° ì´ **{num_scenes}ê°œ**ì˜ ì¥ë©´ì„ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ê³¨ê³ ë£¨ ë°°ë¶„í•˜ì—¬ JSONì„ ìƒì„±í•˜ì„¸ìš”.
"""

        prompt = prompts.GEMINI_IMAGE_PROMPTS.format(
            num_scenes=num_scenes,
            script=script,
            style_instruction=style_instruction,
            limit_instruction=limit_instruction,
            style_prefix=style_prompt or 'High quality, photorealistic'
        )

        text = await self.generate_text(prompt, temperature=0.7)

        # JSON íŒŒì‹±
        import json
        import re

        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            try:
                data = json.loads(json_match.group())
                return data.get("scenes", [])
            except:
                pass
                pass
        return []

    async def generate_video_search_keywords(self, script_segment: str, mood_style: str = "cinematic") -> str:
        """
        Stock Video ê²€ìƒ‰ì„ ìœ„í•œ ì˜ì–´ ê²€ìƒ‰ì–´ ìƒì„±
        ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ ëŒ€ì‹  ê²€ìƒ‰ ì—”ì§„(Pexels)ì— ì í•©í•œ ë‹¨ìˆœ í‚¤ì›Œë“œ ì¡°í•© ìƒì„±
        ì˜ˆ: "Snowy winter night loop", "Fireplace burning cozy"
        """
        prompt = f"""
        You are a Stock Video Search Assistant. Convert the following context into a generic, simple English search query for a stock video site (Pexels/Shutterstock).
        
        [Context]
        Script: "{script_segment[:200]}"
        Mood: {mood_style}
        
        [Requirements]
        - Output ONLY the Search Query. No markdown, no quotes.
        - Use 3-5 simple English words.
        - Add 'loop' or 'background' if appropriate for ambient scenes.
        - Example: "Snowy winter night loop", "City rain timelapse", "Calm ocean waves"
        
        Search Query:
        """
        try:
            query = await self.generate_text(prompt, temperature=0.3)
            return query.strip().replace('"', '').replace("Search Query:", "").strip()
        except:
            return "nature calm loop" # Fallback

    async def generate_video(self, prompt: str, model: str = "veo-3.1-generate-preview") -> dict:
        """
        Gemini Veo (veo-3.1-generate-preview)ë¥¼ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ ìƒì„±
        """
        if not self.api_key:
             return {"status": "error", "error": "API Key is missing"}
        
        try:
             # ì„ì‹œ ë™ê¸° í˜¸ì¶œ (ë¹„ë™ê¸° ë˜í¼ í•„ìš” ì‹œ ìˆ˜ì •)
             # google.genai.Client ì‚¬ìš©
             from google import genai
             client = genai.Client(api_key=self.api_key)
             
             print(f"DEBUG: Starting Veo generation for prompt: {prompt}")
             # 1. Generate Video
             # https://ai.google.dev/gemini-api/docs/video
             operation = client.models.generate_videos(
                 model=model,
                 prompt=prompt,
                 config={
                    'number_of_videos': 1,
                    # 'fps': 24, 
                    # 'duration_seconds': 5 # Preview is usually short
                 }
             )
             
             
             # Handle operation - it might be a string (operation name) or an object
             print(f"DEBUG: Operation type: {type(operation)}")
             
             # If operation is a string, we need to poll differently
             if isinstance(operation, str):
                 op_name = operation
                 print(f"DEBUG: Operation is a string (name): {op_name}")
                 
                 # Manual polling using the operation name
                 import time
                 max_attempts = 60  # 5 minutes
                 attempts = 0
                 
                 while attempts < max_attempts:
                     print(f"Polling operation status... (attempt {attempts + 1}/{max_attempts})")
                     time.sleep(5)
                     attempts += 1
                     
                     try:
                         # Try to get operation status
                         # The SDK might have a different method to check status
                         op_status = client.operations.get(op_name)
                         
                         # Check if it's done
                         if hasattr(op_status, 'done') and op_status.done:
                             operation = op_status
                             break
                         elif isinstance(op_status, dict) and op_status.get('done'):
                             operation = op_status
                             break
                     except Exception as e:
                         print(f"Polling error: {e}")
                         # If we can't poll, just wait and hope for the best
                         if attempts >= 30:  # After 2.5 minutes, try to get result anyway
                             try:
                                 operation = client.operations.get(op_name)
                                 break
                             except:
                                 pass
                 
                 if attempts >= max_attempts:
                     return {"status": "error", "error": "Video generation timed out"}
             
             # If operation is an object, use wait() or poll
             elif hasattr(operation, 'wait'):
                 print("DEBUG: Using operation.wait() method")
                 try:
                     operation = operation.wait(timeout=300)
                 except Exception as e:
                     print(f"Wait error: {e}")
                     return {"status": "error", "error": f"Wait failed: {str(e)}"}
             
             # Try using result() method (blocks until complete)
             elif hasattr(operation, 'result'):
                 print("DEBUG: Using operation.result property (checking if complete)")
                 try:
                     # First check if it's a method or property
                     if callable(operation.result):
                         print("DEBUG: result is callable (method)")
                         result_obj = operation.result(timeout=300)
                     else:
                         print("DEBUG: result is a property")
                         # For properties, we need to poll manually
                         import time
                         max_wait = 300  # 5 minutes
                         start_time = time.time()
                         
                         while time.time() - start_time < max_wait:
                             # Try to refresh operation status
                             if hasattr(operation, 'name'):
                                 try:
                                     fresh_op = client.operations.get(operation.name)
                                     operation = fresh_op
                                 except:
                                     pass
                             
                             # Check if done
                             if hasattr(operation, 'done'):
                                 if callable(operation.done):
                                     is_done = operation.done()
                                 else:
                                     is_done = operation.done
                                 
                                 if is_done:
                                     print("DEBUG: Operation completed!")
                                     break
                             
                             print(f"Waiting for completion... ({int(time.time() - start_time)}s elapsed)")
                             time.sleep(5)
                         
                         if time.time() - start_time >= max_wait:
                             return {"status": "error", "error": "Timeout waiting for video generation"}
                         
                         result_obj = operation.result
                     
                     print(f"DEBUG: Got result: {type(result_obj)}")
                 except Exception as e:
                     print(f"Result error: {e}")
                     import traceback
                     traceback.print_exc()
                     return {"status": "error", "error": f"Result failed: {str(e)}"}
             
             
             # Otherwise, try manual polling on the object
             else:
                 print("DEBUG: Manual polling on operation object")
                 import time
                 max_attempts = 60
                 attempts = 0
                 
                 while attempts < max_attempts:
                     if hasattr(operation, 'done') and operation.done:
                         break
                     
                     print(f"Waiting... (attempt {attempts + 1}/{max_attempts})")
                     time.sleep(5)
                     attempts += 1
                 
                 if attempts >= max_attempts:
                     return {"status": "error", "error": "Timeout"}
                  
             if operation.error:
                 print(f"Veo Error: {operation.error}")
                 return {"status": "error", "error": str(operation.error)}
                 
             # 3. Get Result
             # operation.result is likely a property, not a method
             result = operation.result 
             
             if not result:
                  return {"status": "error", "error": "No result returned"}
                  
             # Inspect structure based on new SDK
             if hasattr(result, 'generated_videos'):
                 generated_video = result.generated_videos[0]
                 video_url = generated_video.video.uri
             else:
                 # Fallback/Debug
                 print(f"DEBUG: Result structure: {result}")
                 video_url = getattr(result, 'uri', None)
             
             if not video_url:
                 return {"status": "error", "error": "Video URI not found in result"}
             
             return {
                 "status": "ok", 
                 "video_url": video_url,
                 "metadata": {
                     "model": model,
                     "prompt": prompt
                 }
             }

        except Exception as e:
            print(f"Veo Generation Failed: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "error", "error": str(e)}

    async def match_images_to_subtitles(self, subtitles: List[dict], image_data: List[dict]) -> dict:
        """
        ìë§‰(í…ìŠ¤íŠ¸)ì™€ ì´ë¯¸ì§€(í”„ë¡¬í”„íŠ¸)ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë§¤ì¹­(íƒ€ì´ë°)ì„ ìƒì„±
        output: { "assignments": [ {"image_index": 0, "subtitle_index": 0}, ... ] }
        """
        
        # ë°ì´í„° ê°„ì†Œí™” (í† í° ì ˆì•½)
        subs_simplified = [{"id": i, "text": s['text'], "start": s['start'], "end": s['end']} for i, s in enumerate(subtitles)]
        imgs_simplified = [{"id": i, "prompt": img.get('prompt', 'Unknown Scene')} for i, img in enumerate(image_data)]
        
        prompt = f"""
        You are a Professional Video Editor.
        Your task is to assign the provided Images (described by prompts) to the Subtitles (timeline) to create a cohesive video flow.

        [Inputs]
        1. Subtitles (Timeline):
        {json.dumps(subs_simplified, ensure_ascii=False, indent=1)}

        2. Available Images (Asset Pool):
        {json.dumps(imgs_simplified, ensure_ascii=False, indent=1)}

        [Instructions]
        - Assign EVERY Image to a specific Subtitle index where it should START appearing.
        - Images should be distributed logically based on the narrative context (Semantic Match).
        - If an image matches a specific keyword in a subtitle, place it there.
        - Ensure images are spread out; do not clump them all at the beginning.
        - Return the result as a JSON object with a list of assignments.

        [Output Format]
        {{
            "assignments": [
                {{ "image_id": 0, "subtitle_id": 2 }},
                {{ "image_id": 1, "subtitle_id": 5 }},
                ...
            ]
        }}
        """

        try:
            print(f"[Gemini Sync] Sending {len(subs_simplified)} subs and {len(imgs_simplified)} images to AI...")
            text = await self.generate_text(prompt, temperature=0.1)
            print(f"[Gemini Sync] Response: {text[:200]}...") # Log first 200 chars
            
            # JSON íŒŒì‹±
            import re
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                data = json.loads(json_match.group())
                print(f"[Gemini Sync] Parsed Data: {data}")
                return data
            print("[Gemini Sync] JSON Parse Failed")
            return {"assignments": []}
            
        except Exception as e:
            print(f"Image-Subtitle Match Failed: {e}")
            return {"assignments": []}

    async def analyze_success_and_creation(self, video_info: dict) -> dict:
        """
        ì˜ìƒì˜ ì„±ê³µ ìš”ì¸ì„ ë¶„ì„í•˜ê³  ë²¤ì¹˜ë§ˆí‚¹ ì½˜í…ì¸ ë¥¼ ìƒì„±
        """
        title = video_info.get('title', '')
        channel = video_info.get('channelTitle', '')
        # Stats might be inside 'statistics' dict or direct keys depending on how it's passed
        views = video_info.get('statistics', {}).get('viewCount', video_info.get('viewCount', 0))
        likes = video_info.get('statistics', {}).get('likeCount', video_info.get('likeCount', 0))
        
        # Optional: Top comment if available
        top_comment = video_info.get('top_comment', 'ì •ë³´ ì—†ìŒ')

        prompt = prompts.GEMINI_SUCCESS_ANALYSIS.format(
            title=title,
            channel=channel,
            views=views,
            likes=likes,
            top_comment=top_comment
        )

        try:
            text = await self.generate_text(prompt, temperature=0.7)
            
            import json
            import re
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"error": "JSON Parsing Failed", "raw": text}
        except Exception as e:
            return {"error": str(e)}

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
gemini_service = GeminiService()
