"""
Gemini API ì„œë¹„ìŠ¤
- í…ìŠ¤íŠ¸ ìƒì„± (ëŒ€ë³¸, ë¶„ì„ ë“±)
- ì´ë¯¸ì§€ ìƒì„± (Imagen 3)
- ì˜ìƒ ìƒì„± (Veo)
"""
import httpx
from typing import Optional, List
import base64
import os
import json
import re

from config import config
from services.prompts import prompts


class GeminiService:
    def __init__(self):
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"

    @property
    def api_key(self):
        return config.GEMINI_API_KEY

    async def generate_text(self, prompt: str, temperature: float = 0.7) -> str:
        """í…ìŠ¤íŠ¸ ìƒì„±"""
        url = f"{self.base_url}/models/gemini-2.0-flash:generateContent?key={self.api_key}"

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": temperature,
                "maxOutputTokens": 8192
            }
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(url, json=payload)
            result = response.json()

            if "candidates" in result:
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                raise Exception(f"Gemini API ì˜¤ë¥˜: {result}")

    async def generate_text_from_image(self, prompt: str, image_bytes: bytes, mime_type: str = "image/png") -> str:
        """ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ ìƒì„± (Vision)"""
        url = f"{self.base_url}/models/gemini-2.0-flash:generateContent?key={self.api_key}"

        encoded_image = base64.b64encode(image_bytes).decode("utf-8")

        payload = {
            "contents": [{
                "parts": [
                    {"text": prompt},
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": encoded_image
                        }
                    }
                ]
            }],
            "generationConfig": {
                "temperature": 0.4, # Lower temperature for accurate description
                "maxOutputTokens": 2048
            }
        }

        async with httpx.AsyncClient(timeout=60.0) as client:
            response = await client.post(url, json=payload)
            result = response.json()

            if "candidates" in result:
                return result["candidates"][0]["content"]["parts"][0]["text"]
            else:
                error_msg = result.get('error', {}).get('message', str(result))
                raise Exception(f"Gemini Vision API ì˜¤ë¥˜: {error_msg}")

    async def analyze_webtoon_panel(self, image_path: str, context: Optional[str] = None, voice_options: Optional[str] = None) -> dict:
        """ì›¹íˆ° íŒ¨ë„ í•œ ì¹¸ì„ ë¶„ì„í•˜ì—¬ ëŒ€ì‚¬, ìºë¦­í„°, ì—°ì¶œ ì •ë³´ ì¶”ì¶œ"""
        
        context_inst = ""
        if context:
            context_inst = f"\n{context}\n"

        prompt = f"""
        Analyze this webtoon panel image.
        {context_inst}
        1. Extract all text/dialogue in Korean. 
           **EXCLUDE**: 
           - Legal notices, copyright warnings (e.g., "â€»ë³¸ ì‘í’ˆì€ ì €ì‘ê¶Œ ë²•ì— ì˜í•´...", "ë¶ˆë²• ë³µì œ ê¸ˆì§€"), logo credits, or watermarks.
           - **Onomatopoeia or stylized sound effect text** (e.g., "ì¾…!", "í„¸ì©", "ìŠˆìš°ìš°", "ëœëœ"). These are visual sound effects, NOT dialogue.
           **INCLUDE**: Only actual character speech or narrative text meant to be read aloud.
        2. Identify who is speaking based on the dialogue and visual context. 
           - **CRITICAL**: Check the [KNOWN CHARACTERS] list in the context. If the character matches, YOU MUST USE THE EXACT SAME NAME.
           - Do NOT use generic names like "Man" or "Woman" if they match a known character (e.g. "Hero", "Jin-woo").
           - If the speaker's name is not explicitly shown, infer it from the context.
           - Only use 'Unknown' if absolutely impossible to infer. Do NOT use 'None' if there is dialogue.
        3. Describe the visual action and atmosphere briefly in English.
           - Append specific Camera Movement keywords at the end. (e.g., "[Camera: Zoom in]", "[Camera: Pan left]", "[Camera: Static]")
        4. Suggest appropriate sound effects (SFX) for this scene (e.g., Boom, Rain, Footsteps, Crowd noise).
        5. **focal_point_y**: A normalized value (float 0.0 to 1.0) indicating the vertical center of the most important subject (e.g., character's eyes/face, main object).
           - 0.0 is top, 1.0 is bottom.
           - This will be used to crop tall vertical panels without cutting through heads or waists.
        6. **is_meaningless**: Set to true if this image contains NO story content.

        Return ONLY a JSON object in this format:
        {{
            "dialogue": "extracted speech text here (empty if only SFX/copyright/logo)",
            "character": "speaker name or 'Unknown'",
            "visual_desc": "brief visual description in English",
            "motion_desc": "DETAILED description for AI Video Generation (Wan 2.1). Focus on movement (e.g. 'Hair blowing in wind', 'Fire flickering', 'Tears falling', 'Sword swinging'). ALSO include Camera Movement (e.g. 'Slow Pan Down along the body', 'Reviewing from top to bottom').",
            "atmosphere": "e.g. dramatic, funny, scary",
            "sound_effects": "suggested SFX list (comma separated) or 'None'",
            "focal_point_y": 0.5,
            "is_meaningless": false,
            "voice_recommendation": {{ "id": "voice_id_here", "name": "voice_name_here", "reason": "reason" }},
            "voice_settings": {{ "stability": 0.5, "similarity_boost": 0.75, "speed": 1.0, "reason": "why this tone?" }},
            "audio_direction": {{ "sfx_prompt": "detailed english description for sound generation", "bgm_mood": "e.g. suspense, happy, sad", "has_sfx": true }}
        }}
        """
        


        prompt += """
        [AUDIO DIRECTION GUIDE]
        1. **sfx_prompt**: 
           - MANDATORY if there is a visible sound effect text (e.g. "WOOSH") or clear action.
           - Generate a detailed English prompt for ElevenLabs. 
           - Format: "Footsteps on gravel, slow pace" or "Heavy rain with thunder".
           - Keep it under 100 characters.
        2. **bgm_mood**: Suggest the background music mood for this scene (e.g., "Tense", "Joyful").
        3. **has_sfx**: Set to true if a specific sound effect is required.

        [VOICE RECOMMENDATION GUIDE]
        """
        
        if voice_options:
            prompt += f"""
            - Select the best voice from this list:
            {voice_options}
            """
        else:
            prompt += """
            - Suggest a generic voice type (e.g. "Deep Male", "Soft Female", "Child").
            - Return "id": "unknown", "name": "Generic Description".
            """

        prompt += """
        [CRITICAL RULES]
        - **NEVER** return actual `null` or empty strings for required fields in JSON structure.
        - **sfx_prompt**: Provide a sound description if there is action. If silent, return "Silence".
        - **bgm_mood**: Suggest a mood if the scene has a clear atmosphere. If neutral or static, return "Silence".
        - If unsure, provide a best guess based on the visual context.
        
        RETURN JSON ONLY.
        """
        
        try:
            with open(image_path, "rb") as f:
                img_bytes = f.read()
            
            response_text = await self.generate_text_from_image(prompt, img_bytes, mime_type="image/jpeg")
            print(f"DEBUG: Gemini RAW response for panel: {response_text[:400]}...")

            print(f"DEBUG: Gemini RAW response for panel: {response_text[:300]}...")

            
            # JSON íŒŒì‹±
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            
            result = {}
            if json_match:
                try:
                    result = json.loads(json_match.group(0))
                except json.JSONDecodeError:
                    print(f"JSON Decode Error in Panel Analysis. Raw: {response_text[:100]}...")
                    pass
            
            # [CRITICAL] Ensure mandatory fields exist for UI
            if "audio_direction" not in result:
                result["audio_direction"] = {"sfx_prompt": "", "bgm_mood": "", "has_sfx": False}
            if "voice_recommendation" not in result:
                result["voice_recommendation"] = {}
                
            # Basic fallbacks if completely failed
            if not result.get("visual_desc"):
                 result["visual_desc"] = response_text if not json_match else "Analysis parsing failed"
            
            return result
            
        except Exception as e:
            print(f"Panel analysis failed: {e}")
            # Ensure safe return even on crash
            return {
                "dialogue": "", 
                "character": "None", 
                "visual_desc": f"Error: {str(e)}", 
                "atmosphere": "Error",
                "audio_direction": {"sfx_prompt": "", "bgm_mood": "Error", "has_sfx": False},
                "voice_recommendation": {}
            }

    async def generate_webtoon_plan(self, scenes: List[dict]) -> dict:
        """ë¶„ì„ëœ íŒ¨ë„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¹„ë””ì˜¤ ì œì‘ì„ ìœ„í•œ ê¸°íš/ê¸°ìˆ  ì œì•ˆì„œ ìƒì„±"""
        
        scenes_preview = []
        for s in scenes:
            # Handle both object and dict
            if hasattr(s, 'get'):
                sc = s
            else:
                sc = s.dict() if hasattr(s, 'dict') else vars(s)
            
            # [CRITICAL] Fake Description Injection with VARIETY
            # ì •ë³´ê°€ ì¡±í•  ë•Œ íšì¼ì ì¸ 'Pan Down'ë§Œ ë‚˜ì˜¤ì§€ ì•Šë„ë¡, ê°€ì§œ ë¬˜ì‚¬ë¥¼ ìƒí™©ë³„ë¡œ ë‹¤ë¥´ê²Œ ì£¼ì…í•˜ì—¬
            # Geminiê°€ ë‹¤ì–‘í•œ ì—°ì¶œ(Wan, Zoom, Shake ë“±)ì„ ì œì•ˆí•˜ë„ë¡ ìœ ë„í•¨.
            raw_desc = str(sc.get('visual_desc') or '')
            
            # ì •ë³´ê°€ ì •ë§ ì—†ê±°ë‚˜ ë¶„ì„ ì‹¤íŒ¨ì¸ ê²½ìš°
            if not raw_desc or "Analysis failed" in raw_desc or len(raw_desc) < 5:
                 import random
                 idx = sc.get('idx', 0)
                 
                 # ì”¬ ë²ˆí˜¸ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘ì„± ë¶€ì—¬ (ë‹¨ìˆœ ëœë¤ì€ ì•„ë‹˜)
                 styles = [
                     ("Dynamic Action", "Intense movement, sparks flying, high tension.", "Mysterious"),
                     ("Emotional Close-up", "Character's face showing deep emotion, tears or anger.", "Sad/Angry"),
                     ("Wide Atmosphere", "A vast landscape with weather effects like rain or wind.", "Grand"),
                     ("Shocking Twist", "Sudden impact, screen shaking, dramatic zoom.", "Tense")
                 ]
                 
                 # ì”¬ í˜¸ì— ë”°ë¼ ìŠ¤íƒ€ì¼ ìˆœí™˜
                 style_name, style_desc, style_mood = styles[idx % len(styles)]
                 
                 fake_desc = f"A {style_name} webtoon panel. {style_desc}"
                 d_text = sc.get('dialogue', '')
                 if d_text: fake_desc += f" Characters are saying: '{d_text}'"
                 
                 sc['visual_desc'] = fake_desc
                 sc['atmosphere'] = style_mood

                
            scenes_preview.append({
                "scene_number": sc.get("scene_number"),
                "dialogue": sc.get("dialogue"),
                "visual_desc": sc.get("visual_desc"),
                "character": sc.get("character"),
                "sound_effects": sc.get("sound_effects")
            })
            
        scenes_json = json.dumps(scenes_preview, ensure_ascii=False)
        
        prompt = f"""
        # ROLE: Hollywood Trailer Editor & VFX Supervisor
        You are creating a high-end cinematic video plan based on webtoon scenes.
        Your goal is to transform static images into a dynamic, immersive video experience using advanced AI video generation tools (Wan 2.1).

        [INPUT DATA]
        {scenes_json}

        [CRITICAL INSTRUCTION FOR 'motion_desc']
        The 'motion_desc' field is the DIRECT PROMPT for the AI Video Generator (Wan 2.1).
        It MUST be highly detailed, creative, and written in ENGLISH.
        
        DO NOT use generic terms like "moving", "animated", or "talking".
        Instead, use "cinematic vocabulary" to describe:
        1. **Micro-Motions**: "Subtle eye trembling", "Hair gently swaying in wind", "Fists clenching", "Tears welling up", "Chest heaving with breath".
        2. **Camera Movement**: "Slow dolly zoom", "Handheld camera shake", "Low angle tilt up", "Rapid crash zoom", "Smooth tracking shot".
        3. **Atmosphere & Lighting**: "Dust particles floating in god rays", "Flickering neon lights in background", "Dark ominous shadows stretching", "Sparks flying from fire".
        4. **Action**: "Explosive debris flying", "Sword slashing with motion blur", "Magic energy swirling spirally".

        [SCENE ANALYSIS GUIDELINES]
        - **Contextual Inference**: If the dialogue is angry, add "Camera shaking, intense red lighting, joyful sparks". If sad, "Slow rain falling, gloomy blue filter".
        - **Vertical Images**: IF the image is vertical (portrait), you MUST use 'pan_down' or 'pan_up' to reveal the full content.
        - **Static Dialogue**: IF the scene is just talking, add "Subtle breathing motion, blinking eyes, natural head movement" to keep it alive.
        - **Audio Direction**: Suggest immersive Sound Effects (SFX) and Background Music (BGM) that match the visual intensity. 
          sfx_prompt should include specific sounds (e.g., "Heavy footsteps on metal").
          bgm_mood should describe the tone (e.g., "Tense orchestral").
          **CRITICAL**: For 'sfx_prompt' or 'bgm_mood', NEVER return "None" or "null". If silent, use "Silence".
        - **Voice Recommendations (CONSISTENCY IS LAW)**: 
          - **NEVER** use "Silence" or "None" as a voice_name. 
          - The SAME character MUST use the EXACT SAME voice name in every scene they appear.
          - DO NOT mix voices for the same person (e.g., No switching between Adam and Josh).
          - **NARRATOR (ë‚´ë ˆì´ì…˜)**: ALWAYS use "Brian".

        [OUTPUT FORMAT (JSON ONLY)]
        {{
            "overall_strategy": "Overall direction summary (Korean)",
            "bgm_style": "Recommended BGM style (Korean)",
            "character_plan": [ ... ],
            "scene_plans": [
                {{
                    "scene_number": 1,
                    "engine": "image" | "wan" | "akool",
                    "effect": "zoom_in" | "zoom_out" | "pan_left" | "pan_right" | "tilt_up" | "tilt_down" | "pan_down" | "pan_up" | "static" | "shake",
                    "motion_desc": "HIGHLY DETAILED ENGLISH PROMPT. (e.g., 'Cinematic extreme close-up of eye, pupil dilating, intense fear, camera slowly zooming in, dark moody lighting')",
                    "rationale": "Reason for direction (Korean). Focus on emotional impact.",
                    "sfx_priority": "High" | "Normal",
                    "cropping_advice": "Composition advice (Korean)",
                    "voice_name": "ElevenLabs Voice Name (e.g. Rachel, Adam, Josh, Dorothy, Nicole, Fin)",
                    "audio_direction": {{
                        "sfx_prompt": "Detailed English SFX prompt for ElevenLabs generation (e.g. 'Swords clashing with sparks, metallic ringing')",
                        "bgm_mood": "Mood description for BGM (e.g. 'Epic battle orchestral, fast pace')" 
                    }}
                }}
            ]
        }}
        """
        
        try:
            text = await self.generate_text(prompt, temperature=0.7)
            
            # JSON íŒŒì‹±
            import re
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                try:
                    return json.loads(json_match.group())
                except:
                    pass
            return {{ "overall_strategy": "Plan parsing failed", "raw": text }}
        except Exception as e:
            print(f"Plan Generation Error: {e}")
            return {{ "overall_strategy": f"Error: {str(e)}" }}

    async def generate_image(
        self,
        prompt: str,
        aspect_ratio: str = "16:9",
        num_images: int = 1
    ) -> List[bytes]:
        """ì´ë¯¸ì§€ ìƒì„± (Imagen 3 ìš°ì„ , ì‹¤íŒ¨ ì‹œ Imagen 2ë¡œ í´ë°±)"""
        
        # [MODIFIED] Use a wider range of models for fallback
        models = [
            "imagen-4.0-generate-001",      # Imagen 4 (Confirmed working for this environment)
            "imagen-3.0-generate-001",      # Imagen 3 Standard
            "imagen-3.0-fast-generate-001", # Imagen 3 Fast
            "imagen-4.0-fast-generate-001", # Imagen 4 Fast
        ]
        
        last_error = None
        
        for model_name in models:
            try:
                url = f"{self.base_url}/models/{model_name}:predict?key={self.api_key}"
                print(f"ğŸ¨ [Imagen] Trying model: {model_name}")
                
                # [NEW] Style Reinforcement for Non-Realistic Styles
                # If the prompt contains stylistic markers but avoids realism, reinforce negative prompts
                stylistic_keywords = ["wimpy", "anime", "cartoon", "ghibli", "sketch", "line art", "doodle", "webtoon"]
                is_stylistic = any(kw in prompt.lower() for kw in stylistic_keywords)
                contains_photo = any(kw in prompt.lower() for kw in ["photo", "realistic", "8k", "cinematic"])
                
                final_prompt = prompt
                if is_stylistic and not contains_photo:
                    # Append massive negative reinforcement to force the style and avoid unwanted text
                    final_prompt += ". NO PHOTOREALISM. NO 3D RENDER. NO DEPTH OF FIELD. FLAT 2D STYLE ONLY. ABSOLUTELY NO REALISTIC TEXTURES. NO TEXT. NO WORDS. NO LETTERS. NO ALPHABET."

                payload = {
                    "instances": [{"prompt": final_prompt}],
                    "parameters": {
                        "sampleCount": num_images,
                        "aspectRatio": aspect_ratio,
                        "safetySetting": "block_low_and_above"
                    }
                }
                
                async with httpx.AsyncClient(timeout=120.0) as client:
                    response = await client.post(url, json=payload)
                    
                    # 404 ì—ëŸ¬ë©´ ë‹¤ìŒ ëª¨ë¸ ì‹œë„
                    if response.status_code == 404:
                        print(f"âš ï¸ [Imagen] Model {model_name} not found (404), trying next...")
                        last_error = f"Model {model_name} not found"
                        continue
                    
                    # ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì‹¤íŒ¨
                    if response.status_code != 200:
                        error_info = response.text
                        print(f"âŒ [Imagen] Error ({response.status_code}): {error_info}")
                        raise Exception(f"API Error ({response.status_code}): {error_info}")
                    
                    result = response.json()
                    print(f"ğŸ” [Imagen] Response from {model_name}:")
                    print(f"   Keys: {list(result.keys())}")
                    
                    images = []
                    if "predictions" in result:
                        print(f"   Predictions count: {len(result['predictions'])}")
                        for idx, pred in enumerate(result["predictions"]):
                            print(f"   Prediction {idx} keys: {list(pred.keys())}")
                            if "bytesBase64Encoded" in pred:
                                img_bytes = base64.b64decode(pred["bytesBase64Encoded"])
                                images.append(img_bytes)
                                print(f"   âœ… Decoded image {idx}, size: {len(img_bytes)} bytes")
                            # Add check for other formats if needed
                            elif "mimeType" in pred and "bytesBase64Encoded" in pred: # Some versions
                                 img_bytes = base64.b64decode(pred["bytesBase64Encoded"])
                                 images.append(img_bytes)
                                 print(f"   âœ… Decoded image {idx} (alt format), size: {len(img_bytes)} bytes")
                            else:
                                print(f"âš ï¸ [Imagen] Unknown prediction format: {pred.keys()}")
                                print(f"   Full prediction content: {pred}")
                                # Check if there's a safety/filter reason
                                if "error" in pred:
                                    print(f"   âŒ Error in prediction: {pred['error']}")
                                if "safetyRatings" in pred:
                                    print(f"   ğŸš« Safety ratings: {pred['safetyRatings']}")
                    else:
                        print(f"âš ï¸ [Imagen] No 'predictions' key in response. Keys: {result.keys()}")
                        print(f"   Full response: {str(result)[:500]}")

                    # Check if we got images (MOVED OUTSIDE else block!)
                    if images:
                        print(f"âœ… [Imagen] Successfully generated {len(images)} image(s) with {model_name}")
                        return images
                    
                    # No images generated - try next model or fail
                    error_msg = result.get('error', {}).get('message', 'No image data in response')
                    print(f"âš ï¸ [Imagen] No images from {model_name}: {error_msg}")
                    last_error = f"No images: {error_msg}"
                    continue
                    
            except httpx.TimeoutException:
                print(f"â±ï¸ [Imagen] Timeout with {model_name}, trying next...")
                last_error = f"Timeout with {model_name}"
                continue
            except Exception as e:
                # 404ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ëŠ” ì¦‰ì‹œ ì‹¤íŒ¨
                if "404" not in str(e):
                    raise
                print(f"âš ï¸ [Imagen] Error with {model_name}: {e}, trying next...")
                last_error = str(e)
                continue
        
        # ëª¨ë“  ëª¨ë¸ ì‹œë„ ì‹¤íŒ¨
        if "No images" in str(last_error) or "Safety" in str(last_error):
             raise Exception(f"ì´ë¯¸ì§€ ìƒì„±ê¸°(Imagen) ë³´ì•ˆ í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ ëª…ì¸ ì´ë¦„, ë¸Œëœë“œëª…, ë˜ëŠ” ë¶€ì ì ˆí•œ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. (Last error: {last_error})")
        raise Exception(f"ëª¨ë“  ì´ë¯¸ì§€ ìƒì„± ëª¨ë¸ ì‹œë„ ì‹¤íŒ¨. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”. (Last error: {last_error})")


    async def generate_video(
        self,
        prompt: str,
        image_path: Optional[str] = None,
        duration_seconds: int = 6, 
        aspect_ratio: str = "16:9"
    ) -> Optional[bytes]:
        """ì˜ìƒ ìƒì„± (Veo) - Text-to-Video or Image-to-Video"""
        model_name = "veo-3.0-fast-generate-001"
        url = f"{self.base_url}/models/{model_name}:predict?key={self.api_key}"
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë³´ê°•
        enhanced_prompt = f"{prompt}, cinematic movement, 4k, fluid motion"

        instance_data = {"prompt": enhanced_prompt}

        # ì´ë¯¸ì§€ ì…ë ¥ì´ ìˆëŠ” ê²½ìš° (Image-to-Video)
        if image_path and os.path.exists(image_path):
            try:
                with open(image_path, "rb") as f:
                    img_bytes = f.read()
                    encoded_img = base64.b64encode(img_bytes).decode("utf-8")
                    instance_data["image"] = {"bytesBase64Encoded": encoded_img}
            except Exception as e:
                print(f"Image read error: {e}")

        payload = {
            "instances": [instance_data],
            "parameters": {
                "sampleCount": 1,
                "aspectRatio": aspect_ratio  # [NEW] Pass Aspect Ratio
            }
        }

        async with httpx.AsyncClient(timeout=300.0) as client:
            try:
                response = await client.post(url, json=payload)
                
                if response.status_code != 200:
                    print(f"Video Gen Error ({response.status_code}): {response.text}")
                    return None
                    
                result = response.json()

                if "predictions" in result:
                    pred = result["predictions"][0]
                    # ì‘ë‹µ í¬ë§· ì²´í¬
                    if "video" in pred and "bytesBase64Encoded" in pred["video"]:
                         return base64.b64decode(pred["video"]["bytesBase64Encoded"])
                    if "bytesBase64Encoded" in pred:
                        return base64.b64decode(pred["bytesBase64Encoded"])
                        
                print(f"Video Gen Unexpected Response: {result}")
                return None
                
            except Exception as e:
                print(f"Video Gen Exception: {e}")
                return None

    async def analyze_comments(self, comments: List[str], video_title: str, transcript: Optional[str] = None) -> dict:
        """ëŒ“ê¸€ ë° ëŒ€ë³¸ ë¶„ì„"""
        
        script_section = ""
        if transcript:
            # í† í° ì œí•œ ê³ ë ¤í•˜ì—¬ ì•ë¶€ë¶„ 5000ìë§Œ ì‚¬ìš©
            script_preview = transcript[:5000]
            script_section = f"""
[ì˜ìƒ ìŠ¤í¬ë¦½íŠ¸ (ì•ë¶€ë¶„ ë°œì·Œ)]
{script_preview}
... (í›„ëµ)
"""

        prompt = prompts.GEMINI_ANALYZE_COMMENTS.format(
            script_indicator=('ê³¼ ìŠ¤í¬ë¦½íŠ¸' if transcript else ''),
            video_title=video_title,
            script_section=script_section,
            comments_text=chr(10).join(comments[:50])
        )

        text = await self.generate_text(prompt, temperature=0.3)

        # JSON íŒŒì‹±
        import json
        import re

        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            return json.loads(json_match.group())
        return {"error": "íŒŒì‹± ì‹¤íŒ¨", "raw": text}

    async def generate_thumbnail_texts(self, topic: str, script: str, style: str, language: str = "ko") -> dict:
        """ëŒ€ë³¸ ë° ìŠ¤íƒ€ì¼ ê¸°ë°˜ ì¸ë„¤ì¼ í›„í‚¹ ë¬¸êµ¬ ìƒì„±"""
        
        # Script truncation to avoid token limits
        safe_script = script[:3000] if script else f"Topic: {topic}"
        
        prompt = prompts.GEMINI_THUMBNAIL_HOOK_TEXT.format(
            script=safe_script,
            thumbnail_style=style,
            image_style=style, # Same for now
            target_language=language
        )

        try:
            text = await self.generate_text(prompt, temperature=0.8)
            
            # JSON Parsing
            import json
            import re
            
            # Clean Markdown
            cleaned_text = re.sub(r'```json\s*|\s*```', '', text).strip()
            
            # Try parse
            try:
                data = json.loads(cleaned_text)
                return data
            except json.JSONDecodeError:
                match = re.search(r'\{[\s\S]*\}', cleaned_text)
                if match:
                    return json.loads(match.group(0))
                else:
                    # Fallback
                    return {"texts": [], "reasoning": "JSON parse failed"}
                    
        except Exception as e:
            print(f"Thumbnail Text Gen Error: {e}")
            return {"texts": [], "reasoning": str(e)}

    async def extract_success_strategy(self, analysis_data: dict) -> List[dict]:
        """ë¶„ì„ ê²°ê³¼ì—ì„œ ì¼ë°˜í™”ëœ ì„±ê³µ ì „ëµ(Knowledge) ì¶”ì¶œ"""
        analysis_json = json.dumps(analysis_data, ensure_ascii=False)
        
        prompt = prompts.GEMINI_EXTRACT_STRATEGY.format(
            analysis_json=analysis_json
        )

        try:
            text = await self.generate_text(prompt, temperature=0.3)
            json_match = re.search(r'\[[\s\S]*\]', text)
            if json_match:
                return json.loads(json_match.group())
        except Exception as e:
            print(f"[Gemini] Strategy extraction failed: {e}")
            
        return []

    async def generate_script_structure(self, analysis_data: dict, recent_titles: List[str] = None, target_language: str = "ko", style_prompt: str = "", accumulated_knowledge: List[dict] = None) -> dict:
        """ë¶„ì„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€ë³¸ êµ¬ì¡° ìë™ ìƒì„± (ë‚´ìš©ê³¼ ì „ëµì˜ ë¶„ë¦¬ + ëˆ„ì  ì§€ì‹ í™œìš©)"""
        
        # [NEW] ë¶„ì„ ë°ì´í„° ë¶„ë¦¬ (ë‚´ìš© vs ì „ëµ)
        topic_keyword = analysis_data.get('topic', 'ì£¼ì œ ì—†ìŒ')
        success_strategy = analysis_data.get('success_analysis', {})
        script_style = analysis_data.get('script_style', 'story')


        # [NEW] ëª©í‘œ ê¸¸ì´ì— ë”°ë¥¸ ìµœì†Œ ì„¹ì…˜ ìˆ˜ ê³„ì‚° (Moved Up)
        duration_seconds = analysis_data.get('duration', 60)
        if isinstance(analysis_data.get('duration_category'), str):
            try:
                duration_seconds = int(re.search(r'\d+', analysis_data['duration_category']).group())
            except: pass

        # [NEW] ìŠ¤íƒ€ì¼ë³„ íŠ¹í™” ì§€ì¹¨ (ê¸°ì¡´ ì½”ë“œ ìœ ì§€)
        specialized_instruction = ""
        if script_style == "story":
            specialized_instruction = f"""
[EXTREMELY IMPORTANT: CREATIVE STORYTELLING]
- **CONTENT DECOUPLING**: You are NOT a summarizer. DO NOT use names (e.g., channel names like 'Dolby', guest names like 'Asra'), specific places, or the exact plot from the benchmarked video.
- **ZERO PLAGIARISM**: If you copy the benchmark video's story, you FAIL.
- **ACTUAL TASK**: Create a 100% ORIGINAL horror story based only on the keyword "{topic_keyword}".
- **HOW TO USE BENCHMARK**: Only look at the *technique*. (e.g., 'The way it built tension at 15s', 'The use of a specific psychological hook') - but use a DIFFERENT scare to do it.
"""
        else:
            specialized_instruction = f"[STYLE: INFORMATIONAL] Focus on '{topic_keyword}'."

        # [NEW] ìˆí¼(Shorts) ê°•ë ¥ ì œì•½ ì¶”ê°€
        if duration_seconds <= 60:
            specialized_instruction += f"""
\n[CRITICAL SHORTFORM CONSTRAINT]
- This is a {duration_seconds}-second SHORTFORM video.
- **IGNORE** any minimum section requirements mentioned elsewhere.
- You MUST generate **MAXIMUM 3 SECTIONS** (e.g., Hook -> Core -> Outro).
- Keep descriptions concise and fast-paced.
"""

        # [NEW] ëˆ„ì  ì§€ì‹ í™œìš© ì§€ì¹¨
        knowledge_instruction = ""
        if accumulated_knowledge:
            knowledge_list = "\n".join([f"- [{k['category']}] {k['pattern']}: {k['insight']}" for k in accumulated_knowledge])
            knowledge_instruction = f"""
### 3. ëˆ„ì ëœ ì„±ê³µ ì „ëµ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ (Success Knowledge DB)
ì•„ë˜ëŠ” ê³¼ê±°ì— ì„±ê³µí–ˆë˜ ë‹¤ë¥¸ ì˜ìƒë“¤ë¡œë¶€í„° ë‹¹ì‹ ì´ ì§ì ‘ ì¶”ì¶œí•˜ì—¬ í•™ìŠµí•œ 'ì„±ê³µ ë¬¸ë²•' ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ì´ë²ˆ ê¸°íšì— ì ê·¹ í™œìš©í•˜ì„¸ìš”:
{knowledge_list}
"""

        # [NEW] ì–¸ì–´/ë¬¸í™”ì  ë§¥ë½ ì„¤ì •
        context_instruction = "Korean context."
        if target_language == "ja": context_instruction = "Japanese context."
        elif target_language == "en": context_instruction = "Global context."
        elif target_language == "vi": context_instruction = "Vietnamese context."
        

        
        min_sections = 4
        
        # [MODIFIED] ìˆí¼(60ì´ˆ ì´í•˜)ì¼ ê²½ìš° ì„¹ì…˜ ìˆ˜ ì œí•œ (Intro, Body, Outro ìµœëŒ€ 3ê°œ)
        if duration_seconds <= 60:
            min_sections = 3
        elif duration_seconds > 300: 
            min_sections = max(8, duration_seconds // 45)
        if duration_seconds > 1800: min_sections = max(20, duration_seconds // 60)
        if duration_seconds > 3600: min_sections = max(40, duration_seconds // 70)

        history_instruction = ""
        if recent_titles:
            history_list = "\n".join([f"- {t}" for t in recent_titles])
            history_instruction = f"Avoid repeating these topics: {history_list}"

        prompt = prompts.GEMINI_SCRIPT_STRUCTURE.format(
            topic_keyword=topic_keyword,
            user_notes=analysis_data.get('user_notes', 'ì—†ìŒ'),
            specialized_instruction=specialized_instruction,
            duration_seconds=duration_seconds,
            min_sections=min_sections,
            custom_prompt_section=f"[Custom Prompt]: {style_prompt}" if style_prompt else "",
            knowledge_instruction=knowledge_instruction,
            success_strategy_json=json.dumps(success_strategy, ensure_ascii=False),
            target_language_context=context_instruction,
            history_instruction=history_instruction
        )

        text = await self.generate_text(prompt, temperature=0.5)
        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            try:
                return json.loads(json_match.group())
            except:
                pass
        return {"error": "êµ¬ì¡° ìƒì„± ì‹¤íŒ¨", "raw": text}
    async def generate_title_recommendations(self, keyword: str, topic: str = "", language: str = "ko") -> List[str]:
        """ì¶”ì²œ ì œëª© 5ê°œ ìƒì„±"""
        prompt = f"""
        ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì½˜í…ì¸  ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í´ë¦­ë¥ (CTR)ì´ ë†’ì€ ë¡±í¼/ì‡¼ì¸  ìœ íŠœë¸Œ ì œëª© 5ê°œë¥¼ ì œì•ˆí•´ì£¼ì„¸ìš”.

        [ì •ë³´]
        - í‚¤ì›Œë“œ: {keyword}
        - ì£¼ì œ/ì„¤ëª…: {topic}
        - ì–¸ì–´: {language}

        [ìš”êµ¬ì‚¬í•­]
        1. 5ê°œì˜ ì œëª©ì„ ìƒì„±í•˜ì„¸ìš”.
        2. ì–´ê·¸ë¡œì„±ë³´ë‹¤ëŠ” í˜¸ê¸°ì‹¬ì„ ìœ ë°œí•˜ê±°ë‚˜, í˜œíƒì„ ëª…í™•íˆ í•˜ê±°ë‚˜, ê°ì •ì„ ìê·¹í•˜ëŠ” ì œëª©ì„ ë§Œë“œì„¸ìš”.
        3. 50ì ì´ë‚´ë¡œ ì§§ê³  ê°•ë ¬í•˜ê²Œ.
        4. ë²ˆí˜¸ ë¶™ì´ì§€ ë§ê³  ì˜¤ì§ JSON ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”. ì˜ˆ: ["ì œëª©1", "ì œëª©2", ...]
        """

        try:
            response_text = await self.generate_text(prompt, temperature=0.8)
            cleaned_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
            match = re.search(r'\[.*\]', cleaned_text, re.DOTALL)
            
            if match:
                titles = json.loads(match.group(0))
                return titles[:5]
            else:
                # Fallback
                return [line.strip().lstrip('-').lstrip('1.').strip() for line in cleaned_text.split('\n') if line.strip()][:5]
        except Exception as e:
            print(f"Title Gen Error: {e}")
            return []


    async def generate_video_metadata(self, script_text: str) -> dict:
        """ëŒ€ë³¸ì„ ë°”íƒ•ìœ¼ë¡œ ì œëª©, ì„¤ëª…, íƒœê·¸ ìƒì„±"""
        prompt = prompts.AUTOPILOT_GENERATE_METADATA.format(script_text=script_text)
        try:
            response_text = await self.generate_text(prompt, temperature=0.7)
            
            # Clean Markdown code blocks
            cleaned_text = re.sub(r'```json\s*|\s*```', '', response_text).strip()
            
            # Use regex to find JSON object
            json_match = re.search(r'\{[\s\S]*\}', cleaned_text)
            if json_match:
                return json.loads(json_match.group(0))
            
            # Fallback if parsing fails
            return {
                "title": f"New Video {config.get_kst_time().date()}",
                "description": "#AI #Shorts",
                "tags": ["ai", "shorts"]
            }
        except Exception as e:
            print(f"Metadata Gen Error: {e}")
            return {
                "title": f"Video {config.get_kst_time().date()}",
                "description": "#AI",
                "tags": ["ai"]
            }


    async def generate_trending_keywords(self, language: str = "ko", period: str = "now", age: str = "all") -> list:
        """
        ì–¸ì–´/ê¸°ê°„/ì—°ë ¹ë³„ ì¸ê¸° ìœ íŠœë¸Œ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ìƒì„± (Search Volume ì‹œë®¬ë ˆì´ì…˜)
        """
        lang_name = ""
        if language == "ko": lang_name = "South Korea (Korean)"
        elif language == "ja": lang_name = "Japan (Japanese)"
        elif language == "en": lang_name = "USA/International (English)"
        elif language == "es": lang_name = "Spain/Latin America (Spanish)"
        elif language == "vi": lang_name = "Vietnam (Vietnamese)"
        else: lang_name = "South Korea (Korean)"

        # ê¸°ê°„ í…ìŠ¤íŠ¸
        period_text = "REAL-TIME / NOW"
        if period == "week": period_text = "THIS WEEK (Last 7 days)"
        elif period == "month": period_text = "THIS MONTH (Last 30 days)"

        # ì—°ë ¹ í…ìŠ¤íŠ¸
        age_text = "ALL Ages"
        if age == "10s": age_text = "Teenagers (10-19)"
        elif age == "20s": age_text = "Young Adults (20-29)"
        elif age == "30s": age_text = "Adults (30-39)"
        elif age == "40s": age_text = "Middle-aged (40-49)"
        elif age == "50s": age_text = "Seniors (50+)"

        prompt = prompts.GEMINI_TRENDING_KEYWORDS.format(
            lang_name=lang_name,
            period_text=period_text,
            age_text=age_text,
            language=language
        )
        
        try:
            text = await self.generate_text(prompt, temperature=0.9)
            
            import json
            import re
            
            match = re.search(r'\[[\s\S]*\]', text)
            if match:
                json_str = match.group(0)
                return json.loads(json_str)
            else:
                # Fallback data if parse fails
                return []
                
        except Exception as e:
            print(f"Trend keywords generation failed: {e}")
            return []

    async def generate_commerce_copywriting(self, product_info: dict) -> dict:
        """ì œí’ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‡¼ì¸ ìš© ë§¤ìš´ë§› ì¹´í”¼ë¼ì´íŒ… 3ì¢… ìƒì„±"""
        
        prompt = f"""
        ë‹¹ì‹ ì€ 100ë§Œ ì¡°íšŒìˆ˜ë¥¼ ë§Œë“œëŠ” ìˆí¼ ë§ˆì¼€íŒ… ì²œì¬ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
        ì•„ë˜ ì œí’ˆ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹œì²­ìë¥¼ ì¦‰ì‹œ ì‚¬ë¡œì¡ëŠ”(Hooking) ì‡¼ì¸  ëŒ€ë³¸ 3ê°€ì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
        
        [ì œí’ˆ ì •ë³´]
        - ì œí’ˆëª…: {product_info.get('product_name')}
        - ê°€ê²©: {product_info.get('product_price')}
        - íŠ¹ì§•: {product_info.get('product_description')}
        
        [ìš”êµ¬ì‚¬í•­]
        1. 3ê°€ì§€ ì „ëµìœ¼ë¡œ ì‘ì„±í•  ê²ƒ:
           A. [ê³µê°/ê³ í†µ] "ì•„ì§ë„ 00í•˜ì„¸ìš”? ì´ê±° ì“°ë©´ í•´ê²°ë©ë‹ˆë‹¤." (ë¬¸ì œ ì œê¸° -> í•´ê²°)
           B. [ê²°ê³¼/ë°˜ì „] "ì´ê±° í•˜ë‚˜ ë°”ê¿¨ë”ë‹ˆ 00ì´ ë‹¬ë¼ì¡Œì–´ìš”." (ë“œë¼ë§ˆí‹±í•œ ë³€í™” ê°•ì¡°)
           C. [ì¶©ê²©/ê°€ì„±ë¹„] "ì‚¬ì¥ë‹˜ì´ ë¯¸ì³¤ì–´ìš”? ì´ ê°€ê²©ì— ì´ê²Œ ëœë‹¤ê³ ?" (ê°€ê²© ëŒ€ë¹„ ì„±ëŠ¥ ê°•ì¡°)
           
        2. ê° ëŒ€ë³¸ì€ 'Hook(3ì´ˆ) -> Body(ì„¤ëª…) -> CTA(í–‰ë™ìœ ë„)' êµ¬ì¡°ë¥¼ ê°€ì§ˆ ê²ƒ.
        3. ë§íˆ¬ëŠ” ë¹ ë¥´ê³  ê°•ë ¬í•˜ê²Œ, êµ¬ì–´ì²´ ì‚¬ìš©. (ì¡´ëŒ“ë§/ë°˜ë§ í˜¼ìš© ê°€ëŠ¥í•˜ë‚˜ ìì—°ìŠ¤ëŸ½ê²Œ)
        4. ì „ì²´ ê¸¸ì´ëŠ” ì½ì—ˆì„ ë•Œ 30ì´ˆ ì´ë‚´ ë¶„ëŸ‰.
        
        [ì¶œë ¥ í˜•ì‹]
        ì˜¤ì§ JSON ê°ì²´ë¡œ ë°˜í™˜í•˜ì„¸ìš”:
        {{
            "copywriting": [
                {{
                    "type": "pain_point",
                    "title": "ê³µê°í˜• (ë¬¸ì œí•´ê²°)",
                    "hook": "...",
                    "body": "...",
                    "cta": "..."
                }},
                {{
                    "type": "benefit",
                    "title": "ê²°ê³¼ê°•ì¡°í˜• (ë¹„í¬ì• í”„í„°)",
                    "hook": "...",
                    "body": "...",
                    "cta": "..."
                }},
                {{
                    "type": "shock",
                    "title": "ì¶©ê²©í˜• (ê°€ì„±ë¹„ëíŒì™•)",
                    "hook": "...",
                    "body": "...",
                    "cta": "..."
                }}
            ]
        }}
        """
        
        try:
            text = await self.generate_text(prompt, temperature=0.8)
            import json
            import re
            
            cleaned = re.sub(r'```json\s*|\s*```', '', text).strip()
            match = re.search(r'\{[\s\S]*\}', cleaned)
            if match:
                return json.loads(match.group(0))
            else:
                return {"copywriting": []}
                
        except Exception as e:
            print(f"Copywriting Gen Error: {e}")
            return {"copywriting": []}

    async def generate_amazon_trends(self) -> List[dict]:
        """ë¯¸êµ­ ì•„ë§ˆì¡´ íŠ¸ë Œë“œ í‚¤ì›Œë“œ ìƒì„±"""
        from config import config
        current_date = config.get_kst_time().strftime("%Y-%m-%d")
        
        prompt = f"""
        Current Date: {current_date}
        Target Market: USA (Amazon.com)
        Role: Amazon Affiliate Marketing Expert
        
        Identify 5 high-potential, trending product keywords for Amazon Affiliate marketing right now.
        Consider seasonality (holidays, weather), viral trends (TikTok/Instagram), and new tech releases.
        
        Return ONLY a JSON array of objects:
        [
            {{
                "keyword": "search term",
                "reason": "Why it sells now (short)"
            }},
            ...
        ]
        """
        
        try:
            text = await self.generate_text(prompt, temperature=0.9)
            import json, re
            cleaned = re.sub(r'```json\s*|\s*```', '', text).strip()
            match = re.search(r'\[[\s\S]*\]', cleaned)
            if match:
                return json.loads(match.group(0))
            return []
        except Exception as e:
            print(f"Trend Gen Error: {e}")
            return []

    async def generate_character_prompts_from_script(self, script: str, visual_style: str = "photorealistic") -> List[dict]:
        """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë“±ì¥ì¸ë¬¼ ì •ë³´ ë° ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        
        prompt = prompts.GEMINI_CHARACTER_PROMPTS.format(
            script=script[:8000], 
            visual_style=visual_style
        )
        
        text = await self.generate_text(prompt, temperature=0.5)
        
        # JSON íŒŒì‹±
        json_match = re.search(r'\{[\s\S]*\}', text)
        if json_match:
            try:
                data = json.loads(json_match.group())
                return data.get("characters", [])
            except Exception as e:
                print(f"Character prompt JSON parse error: {e}")
                pass
        return []

    async def generate_image_prompts_from_script(self, script: str, duration_seconds: int, style_prompt: str = None, characters: List[dict] = None) -> List[dict]:
        """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì¥ë©´ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± (ê°€ë³€ í˜ì´ì‹± ë° ìºë¦­í„° ì¼ê´€ì„± ì ìš©)"""
        
        # [NEW] ê°€ë³€ í˜ì´ì‹±(Dynamic Pacing) ë¡œì§ - ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¥¸ ì •ë°€ ì¡°ì •
        # 0 ~ 2ë¶„ (120s): 8ì´ˆë‹¹ 1ì¥ (15ì¥)
        # 2 ~ 5ë¶„ (180s): 20ì´ˆë‹¹ 1ì¥ (9ì¥)
        # 5 ~ 7ë¶„ (120s): 40ì´ˆë‹¹ 1ì¥ (3ì¥)
        # 7 ~ 10ë¶„ (180s): 60ì´ˆë‹¹ 1ì¥ (3ì¥)
        # 10 ~ 20ë¶„ (600s): 120ì´ˆë‹¹ 1ì¥ (5ì¥)
        # 20ë¶„ ì´í›„: 600ì´ˆë‹¹ 1ì¥
        
        num_scenes = 0
        if duration_seconds <= 120:
            num_scenes = duration_seconds // 8
        elif duration_seconds <= 300:
            num_scenes = 15 + (duration_seconds - 120) // 20
        elif duration_seconds <= 420:
            num_scenes = 15 + 9 + (duration_seconds - 300) // 40
        elif duration_seconds <= 600:
            num_scenes = 15 + 9 + 3 + (duration_seconds - 420) // 60
        elif duration_seconds <= 1200:
            num_scenes = 30 + (duration_seconds - 600) // 120
        else:
            num_scenes = 35 + (duration_seconds - 1200) // 600
        
        num_scenes = max(3, int(num_scenes))
        
        # [CRITICAL] ì‹¤ì‚¬ í‚¤ì›Œë“œ ë°©ì§€ ë¡œì§ ë³´ê°•
        is_realistic = any(kw in style_prompt.lower() for kw in ["realistic", "photo", "cinematic", "8k"])
        style_conflict_prevention = ""
        if not is_realistic:
            style_conflict_prevention = """
[ìŠ¤íƒ€ì¼ ì¶©ëŒ ë°©ì§€ - ì—„ê²© ì¤€ìˆ˜]
í˜„ì¬ ì§€ì •ëœ ìŠ¤íƒ€ì¼ì€ ì‹¤ì‚¬(Photorealistic)ê°€ ì•„ë‹™ë‹ˆë‹¤.
í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œ 'realistic', 'photorealistic', 'hyper-detailed', '8k', 'raw photo', 'masterpiece', 'cinematic lighting', 'depth of field', '3d render', 'octane render', 'unreal engine' ë“±ì˜ ì‹¤ì‚¬ ì§€í–¥ì  í‚¤ì›Œë“œë¥¼ **ì ˆëŒ€** ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
ë˜í•œ, ì´ë¯¸ì§€ ë‚´ì— ì–´ë– í•œ ì˜ì–´ í…ìŠ¤íŠ¸, ë¡œê³ , ë¸Œëœë“œëª…, ë ˆì´ë¸”ë„ í¬í•¨ë˜ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”. (ABSOLUTELY NO English text, NO logos, NO brand names, NO labels in the prompt or the image.)
ì¸ë¬¼ê³¼ ë°°ê²½ ëª¨ë‘ê°€ "{style_prompt}"ì˜ ë§¤ì²´ íŠ¹ì„±(ê·¸ë¦¼ì²´, ì§ˆê°)ì„ ì™„ë²½í•˜ê²Œ ë”°ë¼ì•¼ í•˜ë©°, ì¡°ê¸ˆì´ë¼ë„ ì‹¤ì‚¬ ëŠë‚Œì´ ì„ì´ì§€ ì•Šë„ë¡ í•˜ì„¸ìš”.
"""

        style_instruction = f"""
[ìŠ¤íƒ€ì¼ ì§€ì¹¨ - ë§¤ìš° ì¤‘ìš”]
ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ì— ë‹¤ìŒ ìŠ¤íƒ€ì¼ì„ ë°˜ë“œì‹œ ë°˜ì˜í•˜ì„¸ìš”:
"{style_prompt}"

ëª¨ë“  prompt_enì˜ ì‹œì‘ ë¶€ë¶„ì— ì´ ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œë¥¼ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
ì˜ˆ: "{style_prompt}, ..."
{style_conflict_prevention}
"""

        character_instruction = ""
        if characters:
            char_descriptions = "\n".join([f"- {c['name']} ({c['role']}): {c['prompt_en']}" for c in characters])
            character_instruction = f"""
[ë“±ì¥ì¸ë¬¼ ì¼ê´€ì„± ì§€ì¹¨ - í•„ìˆ˜]
ì´ ì˜ìƒì—ëŠ” ë‹¤ìŒ ìºë¦­í„°ë“¤ì´ ë“±ì¥í•©ë‹ˆë‹¤. ì¥ë©´ë³„ prompt_en ìƒì„± ì‹œ í•´ë‹¹ ì¸ë¬¼ì´ ë“±ì¥í•œë‹¤ë©´ ì•„ë˜ ë¬˜ì‚¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ì—¬ ì™¸í˜• ì¼ê´€ì„±ì„ ìœ ì§€í•˜ì„¸ìš”:
{char_descriptions}
"""

        # [NEW] ì¥ì‹œê°„ ì˜ìƒ í˜ì´ì‹± ì§€ì¹¨ (ì‚¬ìš©ì ìš”ì²­ ì„¸ë¶„í™” ë°˜ì˜)
        limit_instruction = ""
        if duration_seconds > 0: # ì§§ì€ ì˜ìƒë„ ì¼ê´€ëœ ì§€ì¹¨ ì ìš©
            limit_instruction = f"""
[ì¤‘ìš”: ì˜ìƒ í˜ì´ì‹± ì •ì±…]
ì‚¬ìš©ìì˜ ëª°ì…ë„ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì œì‘ íš¨ìœ¨ì„ ë†’ì´ê¸° ìœ„í•´ ë‹¤ìŒ êµ¬ê°„ë³„ í˜ì´ì‹±ì„ ì—„ê²©íˆ ì¤€ìˆ˜í•˜ì„¸ìš”:
1. **ì´ˆë°˜ 2ë¶„ (0~2ë¶„)**: 8ì´ˆë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ ë§¤ìš° ì—­ë™ì ì¸ ì‹œê° ë³€í™”ë¥¼ ì£¼ì–´ í›„í‚¹í•˜ì„¸ìš”.
2. **ëª°ì… ë‹¨ê³„ (2~5ë¶„)**: 20ì´ˆë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ í•µì‹¬ ì¥ë©´ ìœ„ì£¼ë¡œ ì „í™˜í•˜ì„¸ìš”.
3. **ì•ˆì • ë‹¨ê³„ (5~7ë¶„)**: 40ì´ˆë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ ì „ê°œ ì†ë„ë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.
4. **ìœ ì§€ ë‹¨ê³„ (7~10ë¶„)**: 1ë¶„ë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ ë¶„ìœ„ê¸°ë¥¼ ìœ ì§€í•˜ì„¸ìš”.
5. **ê·¸ ì´í›„ (10ë¶„~20ë¶„)**: 2ë¶„ë‹¹ 1ì¥, **(20ë¶„ ì´í›„)**: 10ë¶„ë‹¹ 1ì¥ ìˆ˜ì¤€ìœ¼ë¡œ í° íë¦„ë§Œ ì§šì–´ì£¼ì„¸ìš”.
- ìœ„ í˜ì´ì‹±ì— ë§ì¶° ì´ **{num_scenes}ê°œ**ì˜ ì¥ë©´ì„ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ê³¨ê³ ë£¨ ë°°ë¶„í•˜ì—¬ JSONì„ ìƒì„±í•˜ì„¸ìš”.
"""

        prompt = prompts.GEMINI_IMAGE_PROMPTS.format(
            num_scenes=num_scenes,
            script=script,
            style_instruction=style_instruction,
            character_instruction=character_instruction, # [NEW]
            limit_instruction=limit_instruction,
            style_prefix=style_prompt or 'High quality, photorealistic'
        )

        text = await self.generate_text(prompt, temperature=0.7)

        # JSON íŒŒì‹±
        import json
        import re

        try:
            # 1. Clean Markdown code blocks
            cleaned_text = re.sub(r'```json\s*|\s*```', '', text).strip()
            
            # 2. Try parsing the cleaned text directly
            try:
                data = json.loads(cleaned_text)
            except json.JSONDecodeError:
                # 3. If direct parse fails, try searching for JSON object or list
                json_match = re.search(r'(\{[\s\S]*\}|\[[\s\S]*\])', cleaned_text)
                if json_match:
                    data = json.loads(json_match.group(0))
                else:
                    return []

            # 4. Extract scenes list
            if isinstance(data, dict):
                scenes = data.get("scenes", [])
            elif isinstance(data, list):
                scenes = data
            else:
                scenes = []
            
            # [NEW] Hybrid Approach: Time-based correction
            # Split scenes that are too long (>20 seconds) into sub-images
            corrected_scenes = []
            MAX_SCENE_SECONDS = 20  # Maximum seconds per image
            MIN_SCENE_SECONDS = 5   # Minimum seconds per image
            
            for scene in scenes:
                estimated_sec = scene.get("estimated_seconds", 15)
                
                # If estimated_seconds is missing, calculate from text length
                if not estimated_sec or estimated_sec <= 0:
                    scene_text = scene.get("scene_text", "")
                    estimated_sec = max(5, len(scene_text) / 6)  # ~6 chars/sec for Korean
                
                if estimated_sec <= MAX_SCENE_SECONDS:
                    # Scene is fine, keep as is
                    scene["estimated_seconds"] = estimated_sec
                    corrected_scenes.append(scene)
                else:
                    # Scene is too long, split into sub-images
                    num_splits = int(estimated_sec / MAX_SCENE_SECONDS) + 1
                    sub_duration = estimated_sec / num_splits
                    
                    scene_text = scene.get("scene_text", "")
                    text_parts = self._split_text_evenly(scene_text, num_splits)
                    
                    for i in range(num_splits):
                        sub_scene = scene.copy()
                        sub_scene["scene_number"] = len(corrected_scenes) + 1
                        sub_scene["scene_title"] = f"{scene.get('scene_title', '')} ({i+1}/{num_splits})"
                        sub_scene["scene_text"] = text_parts[i] if i < len(text_parts) else scene_text
                        sub_scene["estimated_seconds"] = sub_duration
                        # Slightly vary the prompt for visual diversity
                        if i > 0:
                            sub_scene["prompt_en"] = scene.get("prompt_en", "") + f", variation {i+1}"
                        corrected_scenes.append(sub_scene)
            
            # Renumber scenes sequentially
            for idx, scene in enumerate(corrected_scenes):
                scene["scene_number"] = idx + 1
            
            print(f"[Hybrid] Original: {len(scenes)} scenes â†’ Corrected: {len(corrected_scenes)} scenes")
            return corrected_scenes
            
        except Exception as e:
            print(f"JSON Parse Error in generate_image_prompts: {e}")
            pass
            
        return []
    
    def _split_text_evenly(self, text: str, num_parts: int) -> list:
        """í…ìŠ¤íŠ¸ë¥¼ ê· ë“±í•˜ê²Œ ë¶„í•  (ë¬¸ì¥ ê²½ê³„ ìš°ì„ )"""
        if not text or num_parts <= 1:
            return [text]
        
        import re
        sentences = re.split(r'(?<=[.!?])\s+', text)
        
        if len(sentences) <= num_parts:
            # Not enough sentences, split by characters
            part_len = len(text) // num_parts
            parts = []
            for i in range(num_parts):
                start = i * part_len
                end = (i + 1) * part_len if i < num_parts - 1 else len(text)
                parts.append(text[start:end].strip())
            return parts
        
        # Distribute sentences evenly
        sentences_per_part = len(sentences) // num_parts
        parts = []
        for i in range(num_parts):
            start_idx = i * sentences_per_part
            end_idx = (i + 1) * sentences_per_part if i < num_parts - 1 else len(sentences)
            parts.append(" ".join(sentences[start_idx:end_idx]))
        
        return parts

    async def generate_video_search_keywords(self, script_segment: str, mood_style: str = "cinematic") -> str:
        """
        Stock Video ê²€ìƒ‰ì„ ìœ„í•œ ì˜ì–´ ê²€ìƒ‰ì–´ ìƒì„±
        ë³µì¡í•œ í”„ë¡¬í”„íŠ¸ ëŒ€ì‹  ê²€ìƒ‰ ì—”ì§„(Pexels)ì— ì í•©í•œ ë‹¨ìˆœ í‚¤ì›Œë“œ ì¡°í•© ìƒì„±
        ì˜ˆ: "Snowy winter night loop", "Fireplace burning cozy"
        """
        prompt = f"""
        You are a Stock Video Search Assistant. Convert the following context into a generic, simple English search query for a stock video site (Pexels/Shutterstock).
        
        [Context]
        Script: "{script_segment[:200]}"
        Mood: {mood_style}
        
        [Requirements]
        - Output ONLY the Search Query. No markdown, no quotes.
        - Use 3-5 simple English words.
        - Add 'loop' or 'background' if appropriate for ambient scenes.
        - Example: "Snowy winter night loop", "City rain timelapse", "Calm ocean waves"
        
        Search Query:
        """
        try:
            query = await self.generate_text(prompt, temperature=0.3)
            return query.strip().replace('"', '').replace("Search Query:", "").strip()
        except:
            return "nature calm loop" # Fallback

    async def generate_video(self, prompt: str, model: str = "veo-3.1-generate-preview") -> dict:
        """
        Gemini Veo (veo-3.1-generate-preview)ë¥¼ ì‚¬ìš©í•œ ë¹„ë””ì˜¤ ìƒì„±
        """
        if not self.api_key:
             return {"status": "error", "error": "API Key is missing"}
        
        try:
             # ì„ì‹œ ë™ê¸° í˜¸ì¶œ (ë¹„ë™ê¸° ë˜í¼ í•„ìš” ì‹œ ìˆ˜ì •)
             # google.genai.Client ì‚¬ìš©
             from google import genai
             client = genai.Client(api_key=self.api_key)
             
             print(f"DEBUG: Starting Veo generation for prompt: {prompt}")
             # 1. Generate Video
             # https://ai.google.dev/gemini-api/docs/video
             operation = client.models.generate_videos(
                 model=model,
                 prompt=prompt,
                 config={
                    'number_of_videos': 1,
                    # 'fps': 24, 
                    # 'duration_seconds': 5 # Preview is usually short
                 }
             )
             
             
             # Handle operation - it might be a string (operation name) or an object
             print(f"DEBUG: Operation type: {type(operation)}")
             
             # If operation is a string, we need to poll differently
             if isinstance(operation, str):
                 op_name = operation
                 print(f"DEBUG: Operation is a string (name): {op_name}")
                 
                 # Manual polling using the operation name
                 import time
                 max_attempts = 60  # 5 minutes
                 attempts = 0
                 
                 while attempts < max_attempts:
                     print(f"Polling operation status... (attempt {attempts + 1}/{max_attempts})")
                     time.sleep(5)
                     attempts += 1
                     
                     try:
                         # Try to get operation status
                         # The SDK might have a different method to check status
                         op_status = client.operations.get(op_name)
                         
                         # Check if it's done
                         if hasattr(op_status, 'done') and op_status.done:
                             operation = op_status
                             break
                         elif isinstance(op_status, dict) and op_status.get('done'):
                             operation = op_status
                             break
                     except Exception as e:
                         print(f"Polling error: {e}")
                         # If we can't poll, just wait and hope for the best
                         if attempts >= 30:  # After 2.5 minutes, try to get result anyway
                             try:
                                 operation = client.operations.get(op_name)
                                 break
                             except:
                                 pass
                 
                 if attempts >= max_attempts:
                     return {"status": "error", "error": "Video generation timed out"}
             
             # If operation is an object, use wait() or poll
             elif hasattr(operation, 'wait'):
                 print("DEBUG: Using operation.wait() method")
                 try:
                     operation = operation.wait(timeout=300)
                 except Exception as e:
                     print(f"Wait error: {e}")
                     return {"status": "error", "error": f"Wait failed: {str(e)}"}
             
             # Try using result() method (blocks until complete)
             elif hasattr(operation, 'result'):
                 print("DEBUG: Using operation.result property (checking if complete)")
                 try:
                     # First check if it's a method or property
                     if callable(operation.result):
                         print("DEBUG: result is callable (method)")
                         result_obj = operation.result(timeout=300)
                     else:
                         print("DEBUG: result is a property")
                         # For properties, we need to poll manually
                         import time
                         max_wait = 300  # 5 minutes
                         start_time = time.time()
                         
                         while time.time() - start_time < max_wait:
                             # Try to refresh operation status
                             if hasattr(operation, 'name'):
                                 try:
                                     fresh_op = client.operations.get(operation.name)
                                     operation = fresh_op
                                 except:
                                     pass
                             
                             # Check if done
                             if hasattr(operation, 'done'):
                                 if callable(operation.done):
                                     is_done = operation.done()
                                 else:
                                     is_done = operation.done
                                 
                                 if is_done:
                                     print("DEBUG: Operation completed!")
                                     break
                             
                             print(f"Waiting for completion... ({int(time.time() - start_time)}s elapsed)")
                             time.sleep(5)
                         
                         if time.time() - start_time >= max_wait:
                             return {"status": "error", "error": "Timeout waiting for video generation"}
                         
                         result_obj = operation.result
                     
                     print(f"DEBUG: Got result: {type(result_obj)}")
                 except Exception as e:
                     print(f"Result error: {e}")
                     import traceback
                     traceback.print_exc()
                     return {"status": "error", "error": f"Result failed: {str(e)}"}
             
             
             # Otherwise, try manual polling on the object
             else:
                 print("DEBUG: Manual polling on operation object")
                 import time
                 max_attempts = 60
                 attempts = 0
                 
                 while attempts < max_attempts:
                     if hasattr(operation, 'done') and operation.done:
                         break
                     
                     print(f"Waiting... (attempt {attempts + 1}/{max_attempts})")
                     time.sleep(5)
                     attempts += 1
                 
                 if attempts >= max_attempts:
                     return {"status": "error", "error": "Timeout"}
                  
             if operation.error:
                 print(f"Veo Error: {operation.error}")
                 return {"status": "error", "error": str(operation.error)}
                 
             # 3. Get Result
             # operation.result is likely a property, not a method
             result = operation.result 
             
             if not result:
                  return {"status": "error", "error": "No result returned"}
                  
             # Inspect structure based on new SDK
             if hasattr(result, 'generated_videos'):
                 generated_video = result.generated_videos[0]
                 video_url = generated_video.video.uri
             else:
                 # Fallback/Debug
                 print(f"DEBUG: Result structure: {result}")
                 video_url = getattr(result, 'uri', None)
             
             if not video_url:
                 return {"status": "error", "error": "Video URI not found in result"}
             
             return {
                 "status": "ok", 
                 "video_url": video_url,
                 "metadata": {
                     "model": model,
                     "prompt": prompt
                 }
             }

        except Exception as e:
            print(f"Veo Generation Failed: {e}")
            import traceback
            traceback.print_exc()
            return {"status": "error", "error": str(e)}

    async def match_images_to_subtitles(self, subtitles: List[dict], image_data: List[dict]) -> dict:
        """
        ìë§‰(í…ìŠ¤íŠ¸)ì™€ ì´ë¯¸ì§€(í”„ë¡¬í”„íŠ¸)ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì ì˜ ë§¤ì¹­(íƒ€ì´ë°)ì„ ìƒì„±
        output: { "assignments": [ {"image_index": 0, "subtitle_index": 0}, ... ] }
        """
        
        # ë°ì´í„° ê°„ì†Œí™” (í† í° ì ˆì•½)
        subs_simplified = [{"id": i, "text": s['text'], "start": s['start'], "end": s['end']} for i, s in enumerate(subtitles)]
        imgs_simplified = [{"id": i, "prompt": img.get('prompt', 'Unknown Scene')} for i, img in enumerate(image_data)]
        
        prompt = f"""
        You are a Professional Video Editor.
        Your task is to assign the provided Images (described by prompts) to the Subtitles (timeline) to create a cohesive video flow.

        [Inputs]
        1. Subtitles (Timeline):
        {json.dumps(subs_simplified, ensure_ascii=False, indent=1)}

        2. Available Images (Asset Pool):
        {json.dumps(imgs_simplified, ensure_ascii=False, indent=1)}

        [Instructions]
        - Assign EVERY Image to a specific Subtitle index where it should START appearing.
        - Images should be distributed logically based on the narrative context (Semantic Match).
        - If an image matches a specific keyword in a subtitle, place it there.
        - Ensure images are spread out; do not clump them all at the beginning.
        - Return the result as a JSON object with a list of assignments.

        [Output Format]
        {{
            "assignments": [
                {{ "image_id": 0, "subtitle_id": 2 }},
                {{ "image_id": 1, "subtitle_id": 5 }},
                ...
            ]
        }}
        """

        try:
            print(f"[Gemini Sync] Sending {len(subs_simplified)} subs and {len(imgs_simplified)} images to AI...")
            text = await self.generate_text(prompt, temperature=0.1)
            print(f"[Gemini Sync] Response: {text[:200]}...") # Log first 200 chars
            
            # JSON íŒŒì‹±
            import re
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                data = json.loads(json_match.group())
                print(f"[Gemini Sync] Parsed Data: {data}")
                return data
            print("[Gemini Sync] JSON Parse Failed")
            return {"assignments": []}
            
        except Exception as e:
            print(f"Image-Subtitle Match Failed: {e}")
            return {"assignments": []}

    async def analyze_success_and_creation(self, video_info: dict) -> dict:
        """
        ì˜ìƒì˜ ì„±ê³µ ìš”ì¸ì„ ë¶„ì„í•˜ê³  ë²¤ì¹˜ë§ˆí‚¹ ì½˜í…ì¸ ë¥¼ ìƒì„±
        """
        title = video_info.get('title', '')
        channel = video_info.get('channelTitle', '')
        # Stats might be inside 'statistics' dict or direct keys depending on how it's passed
        views = video_info.get('statistics', {}).get('viewCount', video_info.get('viewCount', 0))
        likes = video_info.get('statistics', {}).get('likeCount', video_info.get('likeCount', 0))
        
        # Optional: Top comment if available
        top_comment = video_info.get('top_comment', 'ì •ë³´ ì—†ìŒ')

        prompt = prompts.GEMINI_SUCCESS_ANALYSIS.format(
            title=title,
            channel=channel,
            views=views,
            likes=likes,
            top_comment=top_comment
        )

        try:
            text = await self.generate_text(prompt, temperature=0.7)
            
            import json
            import re
            json_match = re.search(r'\{[\s\S]*\}', text)
            if json_match:
                return json.loads(json_match.group())
            else:
                return {"error": "JSON Parsing Failed", "raw": text}
        except Exception as e:
            return {"error": str(e)}

# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
gemini_service = GeminiService()
