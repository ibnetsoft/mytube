
import asyncio
import json
import os
import random
from datetime import datetime, timedelta
import httpx
from typing import List, Dict, Union, Optional, Any
from config import config
import database as db
from services.gemini_service import gemini_service
from services.prompts import prompts
from services.tts_service import tts_service
from services.video_service import video_service
from services.youtube_upload_service import youtube_upload_service
from services.topview_service import topview_service


def split_text_to_subtitle_chunks(text: str, max_chars_per_line: int = 20, max_lines: int = 2) -> list:
    """
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìë§‰ìš© ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    - í•œ ì¤„ë‹¹ ìµœëŒ€ max_chars_per_line ê¸€ì
    - í•œ í™”ë©´ì— ìµœëŒ€ max_lines ì¤„ (ê¸°ë³¸ 2ì¤„)
    - ë¬¸ì¥ ê²½ê³„(. ! ?)ë¥¼ ìš°ì„ ìœ¼ë¡œ ë¶„í• 
    
    Returns: List of subtitle text chunks (each chunk is max 2 lines)
    """
    if not text or not text.strip():
        return []
    
    text = text.strip()
    
    # ë¨¼ì € ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€)
    import re
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    chunks = []
    current_chunk_lines = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        # ë¬¸ì¥ì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„í•  (max_chars_per_line ê¸°ì¤€)
        words = sentence.split()
        current_line = ""
        lines_from_sentence = []
        
        for word in words:
            test_line = f"{current_line} {word}".strip() if current_line else word
            if len(test_line) <= max_chars_per_line:
                current_line = test_line
            else:
                if current_line:
                    lines_from_sentence.append(current_line)
                current_line = word
        
        if current_line:
            lines_from_sentence.append(current_line)
        
        # í˜„ì¬ ì²­í¬ì— ì´ ë¬¸ì¥ì˜ ì¤„ë“¤ì„ ì¶”ê°€
        for line in lines_from_sentence:
            current_chunk_lines.append(line)
            
            # max_linesì— ë„ë‹¬í•˜ë©´ ì²­í¬ ìƒì„±
            if len(current_chunk_lines) >= max_lines:
                chunks.append("\n".join(current_chunk_lines))
                current_chunk_lines = []
    
    # ë‚¨ì€ ì¤„ë“¤ ì²˜ë¦¬
    if current_chunk_lines:
        chunks.append("\n".join(current_chunk_lines))
    
    return chunks


def log_debug(msg: str):
    """Explicitly write to debug.log for external monitoring"""
    print(msg)
    try:
        from config import config
        from datetime import datetime
        with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as f:
            f.write(f"[{datetime.now()}] {msg}\n")
    except:
        pass

class AutoPilotService:
    def __init__(self):
        self.search_url = f"{config.YOUTUBE_BASE_URL}/search"
        self.config = {}  # Director Mode Configuration
        self.is_batch_running = False # [NEW] Batch Concurrency Lock

    async def run_workflow(self, keyword: str, project_id: int = None, config_dict: dict = None):
        """ì˜¤í† íŒŒì¼ëŸ¿ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        print(f"ğŸš€ [Auto-Pilot] '{keyword}' ì‘ì—… ì‹œì‘")
        start_dt = datetime.now()
        db.update_project_setting(project_id, "stats_start_time", start_dt.strftime("%Y-%m-%d %H:%M:%S"))
        
        self.config = config_dict or {}
        if "auto_plan" not in self.config:
            self.config["auto_plan"] = True  # Always generate plan data by default
        
        # [NEW] TopView Commerce Mode Check
        creation_mode = self.config.get("creation_mode", "default")
        if creation_mode == "commerce":
            return await self._run_topview_workflow(project_id, self.config)
        
        try:
            # 1~2. ì†Œì¬ ë°œêµ´ ë° í”„ë¡œì íŠ¸ ìƒì„±
            log_debug(f"âš™ï¸ [Auto-Pilot] Start run_workflow for project {project_id} (Keyword: {keyword})")
            start_dt = datetime.now()
            
            # [FIX] Load latest project settings BEFORE modifying self.config
            if project_id:
                p_settings = db.get_project_settings(project_id) or {}
                # Update self.config with DB settings
                if config_dict:
                    p_settings.update(config_dict)
                self.config = p_settings
            else:
                self.config = config_dict or {}
            
            # Force all_video if needed
            if self.config.get("all_video"):
                 log_debug(f"ğŸ”‹ [Auto-Pilot] all_video flag detected in config for PID {project_id}")

            if not project_id:
                video = await self._find_best_material(keyword)
                if not video: return
                project_name = f"[Auto] {keyword} - {video['snippet']['title'][:20]}"
                project_id = db.create_project(name=project_name, topic=keyword)
                db.update_project(project_id, status="created")
                current_status = "created"
            else:
                project = db.get_project(project_id)
                current_status = project.get('status', 'created')

            # 3. AI ë¶„ì„
            if current_status in ["created", "draft"]:
                db.update_project(project_id, status="analyzing") # [NEW] status for UI
                video = await self._find_best_material(keyword)
                analysis_result = await self._analyze_video(video)
                db.save_analysis(project_id, video, analysis_result)
                db.update_project(project_id, status="analyzed")
                current_status = "analyzed"

            # 4. ê¸°íš ë° ëŒ€ë³¸ ì‘ì„±
            if current_status == "analyzed":
                db.update_project(project_id, status="planning") # [NEW] status for UI
                analysis = db.get_analysis(project_id)
                script = await self._generate_script(project_id, analysis.get("analysis_result", {}), self.config)
                db.update_project_setting(project_id, "script", script)
                
                db.update_project(project_id, status="scripting") # [NEW] status for UI
                # [NEW] AI ì œëª© ë° ì„¤ëª… ìƒì„±
                await self._generate_metadata(project_id, script)
                
                db.update_project(project_id, status="scripted")
                current_status = "scripted"

            # [RE-SYNC] Webtoon mode transition: if it's queued/scripted but came from webtoon studio
            if current_status in ["queued", "scripted", "scripting"]:
                # Check if we have image prompts but no videos
                prompts = db.get_image_prompts(project_id)
                if prompts:
                    current_status = "characters_ready"
                    print(f"ğŸï¸ [Auto-Pilot] Found existing image prompts. Moving to Asset Generation.")

            # 4.5 ìºë¦­í„° ì¶”ì¶œ (ì¼ê´€ì„± ìœ ì§€ìš©)
            if current_status == "scripted":
                script_data = db.get_script(project_id)
                if script_data:
                    await self._extract_characters(project_id, script_data["full_script"], self.config)
                current_status = "characters_ready"

            # 5. ì—ì…‹ ìƒì„± (ì´ë¯¸ì§€ & ì¸ë„¤ì¼ & ì˜¤ë””ì˜¤)
            if current_status == "characters_ready":
                script_data = db.get_script(project_id)
                full_script = script_data["full_script"]
                
                # 5-1. ì˜ìƒ ì†ŒìŠ¤ ìƒì„±
                db.update_project(project_id, status="generating_assets")
                # [FIX] Force all_video=True to ensure dynamic assets (Wan/Akool) are used
                self.config["all_video"] = True 
                await self._generate_assets(project_id, full_script, self.config)
                
                # [NEW] Ensure Metadata exists (Title, Description) - Re-run if skipped earlier
                settings = db.get_project_settings(project_id) or {}
                if not settings.get('title') or not settings.get('description'):
                    print(f"ğŸ“ [Auto-Pilot] Metadata missing for pid {project_id}. Generating...")
                    await self._generate_metadata(project_id, full_script)

                # 5-2. [NEW] ì¸ë„¤ì¼ ìë™ ìƒì„±
                if self.config.get('auto_thumbnail', True):
                    # Check if already exists to avoid duplicate gen
                    if not settings.get('thumbnail_url'):
                        db.update_project(project_id, status="generating_thumbnail")
                        await self._generate_thumbnail(project_id, full_script, self.config)

                db.update_project(project_id, status="tts_done")
                current_status = "tts_done"

            # 6. ì˜ìƒ ë Œë”ë§
            if current_status == "tts_done":
                await self._render_video(project_id)
                current_status = "rendered"

            # 7. ì—…ë¡œë“œ
            if current_status == "rendered":
                settings = db.get_project_settings(project_id)
                video_path = settings.get("video_path")
                if video_path:
                    abs_video_path = os.path.join(config.OUTPUT_DIR, video_path.replace("/output/", ""))
                    if os.path.exists(abs_video_path):
                        await self._upload_video(project_id, abs_video_path)
                        db.update_project(project_id, status="uploaded")
            
            # [NEW] Save Stats
            end_dt = datetime.now()
            duration_str = str(end_dt - start_dt).split('.')[0]
            db.update_project_setting(project_id, "stats_end_time", end_dt.strftime("%Y-%m-%d %H:%M:%S"))
            db.update_project_setting(project_id, "stats_total_duration", duration_str)
            
            db.update_project(project_id, status="done")
            print(f"âœ¨ [Auto-Pilot] ì‘ì—… ì™„ë£Œ! (ID: {project_id}, Time: {duration_str})")

        except Exception as e:
            import traceback
            err_details = traceback.format_exc()
            print(f"âŒ [Auto-Pilot] ì˜¤ë¥˜ ë°œìƒ: {e}")
            print(err_details)
            
            try:
                with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                    df.write(f"[{datetime.now()}] âŒ [Auto-Pilot] CRITICAL ERROR in run_workflow:\n{err_details}\n")
            except: pass
            
            db.update_project(project_id, status="error")

    async def _extract_characters(self, project_id: int, script_text: str, config_dict: dict = None):
        """ëŒ€ë³¸ì—ì„œ ìºë¦­í„° ì¶”ì¶œ ë° ì¼ê´€ì„± ìˆëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ê±´ë„ˆëœ€)"""
        # [NEW] ì´ë¯¸ ìºë¦­í„°ê°€ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        existing = db.get_project_characters(project_id)
        if existing:
            print(f"ğŸ‘¥ [Auto-Pilot] ì´ë¯¸ {len(existing)}ëª…ì˜ ìºë¦­í„°ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        print(f"ğŸ‘¥ [Auto-Pilot] ìºë¦­í„° ì¶”ì¶œ ì‹œì‘...")
        
        # [NEW] ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ ê²°ì •
        style_prefix = "photorealistic"
        if config_dict:
            image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))
            style_presets = db.get_style_presets()
            style_data = style_presets.get(image_style_key, {})
            style_prefix = style_data.get("prompt_value", "photorealistic")
        
        try:
            characters = await gemini_service.generate_character_prompts_from_script(script_text, visual_style=style_prefix)
            if characters:
                db.save_project_characters(project_id, characters)
                print(f"âœ… [Auto-Pilot] {len(characters)}ëª…ì˜ ìºë¦­í„°ë¥¼ ì‹ë³„í•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤. (Style: {style_prefix})")
                
                # [NEW] ìºë¦­í„° ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ë° ì ìš© (ìµœëŒ€ 3ëª…)
                processed_chars = characters[:3]
                has_applied_reference = False
                
                for idx, char in enumerate(processed_chars):
                    try:
                        print(f"ğŸ‘¤ [Auto-Pilot] ìºë¦­í„° '{char['name']}' ({char['role']}) ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
                        detailed_style = style_data.get('prompt_value', style_prefix)
                        full_prompt = f"{char['prompt_en']}, {detailed_style}"
                        
                        # Portrait aspect ratio 1:1
                        images_bytes = await gemini_service.generate_image(
                            prompt=full_prompt,
                            num_images=1,
                            aspect_ratio="1:1"
                        )
                        
                        if images_bytes:
                            now = config.get_kst_time()
                            filename = f"char_{project_id}_{idx}_{now.strftime('%H%M%S')}.png"
                            file_path = os.path.join(config.OUTPUT_DIR, filename)
                            web_url = f"/output/{filename}"
                            
                            with open(file_path, "wb") as f:
                                f.write(images_bytes[0])
                            
                            # DB ì—…ë°ì´íŠ¸
                            db.update_character_image(project_id, char['name'], web_url)
                            
                            # [í•µì‹¬] ì£¼ì¸ê³µì´ê±°ë‚˜ ì²« ë²ˆì§¸ ìºë¦­í„°ì¸ ê²½ìš° í”„ë¡œì íŠ¸ ë ˆí¼ëŸ°ìŠ¤ë¡œ ìë™ ì ìš© (Apply ë²„íŠ¼ íš¨ê³¼)
                            is_protagonist = "ì£¼ì¸ê³µ" in char.get("role", "")
                            if not has_applied_reference:
                                if is_protagonist or (idx == len(processed_chars) - 1) or (idx == 0 and len(processed_chars) == 1):
                                    db.update_project_setting(project_id, "character_ref_text", char['prompt_en'])
                                    db.update_project_setting(project_id, "character_ref_image_path", web_url)
                                    has_applied_reference = True
                                    print(f"âœ¨ [Auto-Pilot] ì£¼ì¸ê³µ '{char['name']}'ì„(ë¥¼) ìºë¦­í„° ë ˆí¼ëŸ°ìŠ¤ë¡œ ì ìš©í–ˆìŠµë‹ˆë‹¤.")
                        
                    except Exception as char_e:
                        print(f"âš ï¸ [Auto-Pilot] ìºë¦­í„° '{char['name']}' ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {char_e}")

        except Exception as e:
            print(f"âš ï¸ [Auto-Pilot] ìºë¦­í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    async def _generate_metadata(self, project_id: int, script_text: str):
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì œëª©, ì„¤ëª…, íƒœê·¸ ìƒì„±"""
        print(f"ğŸ“ [Auto-Pilot] ì œëª© ë° ì„¤ëª… ìƒì„± ì‹œì‘...")
        try:
            metadata = await gemini_service.generate_video_metadata(script_text)
            if metadata:
                db.update_project_setting(project_id, "title", metadata.get("title"))
                db.update_project_setting(project_id, "description", metadata.get("description"))
                db.update_project_setting(project_id, "hashtags", ",".join(metadata.get("tags", [])))
                print(f"âœ… [Auto-Pilot] ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ: {metadata.get('title')}")
        except Exception as e:
            print(f"âš ï¸ [Auto-Pilot] ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")

    async def _find_best_material(self, keyword: str):
        params = {
            "part": "snippet", "q": keyword, "type": "video",
            "maxResults": 3, "order": "relevance", "videoDuration": "short",
            "key": config.YOUTUBE_API_KEY
        }
        async with httpx.AsyncClient() as client:
            response = await client.get(self.search_url, params=params)
            data = response.json()
            return data["items"][0] if "items" in data and data["items"] else None

    async def _analyze_video(self, video_data: dict):
        video_id = video_data['id']['videoId']
        title = video_data['snippet']['title']
        description = video_data['snippet']['description']
        
        prompt = f"""
        ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì˜ìƒì„ ìœ„í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        [ì˜ìƒ ì •ë³´]
        - ì œëª©: {title}
        - ID: {video_id}
        - ì„¤ëª…: {description[:500]}
        
        ì´ ì˜ìƒì˜ í•µì‹¬ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤, ì£¼ìš” ë‚´ìš©, ê·¸ë¦¬ê³  ì´ë¥¼ ë²¤ì¹˜ë§ˆí‚¹í–ˆì„ ë•Œ ëŒ€ì¤‘ë“¤ì´ ì¢‹ì•„í• ë§Œí•œ 'ê³µê° í¬ì¸íŠ¸'ë¥¼ 3ê°€ì§€ë§Œ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ì£¼ì„¸ìš”.
        
        JSON í¬ë§·:
        {{
            "sentiment": "positive/negative/neutral",
            "topics": ["ì£¼ì œ1", "ì£¼ì œ2"],
            "viewer_needs": "ì‹œì²­ìë“¤ì´ ì›í•˜ëŠ” ê²ƒ ì„¤ëª…"
        }}
        JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """
        result_text = await gemini_service.generate_text(prompt, temperature=0.7)
        try:
            import re
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            return json.loads(json_match.group()) if json_match else {"summary": result_text}
        except: return {"summary": result_text}

    async def _generate_script(self, project_id: int, analysis: dict, config_dict: dict):
        style_key = config_dict.get("script_style", "default")
        # Get script style description from DB presets if exists
        script_presets = db.get_script_style_presets()
        style_desc = script_presets.get(style_key, f"Style: {style_key}")

        # [NEW] Check for Manual Planning (Script Structure)
        manual_plan = db.get_script_structure(project_id)

        # [AUTO-PLAN] If auto_plan is requested AND no manual plan exists, generate one now
        if not (manual_plan and manual_plan.get("structure")) and config_dict.get("auto_plan"):
             print(f"ğŸ¤– [Auto-Pilot] ìë™ ê¸°íš ìƒì„± ì‹œì‘...")
             try:
                  target_duration_min = config_dict.get("duration_seconds", 300) // 60
                  struct_prompt = f"""
Create a structured plan for a YouTube video based on this analysis.
Analysis: {json.dumps(analysis, ensure_ascii=False)}

Context:
- Video Topic: {db.get_project(project_id).get('topic')}
- Script Style: {style_desc}
- Target Duration: {target_duration_min} minutes

Required Format (JSON Only):
{{
  "hook": "Strong opening sentence to grab attention",
  "sections": [
    {{ "title": "Section Title", "key_points": ["point1", "point2"] }}
  ],
  "cta": "Conclusion and call to action",
  "style": "{style_key}",
  "duration": {target_duration_min}
}}
Language: Korean
Style Guide: Narration/Monologue only. NO dialogue between characters.
"""
                  # request_s = type('obj', (object,), {"prompt": struct_prompt, "temperature": 0.7})
                  result_text_s = await gemini_service.generate_text(struct_prompt, temperature=0.7)
                  
                  import re
                  match = re.search(r'\{[\s\S]*\}', result_text_s)
                  if match:
                      new_struct = json.loads(match.group())
                      # Ensure style and duration are set if AI missed them
                      if "style" not in new_struct: new_struct["style"] = style_key
                      if "duration" not in new_struct: new_struct["duration"] = target_duration_min
                      
                      db.save_script_structure(project_id, new_struct)
                      manual_plan = {"structure": new_struct} # Update local var to trigger next block
                      print(f"âœ… [Auto-Pilot] ìë™ ê¸°íš ì™„ë£Œ ë° ì €ì¥. (Duration: {target_duration_min}m)")
             except Exception as e:
                 print(f"âš ï¸ [Auto-Pilot] ìë™ ê¸°íš ì‹¤íŒ¨: {e}")
        
        if manual_plan and manual_plan.get("structure"):
            print(f"ğŸ“„ [Auto-Pilot] ìˆ˜ë™ ê¸°íš ë°ì´í„° ë°œê²¬! ê¸°íš ê¸°ë°˜ ëŒ€ë³¸ ì‘ì„± ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            plan_json = json.dumps(manual_plan.get("structure"), ensure_ascii=False)
            
            prompt = f"""You are a professional YouTube scriptwriter.
Write a full script based strictly on the following USER PLANNED STRUCTURE.

[User Plan & Title]
{plan_json}

[Reference Analysis]
{json.dumps(analysis, ensure_ascii=False)}

[Instructions]
1. You MUST follow the 'User Plan' structure (Hook, Body, Conclusion, etc).
2. The 'structure' contains specific Hooks and plot points selected by the user. Do NOT change them.
3. Use the 'Reference Analysis' only to enrich the content details.
4. Voice: Strictly SINGLE SPEAKER Narration or Monologue. 
5. NO DIALOGUE: Do not write conversations between different people (No "A: Hello, B: Hi").
6. Output the full script in Korean.

[Absolute Rules for TTS]
- NO character names or colons (e.g., "Narrator:", "Me:").
- NO parentheses or situational descriptions (e.g., "(music)", "(laughs)").
- NO special characters or emojis.
"""
            if style_key != "default":
                prompt += f"\n\n[Writing Style Directive]: {style_desc}\nApply this style strictly."
        else:
            # Original Logic
            prompt = prompts.AUTOPILOT_GENERATE_SCRIPT.format(
                analysis_json=json.dumps(analysis, ensure_ascii=False)
            )
            if style_key != "default":
                prompt += f"\n\n[Writing Style Directive]: {style_desc}\nApply this style strictly throughout the script."

        # request = type('obj', (object,), {"prompt": prompt, "temperature": 0.8})
        script = await gemini_service.generate_text(prompt, temperature=0.8)
        
        # [CRITICAL] 4ê°€ì§€ ê¸ˆì§€ í•­ëª© ì •ì œ (ê´„í˜¸, íƒ€ì„ìŠ¤íƒ¬í”„, ì´ëª¨í‹°ì½˜, í™”ì í‘œì‹œ)
        import re
        if script:
            # 1. ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ë‚´ìš© ì‚­ì œ (ì˜ˆ: (ë°°ê²½ìŒì•…), (ì›ƒìŒ))
            script = re.sub(r'\([^)]*\)', '', script)
            # 2. íƒ€ì„ìŠ¤íƒ¬í”„ ë° ì‹œê°„ëŒ€ ì‚­ì œ (ì˜ˆ: [0-5ì´ˆ], [00:15])
            script = re.sub(r'\[[^\]]*\]', '', script)
            # 3. ë³„í‘œ ë° ê¾¸ë°ˆ ê¸°í˜¸ ì‚­ì œ (**)
            script = re.sub(r'\*', '', script)
            # 4. ì´ëª¨í‹°ì½˜ ë° íŠ¹ìˆ˜ ê¸°í˜¸ ì‚­ì œ (ğŸ¤£, âœ¨, ğŸ”¥ ë“±)
            script = re.sub(r'[^\w\s\d,.\?\!\"\'\. ]', '', script)
            # 5. í™”ì í‘œì‹œ ì‚­ì œ (ì˜ˆ: ë‚˜:, ìƒì‚¬:, A:) - ë¬¸ì¥ ì‹œì‘ ë¶€ë¶„ì˜ ì´ë¦„ê³¼ ì½œë¡ 
            script = re.sub(r'^[ê°€-í£\w\s]+[\s]*:[\s]*', '', script, flags=re.MULTILINE)
            # 6. ë¶ˆí•„ìš”í•œ ê³µë°± ë° ë¹ˆ ì¤„ ì •ë¦¬
            script = script.strip()
            script = re.sub(r'\n\s*\n', '\n', script)

        # Save script
        # Calculate approximate duration (char count / 15 chars per sec is rough, usually 5 chars/sec for speech)
        # Using a safer estimate provided by user input usually, but here auto-calc
        target_duration_sec = config_dict.get("duration_seconds", 300) 
        db.save_script(project_id, script, len(script), target_duration_sec)
        
        return script

    async def _generate_assets(self, project_id: int, script: str, config_dict: dict):
        all_video = config_dict.get("all_video", False)
        motion_method = config_dict.get("motion_method", "standard")
        video_engine = config_dict.get("video_engine", "wan")
        image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))

        
        # Determine sequence duration based on method
        video_duration = 5.0
        if motion_method in ["extend", "slowmo"]:
            video_duration = 8.0

        # Get visual style prompt from presets
        style_presets = db.get_style_presets()
        style_data = style_presets.get(image_style_key, {})

        style_prefix = style_data.get("prompt_value", "photorealistic")
        
        # 1. Image Prompts
        # [CRITICAL FIX] Use actual target duration for image count calculation
        target_duration = config_dict.get("duration_seconds", 300)
        
        image_prompts = db.get_image_prompts(project_id)
        if not image_prompts:
            print(f"ğŸ–¼ï¸ [Auto-Pilot] Generating image prompts for {target_duration}s video...")
            # [NEW] ìºë¦­í„° ì •ë³´ ì¡°íšŒ ë° ì „ë‹¬
            characters = db.get_project_characters(project_id)
            image_prompts = await gemini_service.generate_image_prompts_from_script(script, target_duration, style_prefix, characters=characters)
            db.save_image_prompts(project_id, image_prompts)
            image_prompts = db.get_image_prompts(project_id)
            print(f"ğŸ–¼ï¸ [Auto-Pilot] Generated {len(image_prompts)} image prompts")

        # Determine how many scenes to make as video
        log_debug(f"ğŸ” [DEBUG] _generate_assets START: all_video={all_video}, motion_method={motion_method}")
        
        if all_video:
            video_scene_count = len(image_prompts)
            log_debug(f"ğŸ¬ [Auto-Pilot] 'ALL VIDEO' mode enabled. Generating {video_scene_count} video scenes.")
        else:
            video_scene_count = config_dict.get("video_scene_count", 0)
            log_debug(f"ğŸ¬ [Auto-Pilot] Video scene count set to: {video_scene_count}")
        
        # [NEW] Force loud debug for all_video to see if it's really working
        if all_video or video_scene_count > 0:
             log_debug(f"ğŸš€ğŸš€ğŸš€ [DYNAMO] VIDEO GENERATION IS ACTIVE! Count: {video_scene_count}, Engine: {video_engine} ğŸš€ğŸš€ğŸš€")

        # 2. Assets (Video/Image)
        from services.replicate_service import replicate_service
        async def process_scene(p, is_video: bool):
            scene_num = p.get("scene_number")
            if p.get("image_url") and not (is_video and not p.get("video_url")): 
                # Already has image, and if video requested, check if video exists
                if not (is_video and not p.get("video_url")):
                    return True
            
            prompt_en = p.get("prompt_en", "cinematic scene")
            now = config.get_kst_time()
            try:
                # Generate base image if not exists
                image_abs_path = None
                if p.get("image_url") and p.get("image_url").startswith("/output/"):
                    image_abs_path = os.path.join(config.OUTPUT_DIR, p.get("image_url").replace("/output/", ""))
                
                if not image_abs_path or not os.path.exists(image_abs_path):
                    # [CRITICAL] Determine aspect ratio based on Mode (Shorts vs Longform)
                    duration_sec = config_dict.get("duration_seconds", 300)
                    mode = config_dict.get("mode", "longform")
                    
                    if mode == "shorts":
                        aspect_ratio = "9:16"
                    elif mode == "longform":
                        aspect_ratio = "16:9"
                    else:
                        # Fallback to duration threshold
                        aspect_ratio = "16:9" if (duration_sec and duration_sec >= 60) else "9:16"
                    
                    print(f"ğŸ¨ [Auto-Pilot] Generating image for Scene {scene_num} (Mode: {mode}, Duration: {duration_sec}s, Aspect Ratio: {aspect_ratio})")
                    images = await gemini_service.generate_image(prompt_en, aspect_ratio=aspect_ratio)

                    if not images: return False
                    
                    filename = f"img_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.png"
                    image_abs_path = os.path.join(config.OUTPUT_DIR, filename)
                    with open(image_abs_path, 'wb') as f: f.write(images[0])
                    db.update_image_prompt_url(project_id, scene_num, f"/output/{filename}")
                
                return True # Image only path success
            except Exception as e:
                print(f"âš ï¸ [Auto-Pilot] Scene {scene_num} Asset Gen Error: {e}")
            return False

        # Pass 1: Image Generation (Ensure all scenes have base images)
        print("ğŸ–¼ï¸ [Auto-Pilot] Pass 1: Generating Base Images...")
        for i, p in enumerate(image_prompts):
            db.update_project(project_id, status=f"images_{i+1}/{len(image_prompts)}")
            await process_scene(p, False) # Only images in Pass 1

        # [CRITICAL] Re-fetch image_prompts from DB to get updated image_url paths
        image_prompts = db.get_image_prompts(project_id)

        # Pass 2: TTS Generation (Collected for each scene)
        print("ğŸ™ï¸ [Auto-Pilot] Pass 2: Generating Scene-based TTS...")
        db.update_project(project_id, status="generating_tts")
        provider = config_dict.get("voice_provider")
        voice_id = config_dict.get("voice_id")
        
        sorted_prompts = sorted(image_prompts, key=lambda x: x.get('scene_number', 0))
        
        if not provider or not voice_id:
             p_settings = db.get_project_settings(project_id) or {}
             provider = p_settings.get("voice_provider")
             voice_id = p_settings.get("voice_id") or p_settings.get("voice_name")
             
             # Fallback logic: If any scene has SFX, prioritize ElevenLabs
             has_sfx = any(p.get("sound_effects") not in [None, 'None', 'Unknown'] for p in sorted_prompts)
             if not provider and has_sfx:
                 provider = "elevenlabs"
                 if not voice_id:
                     voice_id = "4JJwo477JUAx3HV0T7n7" # Default ElevenLabs voice
             
             # Ultimate Fallback
             if not provider: provider = "google_cloud"
             if not voice_id: voice_id = "ko-KR-Neural2-A"
        
        scene_audio_map = {} # scene_number -> local_audio_path
        scene_audio_files = []
        scene_durations = []
        all_alignments = []
        cumulative_audio_time = 0.0
        temp_audios = []
        used_voices = set() # [NEW] Track voices
        import uuid

        # [NEW] Load settings for overrides
        p_settings = db.get_project_settings(project_id) or {}

        for i, p in enumerate(sorted_prompts):
            db.update_project(project_id, status=f"tts_{i+1}/{len(sorted_prompts)}")
            text = p.get('scene_text') or p.get('narrative') or p.get('script') or ""
            scene_num = p.get('scene_number')
            
            # [NEW] Voice Override
            scene_voice = p_settings.get(f"scene_{scene_num}_voice")
            current_voice_id = scene_voice if scene_voice else voice_id
            # [NEW] Voice Settings (Stability, Speed)
            voice_settings = None
            vs_json = p_settings.get(f"scene_{scene_num}_voice_settings")
            if vs_json:
                try:
                    voice_settings = json.loads(vs_json)
                except:
                    pass

            if not text:
                scene_durations.append(3.0)
                cumulative_audio_time += 3.0
                continue

            scene_filename = f"temp_tts_{project_id}_{i}_{uuid.uuid4()}.mp3"
            
            try:
                if provider == "elevenlabs":
                    result = await tts_service.generate_elevenlabs(text, current_voice_id, scene_filename, voice_settings=voice_settings)
                    if result and result.get("audio_path"):
                        audio_path = result["audio_path"]
                        duration = result.get("duration", 3.0)
                        alignment = result.get("alignment", [])
                        
                        temp_audios.append(audio_path)
                        scene_audio_files.append(audio_path)
                        scene_audio_map[scene_num] = audio_path
                        scene_durations.append(duration)
                        
                        for word_info in alignment:
                            all_alignments.append({
                                "word": word_info["word"],
                                "start": word_info["start"] + cumulative_audio_time,
                                "end": word_info["end"] + cumulative_audio_time
                            })
                        cumulative_audio_time += duration
                    else:
                        print(f"âš ï¸ Scene {i} ElevenLabs TTS Failed. Using default.")
                        scene_durations.append(3.0)
                        cumulative_audio_time += 3.0
                else:
                    s_out = None
                    if provider == "openai": s_out = await tts_service.generate_openai(text, current_voice_id, model="tts-1", filename=scene_filename)
                    elif provider == "gemini": s_out = await tts_service.generate_gemini(text, current_voice_id, filename=scene_filename)
                    else: s_out = await tts_service.generate_google_cloud(text, current_voice_id, filename=scene_filename)
                    
                    if s_out and os.path.exists(s_out):
                        temp_audios.append(s_out)
                        scene_audio_files.append(s_out)
                        scene_audio_map[scene_num] = s_out
                        try:
                            try:
                                from moviepy import AudioFileClip
                            except ImportError:
                                from moviepy.audio.io.AudioFileClip import AudioFileClip
                                
                            ac = AudioFileClip(s_out)
                            dur = ac.duration
                            scene_durations.append(dur)
                            cumulative_audio_time += dur
                            ac.close()
                        except Exception as ae:
                            print(f"Audio check failed: {ae}")
                            scene_durations.append(3.0)
                            cumulative_audio_time += 3.0
                    else:
                        scene_durations.append(3.0)
                        cumulative_audio_time += 3.0

                # [NEW] Auto SFX Generation (if missing) 
                # First try to find in image_prompts (if column exists) or webtoon_scenes_json
                # [NEW] sfx_mapping_json ë¡œë“œ (ë£¨í”„ ë°–ì—ì„œ í•˜ë©´ ì¢‹ì§€ë§Œ, ì¤‘ë‹¨ ì¬ì‹œì‘ ê³ ë ¤í•˜ì—¬ ë§¤ë²ˆ ë¡œë“œ/ì €ì¥ ì•ˆì „í•˜ê²Œ)
                sfx_map_json = p_settings.get("sfx_mapping_json")
                sfx_mapping = {}
                if sfx_map_json:
                    try: sfx_mapping = json.loads(sfx_map_json)
                    except: pass
                
                # Check 1: Image Prompt Column 'sound_effects'
                s_desc = p.get('sound_effects')
                
                # Check 2: Webtoon JSON 'sound_effects' OR 'audio_direction'
                if not s_desc:
                    w_json = p_settings.get('webtoon_scenes_json')
                    if w_json:
                        try:
                            w_scenes = json.loads(w_json)
                            if i < len(w_scenes):
                                # Prioritize new audio_direction
                                ad = w_scenes[i].get('audio_direction', {})
                                if ad and ad.get('has_sfx') and ad.get('sfx_prompt'):
                                    s_desc = ad.get('sfx_prompt')
                                else:
                                    s_desc = w_scenes[i].get('sound_effects')
                        except: pass

                # Check if already generated in mapping
                # s_descê°€ ìˆê³ , ë§¤í•‘ì— ì—†ê±°ë‚˜ íŒŒì¼ì´ ì—†ì„ ë•Œ ìƒì„±
                sfx_exists = str(scene_num) in sfx_mapping
                if sfx_exists:
                    # íŒŒì¼ ì¡´ì¬ í™•ì¸
                    sfx_chk_path = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "sound", sfx_mapping[str(scene_num)])
                    if not os.path.exists(sfx_chk_path):
                        sfx_exists = False

                if not sfx_exists and s_desc and s_desc not in ['None', 'Unknown'] and len(s_desc) > 2:
                    try:
                        sfx_p_str = re.sub(r'[^\w\s,]', '', s_desc)
                        print(f"ğŸ”Š [Auto-Pilot] Generating SFX for scene {scene_num}: {sfx_p_str}")
                        sfx_d = await tts_service.generate_sound_effect(sfx_p_str[:100])
                        if sfx_d:
                            sfx_dr = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "sound")
                            os.makedirs(sfx_dr, exist_ok=True)
                            sfx_fn = f"sfx_scene_{scene_num:03d}_auto.mp3"
                            sfx_pth = os.path.join(sfx_dr, sfx_fn)
                            with open(sfx_pth, "wb") as f:
                                f.write(sfx_d)
                            
                            # Update Mapping and Save
                            sfx_mapping[str(scene_num)] = sfx_fn
                            db.update_project_setting(project_id, "sfx_mapping_json", json.dumps(sfx_mapping, ensure_ascii=False))
                            print(f"âœ… [Auto-Pilot] SFX Saved: {sfx_fn}")
                    except Exception as se:
                        print(f"âš ï¸ [Auto-Pilot] SFX Gen failed: {se}")

            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"âš ï¸ Scene {i} TTS Error: {e}")
                scene_durations.append(3.0)
                cumulative_audio_time += 3.0
        
        # All alignments ì €ì¥ (ë‚˜ì¤‘ì— ì •ë°€ ìë§‰ ìƒì„±ì— ì‚¬ìš©)
        if all_alignments:
            alignment_path = os.path.join(config.OUTPUT_DIR, f"tts_alignment_{project_id}.json")
            with open(alignment_path, "w", encoding="utf-8") as f:
                json.dump(all_alignments, f, ensure_ascii=False, indent=2)
            db.update_project_setting(project_id, "tts_alignment_path", alignment_path)
            print(f"âœ… [Auto-Pilot] Saved {len(all_alignments)} word alignments")
        
        # Merge Audios
        final_filename = f"auto_tts_{project_id}.mp3"
        final_audio_path = os.path.join(config.OUTPUT_DIR, final_filename)
        
        total_duration = 0.0
        if scene_audio_files:
            try:
                from moviepy.audio.AudioClip import concatenate_audioclips
                from moviepy.audio.io.AudioFileClip import AudioFileClip
                clips = [AudioFileClip(f) for f in scene_audio_files]
                final_clip = concatenate_audioclips(clips)
                final_clip.write_audiofile(final_audio_path, logger=None)
                
                total_duration = final_clip.duration
                final_clip.close()
                for c in clips: c.close()
                
                # DB Save
                db.save_tts(project_id, provider, voice_id, final_audio_path, total_duration)
                
                # [CRITICAL] Calculate Cumulative Start Timings for Frontend
                cumulative_starts = []
                current_time = 0.0
                for dur in scene_durations:
                    cumulative_starts.append(current_time)
                    current_time += dur
                
                # 1. Save Image Start Timings (Expects START TIMES for frontend sync)
                timings_path = os.path.join(config.OUTPUT_DIR, f"image_timings_{project_id}.json")
                with open(timings_path, "w", encoding="utf-8") as f:
                     json.dump(cumulative_starts, f)
                db.update_project_setting(project_id, "image_timings_path", timings_path)
                
                # 2. Save Initial Subtitles
                # [NEW] ElevenLabs alignment ì •ë³´ê°€ ìˆìœ¼ë©´ ì •ë°€ ìë§‰ ìƒì„±
                auto_subtitles = []
                
                if all_alignments:
                    # ë‹¨ì–´ íƒ€ì´ë°ì„ 2ì¤„ ìë§‰ìœ¼ë¡œ ë³€í™˜
                    auto_subtitles = self._alignment_to_subtitles(all_alignments, max_chars=25)
                    print(f"ğŸ“ [Auto-Pilot] Generated {len(auto_subtitles)} subtitles from TTS alignment (PRECISE)")
                else:
                    # ê¸°ì¡´ ë¡œì§: Scene ê¸°ë°˜ ê· ë“± ë¶„í• 
                    for i, p in enumerate(sorted_prompts):
                        if i >= len(cumulative_starts): break
                        text = p.get('scene_text') or p.get('narrative') or p.get('script') or ""
                        if not text:
                            continue
                        
                        chunks = split_text_to_subtitle_chunks(text, max_chars_per_line=20, max_lines=2)
                        if not chunks:
                            continue
                        
                        scene_start = cumulative_starts[i]
                        scene_duration = scene_durations[i]
                        chunk_duration = scene_duration / len(chunks)
                        
                        for j, chunk_text in enumerate(chunks):
                            chunk_start = scene_start + (j * chunk_duration)
                            chunk_end = chunk_start + chunk_duration
                            
                            auto_subtitles.append({
                                "text": chunk_text,
                                "start": round(chunk_start, 2),
                                "end": round(chunk_end, 2)
                            })
                    
                    print(f"ğŸ“ [Auto-Pilot] Generated {len(auto_subtitles)} subtitle segments (fallback mode)")
                
                sub_path = os.path.join(config.OUTPUT_DIR, f"subtitles_{project_id}.json")
                with open(sub_path, "w", encoding="utf-8") as f:
                    json.dump(auto_subtitles, f, ensure_ascii=False, indent=2)
                db.update_project_setting(project_id, "subtitle_path", sub_path)

                print(f"âœ… [Auto-Pilot] Scene-based TTS & Subtitles Complete. Total: {total_duration:.2f}s, Scenes: {len(scene_durations)}")
                
                # [NEW] Save Stats
                db.update_project_setting(project_id, "stats_audio_duration_sec", f"{total_duration:.2f}")
                db.update_project_setting(project_id, "stats_used_voices", json.dumps(list(used_voices), ensure_ascii=False))
                
            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"âŒ Audio Merge Failed: {e}")
                # Fallback to single file gen logic if merge fails?
        else:
             print("âŒ No audio generated.")
        
        # [NEW] Pass 3: Video Generation (Now we have both Images and Audio)
        log_debug(f"ğŸ“¹ [Auto-Pilot] Pass 3: Generating Video Components... Count: {video_scene_count}, Engine: {video_engine}")
        from services.akool_service import akool_service

        # Re-fetch prompts to get latest image/audio URLs
        image_prompts = db.get_image_prompts(project_id)
        p_settings = db.get_project_settings(project_id) or {} # [NEW] Load settings
        
        for i, p in enumerate(image_prompts):
            is_vid = i < video_scene_count
            log_debug(f"  > Scene {p.get('scene_number')}: is_vid={is_vid}, has_image={bool(p.get('image_url'))}")
            if not is_vid: continue
            
            scene_num = p.get("scene_number")
            db.update_project(project_id, status=f"videos_{i+1}/{video_scene_count}")
            
            image_url = p.get("image_url")
            if not image_url: continue
            image_abs_path = os.path.join(config.OUTPUT_DIR, image_url.replace("/output/", ""))
            
            # [FIX] Skip re-generation if video already exists (e.g. generated on image gen page)
            existing_video_url = p.get("video_url")
            if existing_video_url:
                existing_video_path = os.path.join(config.OUTPUT_DIR, existing_video_url.replace("/output/", ""))
                if os.path.exists(existing_video_path):
                    print(f"  â­ï¸ [Auto-Pilot] Scene {scene_num}: Video already exists â†’ SKIP re-generation. ({os.path.basename(existing_video_path)})")
                    continue  # Use existing video, don't regenerate
                else:
                    print(f"  âš ï¸ [Auto-Pilot] Scene {scene_num}: video_url set but file missing â†’ Regenerating.")

            
            now = config.get_kst_time()
            
            # [Smart Engine Switch]
            scene_text = p.get("scene_text", "").strip()
            has_dialogue = bool(scene_text and len(scene_text) > 1 and scene_text != "None")
            
            # [NEW] Check LipSync Preference
            use_lipsync_val = p_settings.get("use_lipsync")
            use_lipsync = True
            if use_lipsync_val is not None:
                if isinstance(use_lipsync_val, str): use_lipsync = (use_lipsync_val.lower() == 'true' or use_lipsync_val == '1')
                else: use_lipsync = bool(use_lipsync_val)
            try:
                # [SMART ENGINE SWITCH]
                # Priority:
                # 1. Manual Override (from planning/settings)
                # 2. Logic (Dialogue + Lipsync -> Akool, else -> Wan)
                
                manual_engine = p_settings.get(f"scene_{scene_num}_engine")
                if manual_engine in ["wan", "akool", "image"]:
                    local_engine = manual_engine
                    print(f"ğŸ¯ [Manual Override] Scene {scene_num} -> {local_engine}")
                else:
                    local_engine = "akool" if (has_dialogue and use_lipsync) else "wan"
                
                # [EXPERIMENTAL] ê±´ë„ˆë›°ê¸° ë¡œì§ ë³´ì™„ -> [UPDATED] Image ì—”ì§„ë„ ë¹„ë””ì˜¤ íŒŒì¼ ìƒì„± (2D Pan/Zoom)
                if local_engine == "image":
                    print(f"ğŸ–¼ï¸ [Image-Only] Scene {scene_num} using 2D Pan/Zoom Motion...")
                    # Motion type determined by manual override or default 'zoom_in'
                    motion_type = p_settings.get(f"scene_{scene_num}_motion", "zoom_in")
                    
                    # [NEW] Webtoon Settings from DB (Global Preference)
                    # p_settings might have project specific override, but for now we trust Global Settings
                    # Default: True
                    w_auto = db.get_global_setting("webtoon_auto_split", True, value_type="bool")
                    w_pan = db.get_global_setting("webtoon_smart_pan", True, value_type="bool")
                    w_zoom = db.get_global_setting("webtoon_convert_zoom", True, value_type="bool")

                    # Create 2D Motion Video
                    motion_bytes = await video_service.create_image_motion_video(
                        image_path=image_abs_path,
                        duration=video_duration,
                        motion_type=motion_type,
                        width=1080, height=1920, # Default vertical shorts
                        auto_split=w_auto,
                        smart_pan=w_pan,
                        convert_zoom=w_zoom
                    )
                    
                    if motion_bytes:
                        filename = f"vid_img_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                        out = os.path.join(config.OUTPUT_DIR, filename)
                        with open(out, 'wb') as f: f.write(motion_bytes)
                        db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
                    continue

                # [USER MASTER SETTING APPLIED]
                # GEMINIê°€ ë¶„ì„í•œ motion_desc(ì‚¬ìš©ì ì›ì¹™ì´ ë°˜ì˜ëœ ìƒì„¸ ì§€ì¹¨)ë¥¼ ìš°ì„  ì‚¬ìš©
                base_visual = p.get('motion_desc') or p.get('prompt_en') or p.get('visual_desc') or "Cinematic motion"
                manual_motion_desc = p_settings.get(f"scene_{scene_num}_motion_desc")
                
                if local_engine == "wan":
                    if manual_motion_desc:
                        # ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ ì…ë ¥í•œ ëª¨ì…˜ ë¬˜ì‚¬ê°€ ìˆìœ¼ë©´ ê²°í•©
                        final_prompt = f"{base_visual}, {manual_motion_desc}"
                        print(f"ğŸ”¥ [Wan Content Motion Override] Scene {scene_num}: {manual_motion_desc}")
                    else:
                        # AIê°€ ìƒì„±í•œ motion_descë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì´ë¯¸ ì¶©ë¶„íˆ ìƒì„¸í•¨)
                        final_prompt = base_visual
                        print(f"ğŸ¬ [Wan Production Prompt] Scene {scene_num}: {final_prompt[:100]}...")
                    
                    # ì¹´ë©”ë¼ ì´ë™ ì¶”ê°€
                    manual_motion = p_settings.get(f"scene_{scene_num}_motion")
                    if manual_motion:
                        # [NEW] Webtoon Motion Prompt Integration
                        # Retrieve custom prompts from Global Settings
                        w_pan_prompt = db.get_global_setting("webtoon_motion_pan", "Slow upward cinematic camera pan, subtle 2.5D parallax depth effect, soft volumetric lighting, floating dust particles, epic dramatic atmosphere, smooth motion, no distortion")
                        w_zoom_prompt = db.get_global_setting("webtoon_motion_zoom", "Slow push-in camera movement, focus on characterâ€™s eyes, subtle breathing motion, soft rim lighting, cinematic depth of field, emotional atmosphere")
                        w_action_prompt = db.get_global_setting("webtoon_motion_action", "Strong parallax effect, embers floating in the air, light flicker from fire, slight cinematic camera shake, intense dramatic lighting, high energy atmosphere")

                        # Map standard motion keys to Webtoon Styles
                        motion_map = {
                            "zoom_in": w_zoom_prompt,
                            "zoom_out": "dramatic zoom out", # Keep generic for now or map to zoom?
                            "pan_left": "cinematic pan left",
                            "pan_right": "cinematic pan right",
                            "pan_up": w_pan_prompt, # Map 'pan_up' to Vertical Pan style
                            "pan_down": w_pan_prompt, # Map 'pan_down' to Vertical Pan style
                            "tilt_up": w_pan_prompt,
                            "tilt_down": w_pan_prompt,
                            "shake": w_action_prompt, # Map 'shake' to Action style
                            "action": w_action_prompt, # Explicit 'action' key if used
                            "dynamic": w_action_prompt
                        }

                        if manual_motion in motion_map:
                            selected_prompt = motion_map[manual_motion]
                            final_prompt += f", {selected_prompt}"
                            print(f"ğŸ¬ [Wan Camera Move] Scene {scene_num}: {manual_motion} -> {selected_prompt[:50]}...")
                        else:
                            # Fallback for unmapped standard motions
                            final_prompt += f", {manual_motion.replace('_', ' ')} motion"
                else:
                    final_prompt = base_visual
                print(f"ğŸ¤– [Auto-Switch] Scene {scene_num}: Dialogue={has_dialogue} -> Engine={local_engine}")

                if local_engine == "akool":
                    audio_abs_path = scene_audio_map.get(scene_num)
                    if not audio_abs_path:
                        log_debug(f"âš ï¸ [Akool] No audio found for scene {scene_num}. Switching to Wan.")
                        local_engine = "wan" # Fallback if no audio
                    else:
                        try:
                            log_debug(f"ğŸ­ [Akool] Generating Talking Avatar for Scene {scene_num}...")
                            video_bytes = await akool_service.generate_talking_avatar(image_abs_path, audio_abs_path)
                            if video_bytes:
                                filename = f"vid_akool_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                                out = os.path.join(config.OUTPUT_DIR, filename)
                                with open(out, 'wb') as f: f.write(video_bytes)
                                db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
                                log_debug(f"âœ… [Akool] LipSync Success for Scene {scene_num}")
                        except Exception as ak_e:
                            log_debug(f"âš ï¸ [Akool] Error for scene {scene_num}: {ak_e}. Falling back to Wan...")
                            local_engine = "wan" # Fallback to Wan on Akool error
                
                    # Wan / Replicate (Enhanced for Camera Moves)
                    # [NEW] Dual Engine Support: Check User Preference
                    preferred_engine = p_settings.get("video_engine", "wan") # 'wan' or 'akool'
                    
                    if preferred_engine == "akool":
                        try:
                            print(f"ğŸ“¹ [Auto-Pilot] Generating Video via Akool I2V for Scene {scene_num}")
                            video_data = await akool_service.generate_i2v(image_abs_path, final_prompt)
                            
                            if video_data:
                                filename = f"vid_akool_i2v_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                                out = os.path.join(config.OUTPUT_DIR, filename)
                                with open(out, 'wb') as f: f.write(video_data)
                                db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
                                print(f"âœ… [Akool] I2V Success for Scene {scene_num}")
                            else:
                                raise Exception("Empty data returned from Akool I2V")
                                
                        except Exception as ak_i2v_e:
                            print(f"âš ï¸ [Akool] I2V Failed: {ak_i2v_e}. Fallback to Replicate(Wan)...")
                            # Fallback logic below (it will flow into Replicate block if we structure it right, 
                            # or we duplicate call here. Let's redirect to Replicate block)
                            preferred_engine = "wan" 

                    if preferred_engine == "wan":
                        # [FIX] Skip Wan for Vertical Pan scenes (preserve aspect ratio)
                        manual_motion = p_settings.get(f"scene_{scene_num}_motion")
                        if manual_motion in ["pan_down", "pan_up", "vertical_pan"]:
                            print(f"â© [Auto-Pilot] Scene {scene_num} is Vertical Pan ({manual_motion}). Skipping Wan to preserve full resolution.")
                            continue

                        try:
                            print(f"ğŸ“¹ [Auto-Pilot] Generating Wan Video for Scene {scene_num}")
                            
                            # [FIX] Use full original image for Wan 2.1 if available (prevents character cropping)
                            wan_asset_filename = p_settings.get(f"scene_{scene_num}_wan_image", "")
                            if wan_asset_filename:
                                wan_asset_dir = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "image")
                                wan_image_path = os.path.join(wan_asset_dir, wan_asset_filename)
                                if os.path.exists(wan_image_path):
                                    print(f"  ğŸ¯ [Wan] Using FULL original image: {wan_asset_filename}")
                                    wan_source_path = wan_image_path
                                else:
                                    wan_source_path = image_abs_path
                                    print(f"  âš ï¸ [Wan] wan_asset not found, fallback to sliced: {os.path.basename(image_abs_path)}")
                            else:
                                wan_source_path = image_abs_path
                                print(f"  â„¹ï¸ [Wan] No wan_asset configured. Using sliced panel: {os.path.basename(image_abs_path)}")
                            
                            video_data = await replicate_service.generate_video_from_image(
                                wan_source_path, 
                                prompt=final_prompt,
                                duration=video_duration,
                                method=motion_method
                            )
                            if video_data:
                                filename = f"vid_wan_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                                out = os.path.join(config.OUTPUT_DIR, filename)
                                with open(out, 'wb') as f: f.write(video_data)
                                db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
                                with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                                    df.write(f"[{datetime.now()}] âœ… Successfully generated Wan video for Scene {scene_num}\n")
                        except Exception as wan_e:
                            # [STRICT QUALITY CONTROL] User demands High-End Motion (Wan 2.1).
                            # Do NOT fall back to static 2D motion. Raise error to stop process until credits are refilled.
                            err_msg = f"âŒ [Wan] Critical Error: {wan_e} (Likely Insufficient Credits). Process halted to preserve quality."
                            print(err_msg)
                            raise wan_e # Rethrow to stop autopilot
            except Exception as ve:
                err_msg = f"âš ï¸ [Auto-Pilot] Video generation failed for Scene {scene_num}: {ve}"
                print(err_msg)
                with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                    df.write(f"[{datetime.now()}] {err_msg}\n")

        # [NEW] Pass 4: Finalize Timeline (AFTER video generation)
        print("ğŸï¸ [Auto-Pilot] Pass 4: Finalizing Timeline Mapping...")
        updated_prompts = db.get_image_prompts(project_id)
        sorted_updated = sorted(updated_prompts, key=lambda x: x.get('scene_number', 0))
        
        timeline_images = [p.get('video_url') or p.get('image_url') for p in sorted_updated]
        timeline_images = [img for img in timeline_images if img]
        
        tl_images_path = os.path.join(config.OUTPUT_DIR, f"timeline_images_{project_id}.json")
        with open(tl_images_path, "w", encoding="utf-8") as f:
            json.dump(timeline_images, f, ensure_ascii=False, indent=2)
        db.update_project_setting(project_id, "timeline_images_path", tl_images_path)
        print(f"âœ… [Auto-Pilot] Timeline Finalized with {len(timeline_images)} assets.")

        # Cleanup temps
        for f in temp_audios:
            try: os.remove(f)
            except: pass

    async def _generate_thumbnail(self, project_id: int, script: str, config_dict: dict):
        """ëŒ€ë³¸ ê¸°ë°˜ ì¸ë„¤ì¼ ìë™ ê¸°íš ë° ìƒì„±"""
        print(f"ğŸ¨ [Auto-Pilot] ì¸ë„¤ì¼ ìë™ ìƒì„± ì¤‘... Project: {project_id}")
        
        # 1. ì¸ë„¤ì¼ ê¸°íš (Hook & Visual Concept)
        hook_text = "Must Watch"
        visual_concept = "A high quality dramatic scene"
        
        try:
            # [NEW] Use the better prompt for hook text
            project_settings = db.get_project_settings(project_id) or {}
            image_style = config_dict.get("image_style") or project_settings.get("image_style", "realistic")
            thumb_style = config_dict.get("thumbnail_style") or project_settings.get("thumbnail_style", "face")
            
            # Get character info for better context
            characters = db.get_project_characters(project_id)
            char_context = ""
            if characters:
                char_names = [c.get("name") for c in characters if c.get("name")]
                char_context = f"\n[Featured Characters]: {', '.join(char_names)}"

            hook_prompt = prompts.GEMINI_THUMBNAIL_HOOK_TEXT.format(
                script=f"{script[:2000]}{char_context}",
                thumbnail_style=thumb_style,
                image_style=image_style,
                target_language="ko" # Default for now
            )
            
            hook_result = await gemini_service.generate_text(hook_prompt, temperature=0.7)
            import re
            json_match = re.search(r'\{[\s\S]*\}', hook_result)
            if json_match:
                hook_data = json.loads(json_match.group())
                candidates = hook_data.get("texts", [])
                if candidates:
                    hook_text = candidates[0] # Pick the strongest hook
            
            # [NEW] Generate a matching visual concept (Image Prompt)
            # Use THUMBNAIL_IDEA_PROMPT as a secondary pass or merge logic
            idea_prompt = prompts.THUMBNAIL_IDEA_PROMPT.format(
                topic=project_settings.get("topic", "AI Video"),
                script_summary=script[:1000]
            )
            idea_result = await gemini_service.generate_text(idea_prompt, temperature=0.7)
            json_match_idea = re.search(r'\{[\s\S]*\}', idea_result)
            if json_match_idea:
                idea_data = json.loads(json_match_idea.group())
                visual_concept = idea_data.get("image_prompt", visual_concept)
                
        except Exception as e:
            print(f"âš ï¸ [Auto-Pilot] Thumbnail Planning Error: {e}")
            # Fallback to project title if hook fails
            hook_text = project_settings.get("title", "Must Watch") if project_id else "Must Watch"

        # 2. ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        try:
            # [NEW] Art Style & Layout Inheritance
            image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))
            style_presets = db.get_style_presets()
            style_data = style_presets.get(image_style_key, {})
            style_prefix = style_data.get("prompt_value", "photorealistic")

            # [NEW] Layout Style
            thumbnail_style_key = config_dict.get("thumbnail_style", "face")
            thumb_presets = db.get_thumbnail_style_presets()
            thumb_preset = thumb_presets.get(thumbnail_style_key, {})
            layout_desc = thumb_preset.get("prompt", "")
            
            # [NEW] Character Incorporation
            characters = db.get_project_characters(project_id)
            char_desc = ""
            if characters:
                # Use the first 1-2 characters to keep prompt focused
                char_lines = []
                for c in characters[:2]:
                    char_lines.append(c.get("prompt_en", ""))
                char_desc = " Featuring: " + ", ".join(char_lines)
            
            # Combine everything for a consistent look
            final_thumb_prompt = f"ABSOLUTELY NO TEXT. Style: {style_prefix}. Composition: {layout_desc}. Subjects: {visual_concept}.{char_desc}. 8k, high quality."

            # [CRITICAL] Determine aspect ratio based on duration (Long-form vs Shorts)
            duration_sec = config_dict.get("duration_seconds", 300)
            aspect_ratio = "16:9" if duration_sec > 60 else "9:16"
            
            print(f"ğŸ¨ [Auto-Pilot] Generating thumbnail background. Style: {image_style_key}, Aspect: {aspect_ratio}")
            print(f"ğŸ“ Prompt: {final_thumb_prompt[:120]}...")
            
            images = None
            try:
                images = await gemini_service.generate_image(final_thumb_prompt, aspect_ratio=aspect_ratio)
            except Exception as e:
                msg = f"âŒ [Auto-Pilot] Thumbnail Image Gen Failed: {e}"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.now()}] {msg}\n")
                except: pass
                
                # [FALLBACK] Try a safe, generic prompt if the specific one was blocked
                print("ğŸ”„ [Auto-Pilot] Retrying with generic thumbnail prompt due to safety/filter...")
                generic_prompt = f"Minimal aesthetic abstract background, Style: {style_prefix}, 8k, high quality"
                try:
                    images = await gemini_service.generate_image(generic_prompt, aspect_ratio=aspect_ratio)
                except Exception as e2:
                    print(f"âŒ [Auto-Pilot] Final fallback failed: {e2}")
            
            if not images: 
                print("âš ï¸ [Auto-Pilot] No images generated for thumbnail. Skipping synthesis.")
                return

            now = config.get_kst_time()
            bg_filename = f"thumb_bg_{project_id}_{now.strftime('%H%M%S')}.png"
            bg_path = os.path.join(config.OUTPUT_DIR, bg_filename)
            with open(bg_path, 'wb') as f: f.write(images[0])
            
            # 3. í…ìŠ¤íŠ¸ í•©ì„± (ì €ì¥ëœ ì„¤ì • ë°˜ì˜)
            from services.thumbnail_service import thumbnail_service
            final_filename = f"thumbnail_{project_id}_{now.strftime('%H%M%S')}.jpg"
            final_path = os.path.join(config.OUTPUT_DIR, final_filename)
            
            # [PRIORITY 1] Check Autopilot Config / Project Settings for Explicit Style
            project_settings = db.get_project_settings(project_id) or {}
            requested_style = config_dict.get("thumbnail_style") or project_settings.get("thumbnail_style")
            
            text_layers = []
            
            if requested_style:
                text_layers = thumbnail_service.get_style_recipe(requested_style, hook_text)
            
            # [PRIORITY 2] Fallback to Project 1 Template
            elif (saved_thumb_data := db.get_thumbnails(1)) and saved_thumb_data.get("full_settings"):
                layers = saved_thumb_data["full_settings"].get("layers", [])
                
                # Find main text layer (biggest font size)
                main_layer_idx = 0
                max_size = 0
                for i, l in enumerate(layers):
                    fs = int(l.get("font_size", 0))
                    if fs > max_size:
                        max_size = fs
                        main_layer_idx = i
                
                # Copy and Replace Text
                import copy
                text_layers = copy.deepcopy(layers)
                if text_layers and len(text_layers) > main_layer_idx:
                     text_layers[main_layer_idx]["text"] = hook_text
            
            else:
                # [PRIORITY 3] Default Fallback
                text_layers = thumbnail_service.get_style_recipe("mystery", hook_text)

            success = thumbnail_service.create_thumbnail(bg_path, text_layers, final_path)
            
            if success:
                web_path = f"/output/{final_filename}"
                db.update_project_setting(project_id, "thumbnail_url", web_path)
                msg = f"âœ… [Auto-Pilot] ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ: {web_path}"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.now()}] {msg}\n")
                except: pass
            else:
                msg = "âŒ [Auto-Pilot] ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ í•©ì„± ì‹¤íŒ¨ (create_thumbnail returned False)"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.now()}] {msg}\n")
                except: pass
            
            try: os.remove(bg_path)
            except: pass
            
        except Exception as e:
            msg = f"âŒ [Auto-Pilot] ì¸ë„¤ì¼ ìƒì„± ì˜ˆì™¸: {e}"
            print(msg)
            try:
                with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                    df.write(f"[{datetime.now()}] {msg}\n")
            except: pass

    async def _render_video(self, project_id: int):
        images_data = db.get_image_prompts(project_id)
        tts_data = db.get_tts(project_id)
        script_data = db.get_script(project_id)
        settings = db.get_project_settings(project_id) or {}
        
        # 1. Load Subtitles (Prefer Saved)
        # 1. Load Subtitles (Prefer Saved)
        subs = []
        
        # [NEW] Check user preference for subtitles
        use_sub_val = settings.get("use_subtitles")
        use_subtitles = True # Default
        if use_sub_val is not None:
            if isinstance(use_sub_val, str): use_subtitles = (use_sub_val.lower() == 'true' or use_sub_val == '1')
            else: use_subtitles = bool(use_sub_val)

        if use_subtitles and tts_data:
            subtitle_path = settings.get("subtitle_path")
            if subtitle_path and os.path.exists(subtitle_path):
                try:
                    with open(subtitle_path, "r", encoding="utf-8") as f:
                        subs = json.load(f)
                except: pass
                
            if not subs:
                print("ğŸ” [Auto-Pilot] No saved subtitles found. Generating via Whisper...")
                try:
                    audio_path = tts_data["audio_path"]
                    subs = video_service.generate_aligned_subtitles(audio_path, script_data["full_script"])
                except Exception as sub_e: 
                    print(f"âš ï¸ Subtitle Gen Error: {sub_e}")
            
            if not subs: 
                subs = video_service.generate_smart_subtitles(script_data["full_script"], tts_data["duration"])
        elif not use_subtitles:
            print("ğŸš« [Auto-Pilot] Subtitles disabled manually.")
        else:
            print("âš ï¸ [Auto-Pilot] Cannot generate subtitles: TTS data missing.")

        # 2. Load Timeline Images
        # [FIX] Always use fresh DB data from image_prompts (includes video_url from Pass 3)
        # The timeline_images_path JSON file is created during Pass 2 (before video generation)
        # so it may not contain the latest video_url values.
        images = []
        sorted_prompts = sorted(images_data, key=lambda x: x.get('scene_number', 0))
        for img in sorted_prompts:
            # Priority: video_url (motion video) > wan_image (Original Tall) > image_url (Sliced Image)
            video_url = img.get("video_url")
            image_url = img.get("image_url")
            scene_num = img.get('scene_number')
            
            # [FIX] Check for forced original image (for Vertical Pan)
            wan_asset_filename = settings.get(f"scene_{scene_num}_wan_image")
            wan_path = None
            if wan_asset_filename:
                 wan_path_check = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "image", wan_asset_filename)
                 if os.path.exists(wan_path_check):
                     wan_path = wan_path_check

            best_path = None

            # Priority Logic Refined:
            # 1. Existing Video (video_url) -> Use generated video
            # 2. Vertical Pan (Type 1) -> Force Original Tall Image (wan_path) to allow scrolling if no video
            # 3. Sliced Panel (image_url) -> Use standard panel

            check_path = None
            manual_motion = settings.get(f"scene_{scene_num}_motion")
            is_vertical_pan = manual_motion in ["pan_down", "pan_up", "vertical_pan"]
            
            if not video_url:
                # [FIX] If DB fails to save video_url, directly check file system
                import glob
                manual_files = glob.glob(os.path.join(config.OUTPUT_DIR, f"vid_*_{project_id}_{scene_num}_*.mp4"))
                if manual_files:
                    manual_files.sort(key=os.path.getmtime, reverse=True)
                    video_url = manual_files[0]
                    print(f"ğŸ“¸ [Auto-Pilot] Scene {scene_num}: Found unlinked manual video: {os.path.basename(video_url)}")

            if video_url:
                if video_url.startswith("/output/"):
                    fpath = os.path.join(config.OUTPUT_DIR, video_url.replace("/output/", ""))
                else:
                    fpath = os.path.join(config.OUTPUT_DIR, video_url.split("/")[-1])
                
                if os.path.exists(fpath):
                    best_path = fpath
                    print(f"ğŸ“¸ [Auto-Pilot] Scene {scene_num}: Using VIDEO - {os.path.basename(fpath)}")
                    
            elif is_vertical_pan and wan_path:
                 best_path = wan_path
                 print(f"ğŸ“¸ [Auto-Pilot] Scene {scene_num}: Vertical Pan detected. FORCING Original Tall Image - {wan_asset_filename}")
            
            # Note: wan_path is usually the FULL original strip. 
            # If not panning, we should use the sliced panel (image_url) to focus on the specific cut.
            # So we do NOT fallback to wan_path unless it's a pan.

            if not best_path and image_url:
                 if image_url.startswith("/output/"):
                    fpath = os.path.join(config.OUTPUT_DIR, image_url.replace("/output/", ""))
                 else:
                    fpath = os.path.join(config.OUTPUT_DIR, image_url.split("/")[-1])
                 
                 if os.path.exists(fpath):
                     best_path = fpath
                     print(f"ğŸ“¸ [Auto-Pilot] Scene {scene_num}: Using Sliced Image (Fallback) - {os.path.basename(fpath)}")

            if best_path: 
                images.append(best_path)
                
        audio_path = tts_data["audio_path"] if tts_data else None
        output_filename = f"autopilot_{project_id}_{config.get_kst_time().strftime('%H%M%S')}.mp4"

        # [IMPROVED] Calculate Durations from Start Timings
        image_durations = 5.0 # Default fallback
        timings_path = settings.get("image_timings_path")
        
        smart_sync_enabled = False
        if tts_data and timings_path and os.path.exists(timings_path):
            try:
                with open(timings_path, "r", encoding="utf-8") as f:
                    loaded_starts = json.load(f)
                
                if loaded_starts:
                    # If the file contains DURATIONS (old format), we need to detect it.
                    # Usually start times begin with 0.0. 
                    # If there are many values and sum is > total_duration, then if it's start times, the last value would be < total_duration.
                    # Best check: Is it monotonically increasing?
                    is_pacing_format = all(x < y for x, y in zip(loaded_starts, loaded_starts[1:])) if len(loaded_starts) > 1 else True
                    
                    if is_pacing_format:
                        # Convert Start Times to Durations
                        total_dur = tts_data["duration"]
                        durations = []
                        for i in range(len(loaded_starts)):
                            if i < len(loaded_starts) - 1:
                                durations.append(loaded_starts[i+1] - loaded_starts[i])
                            else:
                                durations.append(max(2.0, total_dur - loaded_starts[i]))
                        image_durations = durations
                    else:
                        # Old format: Durations
                        image_durations = loaded_starts
                    
                    # Align with images count
                    if len(image_durations) >= len(images):
                        image_durations = image_durations[:len(images)]
                    else:
                        rem_dur = tts_data["duration"] - sum(image_durations) if isinstance(image_durations, list) else 0
                        rem_cnt = len(images) - len(image_durations)
                        if rem_cnt > 0:
                            avg = max(3.0, rem_dur / rem_cnt)
                            image_durations = image_durations + [avg] * rem_cnt

                    print(f"âœ… [Auto-Pilot] Start-Time Sync Applied: {len(image_durations)} scenes")
                    smart_sync_enabled = True
            except Exception as e:
                print(f"âš ï¸ Failed to load smart timings: {e}")

        # 2. Fallback to Simple N-Division
        if not smart_sync_enabled:
            total_dur = tts_data["duration"] if tts_data else (len(images) * 5.0)
            image_durations = total_dur / len(images) if images else 5.0
            print(f"âš ï¸ [Auto-Pilot] Fallback to N-Division Sync ({image_durations if not isinstance(image_durations, list) else 'list'}s per image)")
        
        # [NEW] Determine Resolution based on App Mode
        app_mode = settings.get("app_mode", "longform")
        resolution = (1920, 1080) if app_mode == "longform" else (1080, 1920)
        print(f"ğŸ¬ [Auto-Pilot] Rendering video with resolution: {resolution} (Mode: {app_mode})")

        # [NEW] Collect SFX Mapping
        # [NEW] Collect SFX Mapping from JSON
        sfx_map = {}
        sfx_map_json = settings.get("sfx_mapping_json")
        if sfx_map_json:
            try:
                raw_sfx_map = json.loads(sfx_map_json)
                for s_num_str, sfx_filename in raw_sfx_map.items():
                    sfx_abs_path = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "sound", sfx_filename)
                    if os.path.exists(sfx_abs_path):
                         sfx_map[str(s_num_str)] = sfx_abs_path
            except Exception as e:
                print(f"âš ï¸ Failed to parse SFX mapping: {e}")

        # [NEW] Handle BGM (Download if URL exists)
        bgm_url = settings.get("bgm_url")
        bgm_path = None
        if bgm_url:
            try:
                import requests
                bgm_filename = f"bgm_{project_id}.mp3"
                local_bgm_path = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "sound", bgm_filename)
                os.makedirs(os.path.dirname(local_bgm_path), exist_ok=True)
                
                if not os.path.exists(local_bgm_path):
                    print(f"ğŸµ [Auto-Pilot] Downloading BGM: {bgm_url}")
                    r = requests.get(bgm_url, timeout=30)
                    if r.status_code == 200:
                        with open(local_bgm_path, "wb") as f:
                            f.write(r.content)
                
                if os.path.exists(local_bgm_path):
                    bgm_path = local_bgm_path
                    # Inject into settings so video_service can find it
                    settings["bgm_path"] = bgm_path
            except Exception as bgme:
                print(f"âš ï¸ BGM Download failed: {bgme}")

        # [NEW] Collect Focal Points and Motions
        f_points = []
        effects = []
        for i, img in enumerate(sorted_prompts):
            s_num = img.get('scene_number')
            f_points.append(img.get("focal_point_y", 0.5))
            
            # Fetch motion from settings (saved from webtoon producer or manual)
            eff = settings.get(f"scene_{s_num}_motion")
            if not eff or eff == 'random':
                # [NEW] Level 2: Gemini Vision ìë™ ë¶„ë¥˜ë¡œ ìµœì  íš¨ê³¼ ì„ íƒ
                # video_service.create_slideshowì—ì„œ 'auto_classify' ê°ì§€ ì‹œ
                # classify_asset_type()ì„ í˜¸ì¶œí•˜ì—¬ ìë™ ê²°ì •
                eff = 'auto_classify'
            effects.append(eff)
            log_debug(f"ğŸï¸ [Render] Scene {s_num}: Effect={eff}")

        final_path = video_service.create_slideshow(
            images=images, audio_path=audio_path, output_filename=output_filename,
            duration_per_image=image_durations, subtitles=subs, project_id=project_id,
            resolution=resolution, subtitle_settings=settings, sfx_map=sfx_map,
            focal_point_ys=f_points, image_effects=effects
        )

        db.update_project_setting(project_id, "video_path", f"/output/{output_filename}")
        db.update_project(project_id, status="rendered")

    async def _run_topview_workflow(self, project_id: int, config_dict: dict):
        """TopView APIë¥¼ ì´ìš©í•œ ì»¤ë¨¸ìŠ¤ ë¹„ë””ì˜¤ ìƒì„± ì›Œí¬í”Œë¡œìš°"""
        product_url = config_dict.get("product_url")
        if not product_url:
            print("âš ï¸ [TopView] Product URL is missing")
            db.update_project(project_id, status="error")
            return

        print(f"ğŸ›ï¸ [TopView] Starting Commerce Workflow for {product_url}")
        db.update_project(project_id, status="topview_requested")

        # 1. íƒœìŠ¤í¬ ì‹œì‘
        from services.topview_service import topview_service
        result = await topview_service.create_video_by_url(product_url)
        
        if not result or (isinstance(result, dict) and "id" not in result):
            print(f"âŒ [TopView] Failed to start task: {result}")
            db.update_project(project_id, status="error")
            return

        task_id = result["id"]
        db.update_project_setting(project_id, "topview_task_id", task_id)
        db.update_project(project_id, status="topview_processing")

        # 2. í´ë§ (ìƒíƒœ í™•ì¸)
        max_retries = 60 # ì•½ 10ë¶„ (10ì´ˆ ê°„ê²©)
        retry_count = 0
        video_url = None

        while retry_count < max_retries:
            await asyncio.sleep(10)
            status_data = await topview_service.get_task_status(task_id)
            
            if not status_data:
                retry_count += 1
                continue

            status = status_data.get("status")
            print(f"â³ [TopView] Processing... ({status})")

            if status == "completed":
                video_url = status_data.get("video_url")
                break
            elif status == "failed":
                print(f"âŒ [TopView] Task failed: {status_data}")
                db.update_project(project_id, status="error")
                return
            
            retry_count += 1

        if not video_url:
            print("âŒ [TopView] Task timed out or no video URL received")
            db.update_project(project_id, status="error")
            return

        # 3. ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
        db.update_project(project_id, status="topview_downloading")
        target_path = os.path.join(config.OUTPUT_DIR, f"topview_{project_id}.mp4")
        
        try:
            async with httpx.AsyncClient() as client:
                resp = await client.get(video_url, timeout=300)
                with open(target_path, "wb") as f:
                    f.write(resp.content)
            
            # DB ì—…ë°ì´íŠ¸
            web_path = f"/output/topview_{project_id}.mp4"
            db.update_project_setting(project_id, "video_path", web_path)
            db.update_project(project_id, status="rendered")
            
            print(f"âœ… [TopView] Video generated and saved: {target_path}")

            # 4. YouTube ì—…ë¡œë“œ (ê¸°ë³¸ ë¡œì§ í™œìš©)
            await self._upload_video(project_id, target_path)
            
        except Exception as e:
            print(f"âŒ [TopView] Download/Save Error: {e}")
            db.update_project(project_id, status="error")

    async def _upload_video(self, project_id: int, video_path: str):
        now = config.get_kst_time()
        
        # Load settings
        p_settings = db.get_project_settings(project_id) or {}
        
        # Determine Privacy & Schedule
        privacy = p_settings.get("upload_privacy", "private")
        schedule_at = p_settings.get("upload_schedule_at")
        
        publish_time = None
        if privacy == "scheduled" or schedule_at:
            if schedule_at:
                try:
                    # Validate format or parse
                    # Format expected: 2026-02-12T08:00:00 or ISO
                    if "T" not in schedule_at:
                        # Simple format YYYY-MM-DD HH:MM
                        dt = datetime.strptime(schedule_at, "%Y-%m-%d %H:%M")
                        publish_time = dt.isoformat()
                    else:
                        publish_time = schedule_at
                except:
                    print(f"âš ï¸ [Upload] Invalid schedule format: {schedule_at}. Falling back to default.")
            
            if not publish_time:
                # Default: Next day 8 AM
                publish_time = (now + timedelta(days=1)).replace(hour=8, minute=0, second=0).isoformat()
            
            # YouTube API requires privacyStatus to be 'private' for scheduled uploads
            privacy = "private" 

        ai_title = p_settings.get("title") or f"AI Auto Video {now.date()}"
        ai_desc = p_settings.get("description") or "#Shorts #AI"
        ai_tags_str = p_settings.get("hashtags") or "ai,shorts"
        ai_tags = [t.strip() for t in ai_tags_str.split(",") if t.strip()]

        # [NEW] Multi-Channel Support: Resolve Token Path
        token_path = None
        channel_id = p_settings.get("youtube_channel_id")
        if channel_id:
            try:
                # get_channel must be implemented in database.py
                channel = db.get_channel(channel_id)
                if channel and channel.get("credentials_path"):
                    cand_path = channel["credentials_path"]
                    if os.path.exists(cand_path):
                        token_path = cand_path
                        print(f"ğŸ”‘ [Upload] Using channel token: {channel.get('name')} ({token_path})")
            except Exception as ce:
                print(f"âš ï¸ [Upload] Failed to resolve channel {channel_id}: {ce}")

        try:
            # 1. Video Upload
            print(f"ğŸš€ [Upload] Starting YouTube upload (Privacy: {privacy}, Schedule: {publish_time}, Channel: {channel_id or 'Default'})")
            response = youtube_upload_service.upload_video(
                file_path=video_path, 
                title=ai_title,
                description=ai_desc, 
                tags=ai_tags,
                privacy_status=privacy, 
                publish_at=publish_time,
                token_path=token_path # Pass token path
            )
            
            # 2. Thumbnail Upload (Wait a bit for video to be indexed)
            video_id = response.get("id")
            if video_id:
                print(f"âœ… [Auto-Pilot] Video uploaded: https://youtu.be/{video_id}. Waiting 10s for thumbnail upload...")
                await asyncio.sleep(10)
                
                settings = db.get_project_settings(project_id)
                thumb_url = settings.get("thumbnail_url")
                
                if thumb_url:
                    # /output/filename.jpg -> LOCAL_PATH/filename.jpg
                    fname = thumb_url.split("/")[-1]
                    thumb_path = os.path.join(config.OUTPUT_DIR, fname)
                    
                    if os.path.exists(thumb_path):
                        print(f"ğŸ–¼ï¸ [Auto-Pilot] Uploading thumbnail: {thumb_path}")
                        try:
                            youtube_upload_service.set_thumbnail(video_id, thumb_path, token_path=token_path)
                            print(f"âœ… [Auto-Pilot] Thumbnail set successfully for {video_id}")
                        except Exception as te:
                            print(f"âš ï¸ Thumbnail upload failed: {te}")
                    else:
                        print(f"âš ï¸ Thumbnail file not found at {thumb_path}")
                else:
                    print(f"âš ï¸ No thumbnail_url found for project {project_id}")
            
            db.update_project_setting(project_id, "is_uploaded", 1)
        except Exception as e:
            print(f"âŒ Upload failed: {e}")

    async def run_batch_workflow(self):
        """queued ìƒíƒœì˜ í”„ë¡œì íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ëª¨ë‘ ì²˜ë¦¬"""
        if self.is_batch_running:
            print("âš ï¸ [Batch] ì´ë¯¸ ì§„í–‰ ì¤‘ì¸ ì¼ê´„ ì²˜ë¦¬ ì‘ì—…ì´ ìˆìŠµë‹ˆë‹¤.")
            return
            
        self.is_batch_running = True
        print("ğŸš¦ [Batch] ì¼ê´„ ì œì‘ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
        import asyncio
        
        try:
            while True:
                projects = db.get_all_projects()
                # FIFO: IDê°€ ì‘ì€ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
                queue = sorted([p for p in projects if p.get("status") == "queued"], key=lambda x: x['id'])
                
                if not queue:
                    print("ğŸ [Batch] ëŒ€ê¸°ì—´ ì‘ì—…ì„ ëª¨ë‘ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
                    break
                    
                project = queue[0]
                pid = project['id']
                print(f"â–¶ï¸ [Batch] í”„ë¡œì íŠ¸ ì‹œì‘: {project.get('topic')} (ID: {pid})")
                
                try:
                    # ì„¤ì • ë¡œë“œ
                    p_settings = db.get_project_settings(pid) or {}
                    
                    # [Logic Fix] ìˆœì„œëŒ€ë¡œ ì§„í–‰í•˜ê¸° ìœ„í•´ ì ì ˆí•œ ì‹œì‘ ìƒíƒœ ê²°ì •
                    # 1. ì´ë¯¸ ëŒ€ë³¸ì´ ìˆëŠ” ê²½ìš° -> ìì‚° ìƒì„±ë¶€í„°
                    if p_settings.get("script") and len(p_settings.get("script").strip()) > 50:
                        print(f"ğŸ“„ [Batch] ê¸°ì¡´ ëŒ€ë³¸ ë°œê²¬ (ID: {pid}). 'scripted' ë‹¨ê³„ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                        db.update_project(pid, status="scripted")
                    # 2. ë¶„ì„ ë°ì´í„°ëŠ” ìˆëŠ” ê²½ìš° -> ê¸°íš/ëŒ€ë³¸ ë‹¨ê³„ë¶€í„°
                    elif db.get_analysis(pid):
                        print(f"ğŸ“Š [Batch] ë¶„ì„ ë°ì´í„° ë°œê²¬ (ID: {pid}). 'analyzed' ë‹¨ê³„ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                        db.update_project(pid, status="analyzed")
                    # 3. ì•„ë¬´ê²ƒë„ ì—†ëŠ” ìƒˆ í”„ë¡œì íŠ¸ì¸ ê²½ìš° -> ì²˜ìŒ(ë¶„ì„)ë¶€í„°
                    else:
                        print(f"ğŸ†• [Batch] ì‹ ê·œ í”„ë¡œì íŠ¸ (ID: {pid}). 'created' ë‹¨ê³„ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                        db.update_project(pid, status="created")
                    
                    config_dict = {
                        "script_style": p_settings.get("script_style", "default"),
                        "duration_seconds": p_settings.get("duration_seconds", 300),
                        "voice_provider": p_settings.get("voice_provider"),
                        "voice_id": p_settings.get("voice_id"),
                        "image_style": p_settings.get("image_style", "realistic"), 
                        "thumbnail_style": p_settings.get("thumbnail_style", "face"), 
                        "all_video": bool(p_settings.get("all_video", 0)),
                        "motion_method": p_settings.get("motion_method", "standard"),
                        "video_scene_count": p_settings.get("video_scene_count", 0),
                        "auto_thumbnail": True,
                        "auto_plan": p_settings.get("auto_plan", True),
                        "video_engine": p_settings.get("video_engine", "wan"),
                        "upload_privacy": p_settings.get("upload_privacy", "private"),
                        "upload_schedule_at": p_settings.get("upload_schedule_at")
                    }
                    
                    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Wait for completion)
                    await self.run_workflow(project.get('topic'), pid, config_dict)
                    print(f"âœ… [Batch] í”„ë¡œì íŠ¸ ì™„ë£Œ: {pid}")
                    
                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    print(f"âŒ [Batch] í”„ë¡œì íŠ¸ ì‹¤íŒ¨ (ID: {pid}): {e}")
                    db.update_project(pid, status="error")
                    
                await asyncio.sleep(2)
        finally:
            self.is_batch_running = False
            print("ğŸ›‘ [Batch] ì¼ê´„ ì œì‘ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
    
    def _alignment_to_subtitles(self, alignments: list, max_chars: int = 25) -> list:
        """
        ë‹¨ì–´ íƒ€ì´ë° ì •ë³´ë¥¼ 2ì¤„ ìë§‰ìœ¼ë¡œ ë³€í™˜ (ì •ë°€ ì‹±í¬)
        
        Args:
            alignments: [{"word": "ì•ˆë…•", "start": 0.0, "end": 0.3}, ...]
            max_chars: ìë§‰ë‹¹ ìµœëŒ€ ê¸€ì ìˆ˜ (2ì¤„ ê¸°ì¤€)
        
        Returns:
            [{"text": "ìë§‰ í…ìŠ¤íŠ¸", "start": 0.0, "end": 1.5}, ...]
        """
        if not alignments:
            return []
        
        subtitles = []
        current_words = []
        current_text = ""
        block_start = None
        block_end = None
        
        for i, word_info in enumerate(alignments):
            word = word_info.get("word", "").strip()
            if not word:
                continue
            
            start = word_info.get("start", 0)
            end = word_info.get("end", start + 0.1)
            
            # ìƒˆ ë¸”ë¡ ì‹œì‘
            if block_start is None:
                block_start = start
            
            # í…ìŠ¤íŠ¸ ëˆ„ì 
            test_text = f"{current_text} {word}".strip() if current_text else word
            
            # ìµœëŒ€ ê¸€ì ìˆ˜ ì²´í¬ ë˜ëŠ” ë¬¸ì¥ ë¶€í˜¸ë¡œ ëŠê¸°
            is_sentence_end = word.endswith(('.', '?', '!', ','))
            should_break = len(test_text) > max_chars or is_sentence_end
            
            if should_break and current_text:
                # í˜„ì¬ ë¸”ë¡ ì €ì¥
                subtitles.append({
                    "text": current_text,
                    "start": round(block_start, 2),
                    "end": round(block_end, 2)
                })
                
                # ìƒˆ ë¸”ë¡ ì‹œì‘
                current_text = word
                block_start = start
                block_end = end
            else:
                current_text = test_text
                block_end = end
        
        # ë§ˆì§€ë§‰ ë¸”ë¡
        if current_text:
            subtitles.append({
                "text": current_text,
                "start": round(block_start, 2),
                "end": round(block_end, 2)
            })
        
        return subtitles

    def get_queue_status(self):
        """í˜„ì¬ ëŒ€ê¸°ì—´ ìƒíƒœ ë°˜í™˜"""
        projects = db.get_all_projects()
        queued_projects = [p for p in projects if p.get("status") == "queued"]
        processing_projects = [p for p in projects if p.get("status") not in ["done", "error", "queued", "draft", "created"]]
        
        return {
            "is_running": self.is_batch_running,
            "queued_count": len(queued_projects),
            "processing_count": len(processing_projects),
            "queued_items": queued_projects[:10],  # ìƒìœ„ 10ê°œë§Œ
            "current_items": processing_projects
        }

    def add_to_queue(self, project_id: int):
        """í”„ë¡œì íŠ¸ë¥¼ ëŒ€ê¸°ì—´ì— ì¶”ê°€"""
        db.update_project(project_id, status="queued")

    def clear_queue(self):
        """ëŒ€ê¸°ì—´ ë¹„ìš°ê¸°"""
        projects = db.get_all_projects()
        for p in projects:
            if p.get("status") == "queued":
                db.update_project(p['id'], status="draft")

    async def generate_production_plan(self, scenes: List[Dict]) -> Dict:
        """
        Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì›¹íˆ° ì¥ë©´ ëª©ë¡ì„ ê¸°ë°˜ìœ¼ë¡œ ë¹„ë””ì˜¤ ì œì‘ ê¸°íšì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        """
        print(f"ğŸ“‹ [Auto-Pilot] Generating Production Plan for {len(scenes)} scenes...")
        
        # 1. Prepare Context & Analyze Image Types (Simple Logic)
        scene_context = []
        for s in scenes:
            scene_context.append({
                "scene_number": s.get('scene_number'),
                "visual_desc": s.get('analysis', {}).get('visual_desc', ''),
                "atmosphere": s.get('analysis', {}).get('atmosphere', ''),
                "dialogue": s.get('analysis', {}).get('dialogue', ''),
                "type": s.get('scene_type', '3'), # 1: Vertical, 2: Horizontal, 3: Regular
            })
            
        prompt = f"""
        You are a professional Video Director specializing in Webtoon-to-Video implementation.
        Review the following {len(scenes)} scenes from a webtoon and create a technical production plan.
        
        Target Output Format (JSON):
        {{
            "overall_strategy": "Brief direction for the video tone and pacing.",
            "bgm_style": "Recommended background music style and mood.",
            "scene_specifications": [
                {{
                    "scene_number": 1,
                    "engine": "wan" or "akool", 
                    "motion": "Detailed description of camera movement (e.g., Slow pan down from sky)",
                    "effect": "pan_down" or "pan_up" or "zoom_in" or "zoom_out" or "static",
                    "rationale": "Why this motion/engine?",
                    "cropping_advice": "Focus on [object] or [character face]"
                }}
            ]
        }}
        
        Rules:
        1. 'wan' engine is best for general cinematic motion and scenery. 'akool' is ONLY for scenes with talking character face (lip-sync).
        2. If 'type' is '1' (Vertical), prefer 'pan_down' or 'pan_up' to show the full height.
        3. If 'type' is '2' (Horizontal), prefer 'pan_left', 'pan_right' or static zoom.
        4. If dialogue exists and it looks like a close-up, consider 'akool' for lip-sync, otherwise use 'wan' with camera motion.
        
        Scenes Data:
        {json.dumps(scene_context, ensure_ascii=False, indent=2)}
        """
        
        try:
            # Call Gemini
            resp = await gemini_service.generate_text(prompt)
            
            # Parse JSON
            # Clean up potential markdown blocks
            clean_json = resp.replace("```json", "").replace("```", "").strip()
            
            # Handle potential extra text
            start_idx = clean_json.find('{')
            end_idx = clean_json.rfind('}')
            if start_idx != -1 and end_idx != -1:
                clean_json = clean_json[start_idx:end_idx+1]
                
            plan = json.loads(clean_json)
            return plan
        except Exception as e:
            print(f"âŒ [Auto-Pilot] Plan Generation Failed: {e}")
            import traceback
            traceback.print_exc()
            # Return dummy plan
            return {
                "overall_strategy": "Plan generation failed. Please try again or proceed manually.",
                "bgm_style": "Casual",
                "scene_specifications": []
            }

    async def start_batch_worker(self):
        """[NEW] í”„ë¡œì íŠ¸ ëŒ€ê¸°ì—´ì„ ê°ì‹œí•˜ê³  ìˆœì°¨ì ìœ¼ë¡œ ì²˜ë¦¬í•˜ëŠ” ì›Œì»¤"""
        if self.is_batch_running:
            print("ğŸš€ [Auto-Pilot] Batch worker already running.")
            return

        self.is_batch_running = True
        print("ğŸš€ [Auto-Pilot] Batch worker started.")

        while True:
            try:
                # 1. 'queued' ìƒíƒœì¸ í”„ë¡œì íŠ¸ ì°¾ê¸°
                projects = db.get_all_projects()
                queued = [p for p in projects if p.get("status") == "queued"]

                if queued:
                    target = queued[0]
                    target_pid = target['id']
                    target_topic = target.get('topic', 'Auto-Webtoon')

                    log_debug(f"ğŸ“¦ [Auto-Pilot] Worker found queued project {target_pid} ({target_topic})...")
                    
                    # 2. ì‹¤í–‰ ìƒíƒœë¡œ ì „ì´ (run_workflowê°€ ì¸ì‹í•  ìˆ˜ ìˆê²Œ)
                    p_settings = db.get_project_settings(target_pid) or {}
                    
                    # ëŒ€ë³¸ì´ ìˆìœ¼ë©´ ë°”ë¡œ ì—ì…‹ ìƒì„± ë‹¨ê³„ë¡œ, ì—†ìœ¼ë©´ ì²˜ìŒë¶€í„°
                    if p_settings.get("script") and len(p_settings.get("script").strip()) > 10:
                        log_debug(f"ğŸ“œ [Auto-Pilot] Setting PID {target_pid} to 'scripted' because script exists.")
                        db.update_project(target_pid, status="scripted")
                    else:
                        log_debug(f"ğŸ†• [Auto-Pilot] Setting PID {target_pid} to 'created'.")
                        db.update_project(target_pid, status="created")

                    # Ensure app_mode compatibility
                    if "mode" not in p_settings and "app_mode" in p_settings:
                        p_settings["mode"] = p_settings["app_mode"]

                    await self.run_workflow(target_topic, project_id=target_pid, config_dict=p_settings)
                    
                    print(f"âœ… [Auto-Pilot] Project {target_pid} processing complete.")
                
                await asyncio.sleep(10) # 10ì´ˆë§ˆë‹¤ í™•ì¸
                
            except Exception as e:
                print(f"âŒ [Auto-Pilot] Batch worker error: {e}")
                import traceback
                traceback.print_exc()
                await asyncio.sleep(20) # ì—ëŸ¬ ì‹œ ì¢€ ë” ê¸¸ê²Œ ëŒ€ê¸°

autopilot_service = AutoPilotService()

