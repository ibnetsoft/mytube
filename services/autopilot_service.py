
import asyncio
import json
import os
import random
from datetime import datetime, timedelta
import httpx
from config import config
import database as db
from services.gemini_service import gemini_service
from services.prompts import prompts
from services.tts_service import tts_service
from services.video_service import video_service
from services.youtube_upload_service import youtube_upload_service
from services.topview_service import topview_service


def split_text_to_subtitle_chunks(text: str, max_chars_per_line: int = 20, max_lines: int = 2) -> list:
    """
    Í∏¥ ÌÖçÏä§Ìä∏Î•º ÏûêÎßâÏö© Ï≤≠ÌÅ¨Î°ú Î∂ÑÌï†Ìï©ÎãàÎã§.
    - Ìïú Ï§ÑÎãπ ÏµúÎåÄ max_chars_per_line Í∏ÄÏûê
    - Ìïú ÌôîÎ©¥Ïóê ÏµúÎåÄ max_lines Ï§Ñ (Í∏∞Î≥∏ 2Ï§Ñ)
    - Î¨∏Ïû• Í≤ΩÍ≥Ñ(. ! ?)Î•º Ïö∞ÏÑ†ÏúºÎ°ú Î∂ÑÌï†
    
    Returns: List of subtitle text chunks (each chunk is max 2 lines)
    """
    if not text or not text.strip():
        return []
    
    text = text.strip()
    
    # Î®ºÏ†Ä Î¨∏Ïû• Îã®ÏúÑÎ°ú Î∂ÑÎ¶¨ (ÎßàÏπ®Ìëú, ÎäêÎÇåÌëú, Î¨ºÏùåÌëú Í∏∞Ï§Ä)
    import re
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    chunks = []
    current_chunk_lines = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        # Î¨∏Ïû•ÏùÑ Ï§Ñ Îã®ÏúÑÎ°ú Î∂ÑÌï† (max_chars_per_line Í∏∞Ï§Ä)
        words = sentence.split()
        current_line = ""
        lines_from_sentence = []
        
        for word in words:
            test_line = f"{current_line} {word}".strip() if current_line else word
            if len(test_line) <= max_chars_per_line:
                current_line = test_line
            else:
                if current_line:
                    lines_from_sentence.append(current_line)
                current_line = word
        
        if current_line:
            lines_from_sentence.append(current_line)
        
        # ÌòÑÏû¨ Ï≤≠ÌÅ¨Ïóê Ïù¥ Î¨∏Ïû•Ïùò Ï§ÑÎì§ÏùÑ Ï∂îÍ∞Ä
        for line in lines_from_sentence:
            current_chunk_lines.append(line)
            
            # max_linesÏóê ÎèÑÎã¨ÌïòÎ©¥ Ï≤≠ÌÅ¨ ÏÉùÏÑ±
            if len(current_chunk_lines) >= max_lines:
                chunks.append("\n".join(current_chunk_lines))
                current_chunk_lines = []
    
    # ÎÇ®ÏùÄ Ï§ÑÎì§ Ï≤òÎ¶¨
    if current_chunk_lines:
        chunks.append("\n".join(current_chunk_lines))
    
    return chunks


class AutoPilotService:
    def __init__(self):
        self.search_url = f"{config.YOUTUBE_BASE_URL}/search"
        self.config = {}  # Director Mode Configuration
        self.is_batch_running = False # [NEW] Batch Concurrency Lock

    async def run_workflow(self, keyword: str, project_id: int = None, config_dict: dict = None):
        """Ïò§ÌÜ†ÌååÏùºÎüø Ï†ÑÏ≤¥ ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ïã§Ìñâ"""
        print(f"üöÄ [Auto-Pilot] '{keyword}' ÏûëÏóÖ ÏãúÏûë")
        start_dt = datetime.now()
        db.update_project_setting(project_id, "stats_start_time", start_dt.strftime("%Y-%m-%d %H:%M:%S"))
        
        self.config = config_dict or {}
        if "auto_plan" not in self.config:
            self.config["auto_plan"] = True  # Always generate plan data by default
        
        # [NEW] TopView Commerce Mode Check
        creation_mode = self.config.get("creation_mode", "default")
        if creation_mode == "commerce":
            return await self._run_topview_workflow(project_id, self.config)
        
        try:
            # 1~2. ÏÜåÏû¨ Î∞úÍµ¥ Î∞è ÌîÑÎ°úÏ†ùÌä∏ ÏÉùÏÑ±
            if not project_id:
                video = await self._find_best_material(keyword)
                if not video: return
                project_name = f"[Auto] {keyword} - {video['snippet']['title'][:20]}"
                project_id = db.create_project(name=project_name, topic=keyword)
                db.update_project(project_id, status="created")
                current_status = "created"
            else:
                project = db.get_project(project_id)
                current_status = project.get('status', 'created')

            # 3. AI Î∂ÑÏÑù
            if current_status in ["created", "draft"]:
                db.update_project(project_id, status="analyzing") # [NEW] status for UI
                video = await self._find_best_material(keyword)
                analysis_result = await self._analyze_video(video)
                db.save_analysis(project_id, video, analysis_result)
                db.update_project(project_id, status="analyzed")
                current_status = "analyzed"

            # 4. Í∏∞Ìöç Î∞è ÎåÄÎ≥∏ ÏûëÏÑ±
            if current_status == "analyzed":
                db.update_project(project_id, status="planning") # [NEW] status for UI
                analysis = db.get_analysis(project_id)
                script = await self._generate_script(project_id, analysis.get("analysis_result", {}), self.config)
                db.update_project_setting(project_id, "script", script)
                
                db.update_project(project_id, status="scripting") # [NEW] status for UI
                # [NEW] AI Ï†úÎ™© Î∞è ÏÑ§Î™Ö ÏÉùÏÑ±
                await self._generate_metadata(project_id, script)
                
                db.update_project(project_id, status="scripted")
                current_status = "scripted"

            # [RE-SYNC] Webtoon mode transition: if it's queued/scripted but came from webtoon studio
            if current_status in ["queued", "scripted", "scripting"]:
                # Check if we have image prompts but no videos
                prompts = db.get_image_prompts(project_id)
                if prompts:
                    current_status = "characters_ready"
                    print(f"üéûÔ∏è [Auto-Pilot] Found existing image prompts. Moving to Asset Generation.")

            # 4.5 Ï∫êÎ¶≠ÌÑ∞ Ï∂îÏ∂ú (ÏùºÍ¥ÄÏÑ± Ïú†ÏßÄÏö©)
            if current_status == "scripted":
                script_data = db.get_script(project_id)
                if script_data:
                    await self._extract_characters(project_id, script_data["full_script"], self.config)
                current_status = "characters_ready"

            # 5. ÏóêÏÖã ÏÉùÏÑ± (Ïù¥ÎØ∏ÏßÄ & Ïç∏ÎÑ§Ïùº & Ïò§ÎîîÏò§)
            if current_status == "characters_ready":
                script_data = db.get_script(project_id)
                full_script = script_data["full_script"]
                
                # 5-1. ÏòÅÏÉÅ ÏÜåÏä§ ÏÉùÏÑ±
                db.update_project(project_id, status="generating_assets")
                await self._generate_assets(project_id, full_script, self.config)
                
                # [NEW] Ensure Metadata exists (Title, Description) - Re-run if skipped earlier
                settings = db.get_project_settings(project_id) or {}
                if not settings.get('title') or not settings.get('description'):
                    print(f"üìù [Auto-Pilot] Metadata missing for pid {project_id}. Generating...")
                    await self._generate_metadata(project_id, full_script)

                # 5-2. [NEW] Ïç∏ÎÑ§Ïùº ÏûêÎèô ÏÉùÏÑ±
                if self.config.get('auto_thumbnail', True):
                    # Check if already exists to avoid duplicate gen
                    if not settings.get('thumbnail_url'):
                        db.update_project(project_id, status="generating_thumbnail")
                        await self._generate_thumbnail(project_id, full_script, self.config)

                db.update_project(project_id, status="tts_done")
                current_status = "tts_done"

            # 6. ÏòÅÏÉÅ Î†åÎçîÎßÅ
            if current_status == "tts_done":
                await self._render_video(project_id)
                current_status = "rendered"

            # 7. ÏóÖÎ°úÎìú
            if current_status == "rendered":
                settings = db.get_project_settings(project_id)
                video_path = settings.get("video_path")
                if video_path:
                    abs_video_path = os.path.join(config.OUTPUT_DIR, video_path.replace("/output/", ""))
                    if os.path.exists(abs_video_path):
                        await self._upload_video(project_id, abs_video_path)
                        db.update_project(project_id, status="uploaded")
            
            # [NEW] Save Stats
            end_dt = datetime.now()
            duration_str = str(end_dt - start_dt).split('.')[0]
            db.update_project_setting(project_id, "stats_end_time", end_dt.strftime("%Y-%m-%d %H:%M:%S"))
            db.update_project_setting(project_id, "stats_total_duration", duration_str)
            
            db.update_project(project_id, status="done")
            print(f"‚ú® [Auto-Pilot] ÏûëÏóÖ ÏôÑÎ£å! (ID: {project_id}, Time: {duration_str})")

        except Exception as e:
            print(f"‚ùå [Auto-Pilot] Ïò§Î•ò Î∞úÏÉù: {e}")
            db.update_project(project_id, status="error")

    async def _extract_characters(self, project_id: int, script_text: str, config_dict: dict = None):
        """ÎåÄÎ≥∏ÏóêÏÑú Ï∫êÎ¶≠ÌÑ∞ Ï∂îÏ∂ú Î∞è ÏùºÍ¥ÄÏÑ± ÏûàÎäî ÌîÑÎ°¨ÌîÑÌä∏ ÏÉùÏÑ± (Ïù¥ÎØ∏ ÏûàÏúºÎ©¥ Í±¥ÎÑàÎúÄ)"""
        # [NEW] Ïù¥ÎØ∏ Ï∫êÎ¶≠ÌÑ∞Í∞Ä ÏàòÎèôÏúºÎ°ú ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÎäîÏßÄ ÌôïÏù∏
        existing = db.get_project_characters(project_id)
        if existing:
            print(f"üë• [Auto-Pilot] Ïù¥ÎØ∏ {len(existing)}Î™ÖÏùò Ï∫êÎ¶≠ÌÑ∞Í∞Ä ÏÑ§Ï†ïÎêòÏñ¥ ÏûàÏäµÎãàÎã§. Ï∂îÏ∂úÏùÑ Í±¥ÎÑàÎúÅÎãàÎã§.")
            return

        print(f"üë• [Auto-Pilot] Ï∫êÎ¶≠ÌÑ∞ Ï∂îÏ∂ú ÏãúÏûë...")
        
        # [NEW] ÎπÑÏ£ºÏñº Ïä§ÌÉÄÏùº Í≤∞Ï†ï
        style_prefix = "photorealistic"
        if config_dict:
            image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))
            style_presets = db.get_style_presets()
            style_data = style_presets.get(image_style_key, {})
            style_prefix = style_data.get("prompt_value", "photorealistic")
        
        try:
            characters = await gemini_service.generate_character_prompts_from_script(script_text, visual_style=style_prefix)
            if characters:
                db.save_project_characters(project_id, characters)
                print(f"‚úÖ [Auto-Pilot] {len(characters)}Î™ÖÏùò Ï∫êÎ¶≠ÌÑ∞Î•º ÏãùÎ≥ÑÌïòÍ≥† Ï†ÄÏû•ÌñàÏäµÎãàÎã§. (Style: {style_prefix})")
                
                # [NEW] Ï∫êÎ¶≠ÌÑ∞ ÏÉòÌîå Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± Î∞è Ï†ÅÏö© (ÏµúÎåÄ 3Î™Ö)
                processed_chars = characters[:3]
                has_applied_reference = False
                
                for idx, char in enumerate(processed_chars):
                    try:
                        print(f"üë§ [Auto-Pilot] Ï∫êÎ¶≠ÌÑ∞ '{char['name']}' ({char['role']}) ÏÉòÌîå Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± Ï§ë...")
                        detailed_style = style_data.get('prompt_value', style_prefix)
                        full_prompt = f"{char['prompt_en']}, {detailed_style}"
                        
                        # Portrait aspect ratio 1:1
                        images_bytes = await gemini_service.generate_image(
                            prompt=full_prompt,
                            num_images=1,
                            aspect_ratio="1:1"
                        )
                        
                        if images_bytes:
                            now = config.get_kst_time()
                            filename = f"char_{project_id}_{idx}_{now.strftime('%H%M%S')}.png"
                            file_path = os.path.join(config.OUTPUT_DIR, filename)
                            web_url = f"/output/{filename}"
                            
                            with open(file_path, "wb") as f:
                                f.write(images_bytes[0])
                            
                            # DB ÏóÖÎç∞Ïù¥Ìä∏
                            db.update_character_image(project_id, char['name'], web_url)
                            
                            # [ÌïµÏã¨] Ï£ºÏù∏Í≥µÏù¥Í±∞ÎÇò Ï≤´ Î≤àÏß∏ Ï∫êÎ¶≠ÌÑ∞Ïù∏ Í≤ΩÏö∞ ÌîÑÎ°úÏ†ùÌä∏ Î†àÌçºÎü∞Ïä§Î°ú ÏûêÎèô Ï†ÅÏö© (Apply Î≤ÑÌäº Ìö®Í≥º)
                            is_protagonist = "Ï£ºÏù∏Í≥µ" in char.get("role", "")
                            if not has_applied_reference:
                                if is_protagonist or (idx == len(processed_chars) - 1) or (idx == 0 and len(processed_chars) == 1):
                                    db.update_project_setting(project_id, "character_ref_text", char['prompt_en'])
                                    db.update_project_setting(project_id, "character_ref_image_path", web_url)
                                    has_applied_reference = True
                                    print(f"‚ú® [Auto-Pilot] Ï£ºÏù∏Í≥µ '{char['name']}'ÏùÑ(Î•º) Ï∫êÎ¶≠ÌÑ∞ Î†àÌçºÎü∞Ïä§Î°ú Ï†ÅÏö©ÌñàÏäµÎãàÎã§.")
                        
                    except Exception as char_e:
                        print(f"‚ö†Ô∏è [Auto-Pilot] Ï∫êÎ¶≠ÌÑ∞ '{char['name']}' Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ± Ïã§Ìå®: {char_e}")

        except Exception as e:
            print(f"‚ö†Ô∏è [Auto-Pilot] Ï∫êÎ¶≠ÌÑ∞ Ï∂îÏ∂ú Ïã§Ìå®: {e}")

    async def _generate_metadata(self, project_id: int, script_text: str):
        """AIÎ•º ÏÇ¨Ïö©ÌïòÏó¨ Ï†úÎ™©, ÏÑ§Î™Ö, ÌÉúÍ∑∏ ÏÉùÏÑ±"""
        print(f"üìù [Auto-Pilot] Ï†úÎ™© Î∞è ÏÑ§Î™Ö ÏÉùÏÑ± ÏãúÏûë...")
        try:
            metadata = await gemini_service.generate_video_metadata(script_text)
            if metadata:
                db.update_project_setting(project_id, "title", metadata.get("title"))
                db.update_project_setting(project_id, "description", metadata.get("description"))
                db.update_project_setting(project_id, "hashtags", ",".join(metadata.get("tags", [])))
                print(f"‚úÖ [Auto-Pilot] Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± ÏôÑÎ£å: {metadata.get('title')}")
        except Exception as e:
            print(f"‚ö†Ô∏è [Auto-Pilot] Î©îÌÉÄÎç∞Ïù¥ÌÑ∞ ÏÉùÏÑ± Ïã§Ìå®: {e}")

    async def _find_best_material(self, keyword: str):
        params = {
            "part": "snippet", "q": keyword, "type": "video",
            "maxResults": 3, "order": "relevance", "videoDuration": "short",
            "key": config.YOUTUBE_API_KEY
        }
        async with httpx.AsyncClient() as client:
            response = await client.get(self.search_url, params=params)
            data = response.json()
            return data["items"][0] if "items" in data and data["items"] else None

    async def _analyze_video(self, video_data: dict):
        video_id = video_data['id']['videoId']
        title = video_data['snippet']['title']
        description = video_data['snippet']['description']
        
        prompt = f"""
        Ïú†ÌäúÎ∏å ÏòÅÏÉÅ Ï†ïÎ≥¥Î•º Î∞îÌÉïÏúºÎ°ú ÏÉàÎ°úÏö¥ ÏòÅÏÉÅÏùÑ ÏúÑÌïú Î∂ÑÏÑùÏùÑ ÏàòÌñâÌï©ÎãàÎã§.
        
        [ÏòÅÏÉÅ Ï†ïÎ≥¥]
        - Ï†úÎ™©: {title}
        - ID: {video_id}
        - ÏÑ§Î™Ö: {description[:500]}
        
        Ïù¥ ÏòÅÏÉÅÏùò ÌïµÏã¨ ÌÉÄÍ≤ü Ïò§ÎîîÏñ∏Ïä§, Ï£ºÏöî ÎÇ¥Ïö©, Í∑∏Î¶¨Í≥† Ïù¥Î•º Î≤§ÏπòÎßàÌÇπÌñàÏùÑ Îïå ÎåÄÏ§ëÎì§Ïù¥ Ï¢ãÏïÑÌï†ÎßåÌïú 'Í≥µÍ∞ê Ìè¨Ïù∏Ìä∏'Î•º 3Í∞ÄÏßÄÎßå Î∂ÑÏÑùÌï¥ÏÑú JSONÏúºÎ°ú Ï£ºÏÑ∏Ïöî.
        
        JSON Ìè¨Îß∑:
        {{
            "sentiment": "positive/negative/neutral",
            "topics": ["Ï£ºÏ†ú1", "Ï£ºÏ†ú2"],
            "viewer_needs": "ÏãúÏ≤≠ÏûêÎì§Ïù¥ ÏõêÌïòÎäî Í≤É ÏÑ§Î™Ö"
        }}
        JSONÎßå Ï∂úÎ†•ÌïòÏÑ∏Ïöî.
        """
        result_text = await gemini_service.generate_text(prompt, temperature=0.7)
        try:
            import re
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            return json.loads(json_match.group()) if json_match else {"summary": result_text}
        except: return {"summary": result_text}

    async def _generate_script(self, project_id: int, analysis: dict, config_dict: dict):
        style_key = config_dict.get("script_style", "default")
        # Get script style description from DB presets if exists
        script_presets = db.get_script_style_presets()
        style_desc = script_presets.get(style_key, f"Style: {style_key}")

        # [NEW] Check for Manual Planning (Script Structure)
        manual_plan = db.get_script_structure(project_id)

        # [AUTO-PLAN] If auto_plan is requested AND no manual plan exists, generate one now
        if not (manual_plan and manual_plan.get("structure")) and config_dict.get("auto_plan"):
             print(f"ü§ñ [Auto-Pilot] ÏûêÎèô Í∏∞Ìöç ÏÉùÏÑ± ÏãúÏûë...")
             try:
                  target_duration_min = config_dict.get("duration_seconds", 300) // 60
                  struct_prompt = f"""
Create a structured plan for a YouTube video based on this analysis.
Analysis: {json.dumps(analysis, ensure_ascii=False)}

Context:
- Video Topic: {db.get_project(project_id).get('topic')}
- Script Style: {style_desc}
- Target Duration: {target_duration_min} minutes

Required Format (JSON Only):
{{
  "hook": "Strong opening sentence to grab attention",
  "sections": [
    {{ "title": "Section Title", "key_points": ["point1", "point2"] }}
  ],
  "cta": "Conclusion and call to action",
  "style": "{style_key}",
  "duration": {target_duration_min}
}}
Language: Korean
Style Guide: Narration/Monologue only. NO dialogue between characters.
"""
                  # request_s = type('obj', (object,), {"prompt": struct_prompt, "temperature": 0.7})
                  result_text_s = await gemini_service.generate_text(struct_prompt, temperature=0.7)
                  
                  import re
                  match = re.search(r'\{[\s\S]*\}', result_text_s)
                  if match:
                      new_struct = json.loads(match.group())
                      # Ensure style and duration are set if AI missed them
                      if "style" not in new_struct: new_struct["style"] = style_key
                      if "duration" not in new_struct: new_struct["duration"] = target_duration_min
                      
                      db.save_script_structure(project_id, new_struct)
                      manual_plan = {"structure": new_struct} # Update local var to trigger next block
                      print(f"‚úÖ [Auto-Pilot] ÏûêÎèô Í∏∞Ìöç ÏôÑÎ£å Î∞è Ï†ÄÏû•. (Duration: {target_duration_min}m)")
             except Exception as e:
                 print(f"‚ö†Ô∏è [Auto-Pilot] ÏûêÎèô Í∏∞Ìöç Ïã§Ìå®: {e}")
        
        if manual_plan and manual_plan.get("structure"):
            print(f"üìÑ [Auto-Pilot] ÏàòÎèô Í∏∞Ìöç Îç∞Ïù¥ÌÑ∞ Î∞úÍ≤¨! Í∏∞Ìöç Í∏∞Î∞ò ÎåÄÎ≥∏ ÏûëÏÑ± Î™®ÎìúÎ°ú Ï†ÑÌôòÌï©ÎãàÎã§.")
            plan_json = json.dumps(manual_plan.get("structure"), ensure_ascii=False)
            
            prompt = f"""You are a professional YouTube scriptwriter.
Write a full script based strictly on the following USER PLANNED STRUCTURE.

[User Plan & Title]
{plan_json}

[Reference Analysis]
{json.dumps(analysis, ensure_ascii=False)}

[Instructions]
1. You MUST follow the 'User Plan' structure (Hook, Body, Conclusion, etc).
2. The 'structure' contains specific Hooks and plot points selected by the user. Do NOT change them.
3. Use the 'Reference Analysis' only to enrich the content details.
4. Voice: Strictly SINGLE SPEAKER Narration or Monologue. 
5. NO DIALOGUE: Do not write conversations between different people (No "A: Hello, B: Hi").
6. Output the full script in Korean.

[Absolute Rules for TTS]
- NO character names or colons (e.g., "Narrator:", "Me:").
- NO parentheses or situational descriptions (e.g., "(music)", "(laughs)").
- NO special characters or emojis.
"""
            if style_key != "default":
                prompt += f"\n\n[Writing Style Directive]: {style_desc}\nApply this style strictly."
        else:
            # Original Logic
            prompt = prompts.AUTOPILOT_GENERATE_SCRIPT.format(
                analysis_json=json.dumps(analysis, ensure_ascii=False)
            )
            if style_key != "default":
                prompt += f"\n\n[Writing Style Directive]: {style_desc}\nApply this style strictly throughout the script."

        # request = type('obj', (object,), {"prompt": prompt, "temperature": 0.8})
        script = await gemini_service.generate_text(prompt, temperature=0.8)
        
        # [CRITICAL] 4Í∞ÄÏßÄ Í∏àÏßÄ Ìï≠Î™© Ï†ïÏ†ú (Í¥ÑÌò∏, ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ, Ïù¥Î™®Ìã∞ÏΩò, ÌôîÏûê ÌëúÏãú)
        import re
        if script:
            # 1. Í¥ÑÌò∏ÏôÄ Í∑∏ ÏïàÏùò ÎÇ¥Ïö© ÏÇ≠Ï†ú (Ïòà: (Î∞∞Í≤ΩÏùåÏïÖ), (ÏõÉÏùå))
            script = re.sub(r'\([^)]*\)', '', script)
            # 2. ÌÉÄÏûÑÏä§ÌÉ¨ÌîÑ Î∞è ÏãúÍ∞ÑÎåÄ ÏÇ≠Ï†ú (Ïòà: [0-5Ï¥à], [00:15])
            script = re.sub(r'\[[^\]]*\]', '', script)
            # 3. Î≥ÑÌëú Î∞è Íæ∏Î∞à Í∏∞Ìò∏ ÏÇ≠Ï†ú (**)
            script = re.sub(r'\*', '', script)
            # 4. Ïù¥Î™®Ìã∞ÏΩò Î∞è ÌäπÏàò Í∏∞Ìò∏ ÏÇ≠Ï†ú (ü§£, ‚ú®, üî• Îì±)
            script = re.sub(r'[^\w\s\d,.\?\!\"\'\. ]', '', script)
            # 5. ÌôîÏûê ÌëúÏãú ÏÇ≠Ï†ú (Ïòà: ÎÇò:, ÏÉÅÏÇ¨:, A:) - Î¨∏Ïû• ÏãúÏûë Î∂ÄÎ∂ÑÏùò Ïù¥Î¶ÑÍ≥º ÏΩúÎ°†
            script = re.sub(r'^[Í∞Ä-Ìû£\w\s]+[\s]*:[\s]*', '', script, flags=re.MULTILINE)
            # 6. Î∂àÌïÑÏöîÌïú Í≥µÎ∞± Î∞è Îπà Ï§Ñ Ï†ïÎ¶¨
            script = script.strip()
            script = re.sub(r'\n\s*\n', '\n', script)

        # Save script
        # Calculate approximate duration (char count / 15 chars per sec is rough, usually 5 chars/sec for speech)
        # Using a safer estimate provided by user input usually, but here auto-calc
        target_duration_sec = config_dict.get("duration_seconds", 300) 
        db.save_script(project_id, script, len(script), target_duration_sec)
        
        return script

    async def _generate_assets(self, project_id: int, script: str, config_dict: dict):
        all_video = config_dict.get("all_video", False)
        motion_method = config_dict.get("motion_method", "standard")
        image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))

        
        # Determine sequence duration based on method
        video_duration = 5.0
        if motion_method in ["extend", "slowmo"]:
            video_duration = 8.0

        # Get visual style prompt from presets
        style_presets = db.get_style_presets()
        style_data = style_presets.get(image_style_key, {})

        style_prefix = style_data.get("prompt_value", "photorealistic")
        
        # 1. Image Prompts
        # [CRITICAL FIX] Use actual target duration for image count calculation
        target_duration = config_dict.get("duration_seconds", 300)
        
        image_prompts = db.get_image_prompts(project_id)
        if not image_prompts:
            print(f"üñºÔ∏è [Auto-Pilot] Generating image prompts for {target_duration}s video...")
            # [NEW] Ï∫êÎ¶≠ÌÑ∞ Ï†ïÎ≥¥ Ï°∞Ìöå Î∞è Ï†ÑÎã¨
            characters = db.get_project_characters(project_id)
            image_prompts = await gemini_service.generate_image_prompts_from_script(script, target_duration, style_prefix, characters=characters)
            db.save_image_prompts(project_id, image_prompts)
            image_prompts = db.get_image_prompts(project_id)
            print(f"üñºÔ∏è [Auto-Pilot] Generated {len(image_prompts)} image prompts")

        # Determine how many scenes to make as video
        if all_video:
            video_scene_count = len(image_prompts)
            print(f"üé¨ [Auto-Pilot] 'ALL VIDEO' mode enabled. Generating {video_scene_count} video scenes.")
        else:
            video_scene_count = config_dict.get("video_scene_count", 0)
            print(f"üé¨ [Auto-Pilot] Video scene count set to: {video_scene_count}")

        # 2. Assets (Video/Image)
        from services.replicate_service import replicate_service
        async def process_scene(p, is_video: bool):
            scene_num = p.get("scene_number")
            if p.get("image_url") and not (is_video and not p.get("video_url")): 
                # Already has image, and if video requested, check if video exists
                if not (is_video and not p.get("video_url")):
                    return True
            
            prompt_en = p.get("prompt_en", "cinematic scene")
            now = config.get_kst_time()
            try:
                # Generate base image if not exists
                image_abs_path = None
                if p.get("image_url") and p.get("image_url").startswith("/output/"):
                    image_abs_path = os.path.join(config.OUTPUT_DIR, p.get("image_url").replace("/output/", ""))
                
                if not image_abs_path or not os.path.exists(image_abs_path):
                    # [CRITICAL] Determine aspect ratio based on Mode (Shorts vs Longform)
                    duration_sec = config_dict.get("duration_seconds", 300)
                    mode = config_dict.get("mode", "longform")
                    
                    if mode == "shorts":
                        aspect_ratio = "9:16"
                    elif mode == "longform":
                        aspect_ratio = "16:9"
                    else:
                        # Fallback to duration threshold
                        aspect_ratio = "16:9" if (duration_sec and duration_sec >= 60) else "9:16"
                    
                    print(f"üé® [Auto-Pilot] Generating image for Scene {scene_num} (Mode: {mode}, Duration: {duration_sec}s, Aspect Ratio: {aspect_ratio})")
                    images = await gemini_service.generate_image(prompt_en, aspect_ratio=aspect_ratio)

                    if not images: return False
                    
                    filename = f"img_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.png"
                    image_abs_path = os.path.join(config.OUTPUT_DIR, filename)
                    with open(image_abs_path, 'wb') as f: f.write(images[0])
                    db.update_image_prompt_url(project_id, scene_num, f"/output/{filename}")
                
                return True # Image only path success
            except Exception as e:
                print(f"‚ö†Ô∏è [Auto-Pilot] Scene {scene_num} Asset Gen Error: {e}")
            return False

        # Pass 1: Image Generation (Ensure all scenes have base images)
        print("üñºÔ∏è [Auto-Pilot] Pass 1: Generating Base Images...")
        for i, p in enumerate(image_prompts):
            db.update_project(project_id, status=f"images_{i+1}/{len(image_prompts)}")
            await process_scene(p, False) # Only images in Pass 1

        # [CRITICAL] Re-fetch image_prompts from DB to get updated image_url paths
        image_prompts = db.get_image_prompts(project_id)

        # Pass 2: TTS Generation (Collected for each scene)
        print("üéôÔ∏è [Auto-Pilot] Pass 2: Generating Scene-based TTS...")
        db.update_project(project_id, status="generating_tts")
        provider = config_dict.get("voice_provider")
        voice_id = config_dict.get("voice_id")
        
        sorted_prompts = sorted(image_prompts, key=lambda x: x.get('scene_number', 0))
        
        if not provider or not voice_id:
             p_settings = db.get_project_settings(project_id) or {}
             provider = p_settings.get("voice_provider")
             voice_id = p_settings.get("voice_id") or p_settings.get("voice_name")
             
             # Fallback logic: If any scene has SFX, prioritize ElevenLabs
             has_sfx = any(p.get("sound_effects") not in [None, 'None', 'Unknown'] for p in sorted_prompts)
             if not provider and has_sfx:
                 provider = "elevenlabs"
                 if not voice_id:
                     voice_id = "4JJwo477JUAx3HV0T7n7" # Default ElevenLabs voice
             
             # Ultimate Fallback
             if not provider: provider = "google_cloud"
             if not voice_id: voice_id = "ko-KR-Neural2-A"
        
        scene_audio_map = {} # scene_number -> local_audio_path
        scene_audio_files = []
        scene_durations = []
        all_alignments = []
        cumulative_audio_time = 0.0
        temp_audios = []
        used_voices = set() # [NEW] Track voices
        import uuid

        # [NEW] Load settings for overrides
        p_settings = db.get_project_settings(project_id) or {}

        for i, p in enumerate(sorted_prompts):
            db.update_project(project_id, status=f"tts_{i+1}/{len(sorted_prompts)}")
            text = p.get('scene_text') or p.get('narrative') or p.get('script') or ""
            scene_num = p.get('scene_number')
            
            # [NEW] Voice Override
            scene_voice = p_settings.get(f"scene_{scene_num}_voice")
            current_voice_id = scene_voice if scene_voice else voice_id
            used_voices.add(current_voice_id) # Collect

            if not text:
                scene_durations.append(3.0)
                cumulative_audio_time += 3.0
                continue

            scene_filename = f"temp_tts_{project_id}_{i}_{uuid.uuid4()}.mp3"
            
            try:
                if provider == "elevenlabs":
                    result = await tts_service.generate_elevenlabs(text, current_voice_id, scene_filename)
                    if result and result.get("audio_path"):
                        audio_path = result["audio_path"]
                        duration = result.get("duration", 3.0)
                        alignment = result.get("alignment", [])
                        
                        temp_audios.append(audio_path)
                        scene_audio_files.append(audio_path)
                        scene_audio_map[scene_num] = audio_path
                        scene_durations.append(duration)
                        
                        for word_info in alignment:
                            all_alignments.append({
                                "word": word_info["word"],
                                "start": word_info["start"] + cumulative_audio_time,
                                "end": word_info["end"] + cumulative_audio_time
                            })
                        cumulative_audio_time += duration
                    else:
                        print(f"‚ö†Ô∏è Scene {i} ElevenLabs TTS Failed. Using default.")
                        scene_durations.append(3.0)
                        cumulative_audio_time += 3.0
                else:
                    s_out = None
                    if provider == "openai": s_out = await tts_service.generate_openai(text, current_voice_id, model="tts-1", filename=scene_filename)
                    elif provider == "gemini": s_out = await tts_service.generate_gemini(text, current_voice_id, filename=scene_filename)
                    else: s_out = await tts_service.generate_google_cloud(text, current_voice_id, filename=scene_filename)
                    
                    if s_out and os.path.exists(s_out):
                        temp_audios.append(s_out)
                        scene_audio_files.append(s_out)
                        scene_audio_map[scene_num] = s_out
                        
                        try:
                            from moviepy import AudioFileClip
                            ac = AudioFileClip(s_out)
                            dur = ac.duration
                            scene_durations.append(dur)
                            cumulative_audio_time += dur
                            ac.close()
                        except:
                            scene_durations.append(3.0)
                            cumulative_audio_time += 3.0
                    else:
                        scene_durations.append(3.0)
                        cumulative_audio_time += 3.0

                # [NEW] Auto SFX Generation (if missing) 
                # First try to find in image_prompts (if column exists) or webtoon_scenes_json
                s_desc = p.get('sound_effects')
                if not s_desc:
                    # Try to extract from webtoon_scenes_json
                    w_json = p_settings.get('webtoon_scenes_json')
                    if w_json:
                        try:
                            w_scenes = json.loads(w_json)
                            if i < len(w_scenes):
                                s_desc = w_scenes[i].get('sound_effects')
                        except: pass

                sfx_k = f"scene_{scene_num}_sfx"
                if s_desc and s_desc not in ['None', 'Unknown'] and len(s_desc) > 2 and not p_settings.get(sfx_k):
                    try:
                        sfx_p_str = re.sub(r'[^\w\s,]', '', s_desc)
                        print(f"üîä [Auto-Pilot] Generating SFX for scene {scene_num}: {sfx_p_str}")
                        sfx_d = await tts_service.generate_sound_effect(sfx_p_str[:100])
                        if sfx_d:
                            sfx_dr = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "sound")
                            os.makedirs(sfx_dr, exist_ok=True)
                            sfx_fn = f"sfx_scene_{scene_num:03d}_auto.mp3"
                            sfx_pth = os.path.join(sfx_dr, sfx_fn)
                            with open(sfx_pth, "wb") as f:
                                f.write(sfx_d)
                            db.update_project_setting(project_id, sfx_k, sfx_fn)
                            print(f"‚úÖ [Auto-Pilot] SFX Saved: {sfx_fn}")
                    except Exception as se:
                        print(f"‚ö†Ô∏è [Auto-Pilot] SFX Gen failed: {se}")

            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"‚ö†Ô∏è Scene {i} TTS Error: {e}")
                scene_durations.append(3.0)
                cumulative_audio_time += 3.0
        
        # All alignments Ï†ÄÏû• (ÎÇòÏ§ëÏóê Ï†ïÎ∞Ä ÏûêÎßâ ÏÉùÏÑ±Ïóê ÏÇ¨Ïö©)
        if all_alignments:
            alignment_path = os.path.join(config.OUTPUT_DIR, f"tts_alignment_{project_id}.json")
            with open(alignment_path, "w", encoding="utf-8") as f:
                json.dump(all_alignments, f, ensure_ascii=False, indent=2)
            db.update_project_setting(project_id, "tts_alignment_path", alignment_path)
            print(f"‚úÖ [Auto-Pilot] Saved {len(all_alignments)} word alignments")
        
        # Merge Audios
        final_filename = f"auto_tts_{project_id}.mp3"
        final_audio_path = os.path.join(config.OUTPUT_DIR, final_filename)
        
        total_duration = 0.0
        if scene_audio_files:
            try:
                from moviepy.audio.AudioClip import concatenate_audioclips
                from moviepy.audio.io.AudioFileClip import AudioFileClip
                clips = [AudioFileClip(f) for f in scene_audio_files]
                final_clip = concatenate_audioclips(clips)
                final_clip.write_audiofile(final_audio_path, logger=None)
                
                total_duration = final_clip.duration
                final_clip.close()
                for c in clips: c.close()
                
                # DB Save
                db.save_tts(project_id, provider, voice_id, final_audio_path, total_duration)
                
                # [CRITICAL] Calculate Cumulative Start Timings for Frontend
                cumulative_starts = []
                current_time = 0.0
                for dur in scene_durations:
                    cumulative_starts.append(current_time)
                    current_time += dur
                
                # 1. Save Image Start Timings (Expects START TIMES for frontend sync)
                timings_path = os.path.join(config.OUTPUT_DIR, f"image_timings_{project_id}.json")
                with open(timings_path, "w", encoding="utf-8") as f:
                     json.dump(cumulative_starts, f)
                db.update_project_setting(project_id, "image_timings_path", timings_path)
                
                # 2. Save Initial Subtitles
                # [NEW] ElevenLabs alignment Ï†ïÎ≥¥Í∞Ä ÏûàÏúºÎ©¥ Ï†ïÎ∞Ä ÏûêÎßâ ÏÉùÏÑ±
                auto_subtitles = []
                
                if all_alignments:
                    # Îã®Ïñ¥ ÌÉÄÏù¥Î∞çÏùÑ 2Ï§Ñ ÏûêÎßâÏúºÎ°ú Î≥ÄÌôò
                    auto_subtitles = self._alignment_to_subtitles(all_alignments, max_chars=40)
                    print(f"üìù [Auto-Pilot] Generated {len(auto_subtitles)} subtitles from TTS alignment (PRECISE)")
                else:
                    # Í∏∞Ï°¥ Î°úÏßÅ: Scene Í∏∞Î∞ò Í∑†Îì± Î∂ÑÌï†
                    for i, p in enumerate(sorted_prompts):
                        if i >= len(cumulative_starts): break
                        text = p.get('scene_text') or p.get('narrative') or p.get('script') or ""
                        if not text:
                            continue
                        
                        chunks = split_text_to_subtitle_chunks(text, max_chars_per_line=20, max_lines=2)
                        if not chunks:
                            continue
                        
                        scene_start = cumulative_starts[i]
                        scene_duration = scene_durations[i]
                        chunk_duration = scene_duration / len(chunks)
                        
                        for j, chunk_text in enumerate(chunks):
                            chunk_start = scene_start + (j * chunk_duration)
                            chunk_end = chunk_start + chunk_duration
                            
                            auto_subtitles.append({
                                "text": chunk_text,
                                "start": round(chunk_start, 2),
                                "end": round(chunk_end, 2)
                            })
                    
                    print(f"üìù [Auto-Pilot] Generated {len(auto_subtitles)} subtitle segments (fallback mode)")
                
                sub_path = os.path.join(config.OUTPUT_DIR, f"subtitles_{project_id}.json")
                with open(sub_path, "w", encoding="utf-8") as f:
                    json.dump(auto_subtitles, f, ensure_ascii=False, indent=2)
                db.update_project_setting(project_id, "subtitle_path", sub_path)

                # 3. Save Timeline Images (Order mapping)
                timeline_images = [p.get('video_url') or p.get('image_url') for p in sorted_prompts]
                # Filter out None/Empty
                timeline_images = [img for img in timeline_images if img]
                
                tl_images_path = os.path.join(config.OUTPUT_DIR, f"timeline_images_{project_id}.json")
                with open(tl_images_path, "w", encoding="utf-8") as f:
                    json.dump(timeline_images, f, ensure_ascii=False, indent=2)
                db.update_project_setting(project_id, "timeline_images_path", tl_images_path)
                
                print(f"‚úÖ [Auto-Pilot] Scene-based TTS & Subtitles Complete. Total: {total_duration:.2f}s, Scenes: {len(scene_durations)}")
                
                # [NEW] Save Stats
                db.update_project_setting(project_id, "stats_audio_duration_sec", f"{total_duration:.2f}")
                db.update_project_setting(project_id, "stats_used_voices", json.dumps(list(used_voices), ensure_ascii=False))
                
            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"‚ùå Audio Merge Failed: {e}")
                # Fallback to single file gen logic if merge fails?
        else:
             print("‚ùå No audio generated.")
        
        # [NEW] Pass 3: Video Generation (Now we have both Images and Audio)
        print("üìπ [Auto-Pilot] Pass 3: Generating Video Components...")
        video_engine = config_dict.get("video_engine", "wan")
        from services.akool_service import akool_service

        # Re-fetch prompts to get latest image/audio URLs
        image_prompts = db.get_image_prompts(project_id)
        p_settings = db.get_project_settings(project_id) or {} # [NEW] Load settings
        
        for i, p in enumerate(image_prompts):
            is_vid = i < video_scene_count
            if not is_vid: continue
            
            scene_num = p.get("scene_number")
            db.update_project(project_id, status=f"videos_{i+1}/{video_scene_count}")
            
            image_url = p.get("image_url")
            if not image_url: continue
            image_abs_path = os.path.join(config.OUTPUT_DIR, image_url.replace("/output/", ""))
            
            now = config.get_kst_time()
            
            # [Smart Engine Switch]
            scene_text = p.get("scene_text", "").strip()
            has_dialogue = bool(scene_text and len(scene_text) > 1 and scene_text != "None")
            
            # [NEW] Check LipSync Preference
            use_lipsync_val = p_settings.get("use_lipsync")
            use_lipsync = True
            if use_lipsync_val is not None:
                if isinstance(use_lipsync_val, str): use_lipsync = (use_lipsync_val.lower() == 'true' or use_lipsync_val == '1')
                else: use_lipsync = bool(use_lipsync_val)
            try:
                # [SMART ENGINE SWITCH]
                # Priority:
                # 1. Manual Override (from planning/settings)
                # 2. Logic (Dialogue + Lipsync -> Akool, else -> Wan)
                
                manual_engine = p_settings.get(f"scene_{scene_num}_engine")
                if manual_engine in ["wan", "akool", "image"]:
                    local_engine = manual_engine
                    print(f"üéØ [Manual Override] Scene {scene_num} -> {local_engine}")
                else:
                    local_engine = "akool" if (has_dialogue and use_lipsync) else "wan"
                
                # [EXPERIMENTAL] Í±¥ÎÑàÎõ∞Í∏∞ Î°úÏßÅ Î≥¥ÏôÑ -> [UPDATED] Image ÏóîÏßÑÎèÑ ÎπÑÎîîÏò§ ÌååÏùº ÏÉùÏÑ± (2D Pan/Zoom)
                if local_engine == "image":
                    print(f"üñºÔ∏è [Image-Only] Scene {scene_num} using 2D Pan/Zoom Motion...")
                    # Motion type determined by manual override or default 'zoom_in'
                    motion_type = p_settings.get(f"scene_{scene_num}_motion", "zoom_in")
                    
                    # Create 2D Motion Video
                    motion_bytes = await video_service.create_image_motion_video(
                        image_path=image_abs_path,
                        duration=video_duration,
                        motion_type=motion_type,
                        width=1080, height=1920 # Default vertical shorts
                    )
                    
                    if motion_bytes:
                        filename = f"vid_img_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                        out = os.path.join(config.OUTPUT_DIR, filename)
                        with open(out, 'wb') as f: f.write(motion_bytes)
                        db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
                    continue

                # [SPECIAL] ÎßåÏïΩ Wan Î™®ÎìúÏù¥Í≥† Îß§Îâ¥Ïñº Ìö®Í≥ºÍ∞Ä ÏûàÏúºÎ©¥ ÌîÑÎ°¨ÌîÑÌä∏ Î≥¥Í∞ï
                base_visual = p.get('prompt_en') or p.get('visual_desc') or "Cinematic motion"
                manual_motion_desc = p_settings.get(f"scene_{scene_num}_motion_desc")
                
                if local_engine == "wan":
                    if manual_motion_desc:
                        # ÏÇ¨Ïö©Ïûê/AIÍ∞Ä ÏßÄÏ†ïÌïú Íµ¨Ï≤¥Ï†ÅÏù∏ ÏõÄÏßÅÏûÑ(Ïòà: Î∂àÍ∏∏Ïù¥ ÌôúÌôú ÌÉÄÏò§Î¶Ñ)Ïù¥ ÏûàÏúºÎ©¥ Ïù¥Î•º Ïö∞ÏÑ†Ïãú
                        final_prompt = f"{base_visual}, {manual_motion_desc}"
                        print(f"üî• [Wan Content Motion] Scene {scene_num}: {manual_motion_desc}")
                    else:
                        final_prompt = f"{base_visual}, smooth motion"
                    
                    # Ïπ¥Î©îÎùº Ïù¥Îèô Ï∂îÍ∞Ä
                    manual_motion = p_settings.get(f"scene_{scene_num}_motion")
                    if manual_motion:
                        motion_map = {
                            "zoom_in": "dramatic zoom in",
                            "zoom_out": "dramatic zoom out",
                            "pan_left": "cinematic pan left",
                            "pan_right": "cinematic pan right",
                            "tilt_up": "cinematic tilt up",
                            "tilt_down": "cinematic tilt down",
                            "shake": "handheld camera shake"
                        }
                        if manual_motion in motion_map:
                            final_prompt += f", {motion_map[manual_motion]}"
                            print(f"üé¨ [Wan Camera Move] Scene {scene_num}: {manual_motion}")
                else:
                    final_prompt = base_visual

                print(f"ü§ñ [Auto-Switch] Scene {scene_num}: Dialogue={has_dialogue} -> Engine={local_engine}")

                if local_engine == "akool":
                    audio_abs_path = scene_audio_map.get(scene_num)
                    if not audio_abs_path: 
                        print(f"‚ö†Ô∏è [Akool] No audio found for scene {scene_num}. Switching to Wan.")
                        local_engine = "wan" # Fallback if no audio
                    else:
                        print(f"üé≠ [Akool] Generating Talking Avatar for Scene {scene_num}...")
                        video_bytes = await akool_service.generate_talking_avatar(image_abs_path, audio_abs_path)
                        if video_bytes:
                            filename = f"vid_akool_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                            out = os.path.join(config.OUTPUT_DIR, filename)
                            with open(out, 'wb') as f: f.write(video_bytes)
                            db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
                
                if local_engine == "wan":
                    # Wan / Replicate (Enhanced for Camera Moves)
                    print(f"üìπ [Auto-Pilot] Generating Wan Video for Scene {scene_num}")
                    video_data = await replicate_service.generate_video_from_image(
                        image_abs_path, 
                        prompt=final_prompt,
                        duration=video_duration,
                        method=motion_method
                    )
                    if video_data:
                        filename = f"vid_wan_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                        out = os.path.join(config.OUTPUT_DIR, filename)
                        with open(out, 'wb') as f: f.write(video_data)
                        db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
            except Exception as ve:
                print(f"‚ö†Ô∏è [Auto-Pilot] Video generation failed for Scene {scene_num}: {ve}")

        # Cleanup temps
        for f in temp_audios:
            try: os.remove(f)
            except: pass

    async def _generate_thumbnail(self, project_id: int, script: str, config_dict: dict):
        """ÎåÄÎ≥∏ Í∏∞Î∞ò Ïç∏ÎÑ§Ïùº ÏûêÎèô Í∏∞Ìöç Î∞è ÏÉùÏÑ±"""
        print(f"üé® [Auto-Pilot] Ïç∏ÎÑ§Ïùº ÏûêÎèô ÏÉùÏÑ± Ï§ë... Project: {project_id}")
        
        # 1. Ïç∏ÎÑ§Ïùº Í∏∞Ìöç (Hook & Visual Concept)
        hook_text = "Must Watch"
        visual_concept = "A high quality dramatic scene"
        
        try:
            # [NEW] Use the better prompt for hook text
            project_settings = db.get_project_settings(project_id) or {}
            image_style = config_dict.get("image_style") or project_settings.get("image_style", "realistic")
            thumb_style = config_dict.get("thumbnail_style") or project_settings.get("thumbnail_style", "face")
            
            # Get character info for better context
            characters = db.get_project_characters(project_id)
            char_context = ""
            if characters:
                char_names = [c.get("name") for c in characters if c.get("name")]
                char_context = f"\n[Featured Characters]: {', '.join(char_names)}"

            hook_prompt = prompts.GEMINI_THUMBNAIL_HOOK_TEXT.format(
                script=f"{script[:2000]}{char_context}",
                thumbnail_style=thumb_style,
                image_style=image_style,
                target_language="ko" # Default for now
            )
            
            hook_result = await gemini_service.generate_text(hook_prompt, temperature=0.7)
            import re
            json_match = re.search(r'\{[\s\S]*\}', hook_result)
            if json_match:
                hook_data = json.loads(json_match.group())
                candidates = hook_data.get("texts", [])
                if candidates:
                    hook_text = candidates[0] # Pick the strongest hook
            
            # [NEW] Generate a matching visual concept (Image Prompt)
            # Use THUMBNAIL_IDEA_PROMPT as a secondary pass or merge logic
            idea_prompt = prompts.THUMBNAIL_IDEA_PROMPT.format(
                topic=project_settings.get("topic", "AI Video"),
                script_summary=script[:1000]
            )
            idea_result = await gemini_service.generate_text(idea_prompt, temperature=0.7)
            json_match_idea = re.search(r'\{[\s\S]*\}', idea_result)
            if json_match_idea:
                idea_data = json.loads(json_match_idea.group())
                visual_concept = idea_data.get("image_prompt", visual_concept)
                
        except Exception as e:
            print(f"‚ö†Ô∏è [Auto-Pilot] Thumbnail Planning Error: {e}")
            # Fallback to project title if hook fails
            hook_text = project_settings.get("title", "Must Watch") if project_id else "Must Watch"

        # 2. Î∞∞Í≤Ω Ïù¥ÎØ∏ÏßÄ ÏÉùÏÑ±
        try:
            # [NEW] Art Style & Layout Inheritance
            image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))
            style_presets = db.get_style_presets()
            style_data = style_presets.get(image_style_key, {})
            style_prefix = style_data.get("prompt_value", "photorealistic")

            # [NEW] Layout Style
            thumbnail_style_key = config_dict.get("thumbnail_style", "face")
            thumb_presets = db.get_thumbnail_style_presets()
            thumb_preset = thumb_presets.get(thumbnail_style_key, {})
            layout_desc = thumb_preset.get("prompt", "")
            
            # [NEW] Character Incorporation
            characters = db.get_project_characters(project_id)
            char_desc = ""
            if characters:
                # Use the first 1-2 characters to keep prompt focused
                char_lines = []
                for c in characters[:2]:
                    char_lines.append(c.get("prompt_en", ""))
                char_desc = " Featuring: " + ", ".join(char_lines)
            
            # Combine everything for a consistent look
            final_thumb_prompt = f"ABSOLUTELY NO TEXT. Style: {style_prefix}. Composition: {layout_desc}. Subjects: {visual_concept}.{char_desc}. 8k, high quality."

            # [CRITICAL] Determine aspect ratio based on duration (Long-form vs Shorts)
            duration_sec = config_dict.get("duration_seconds", 300)
            aspect_ratio = "16:9" if duration_sec > 60 else "9:16"
            
            print(f"üé® [Auto-Pilot] Generating thumbnail background. Style: {image_style_key}, Aspect: {aspect_ratio}")
            print(f"üìù Prompt: {final_thumb_prompt[:120]}...")
            
            images = None
            try:
                images = await gemini_service.generate_image(final_thumb_prompt, aspect_ratio=aspect_ratio)
            except Exception as e:
                msg = f"‚ùå [Auto-Pilot] Thumbnail Image Gen Failed: {e}"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.datetime.now()}] {msg}\n")
                except: pass
                
                # [FALLBACK] Try a safe, generic prompt if the specific one was blocked
                print("üîÑ [Auto-Pilot] Retrying with generic thumbnail prompt due to safety/filter...")
                generic_prompt = f"Minimal aesthetic abstract background, Style: {style_prefix}, 8k, high quality"
                try:
                    images = await gemini_service.generate_image(generic_prompt, aspect_ratio=aspect_ratio)
                except Exception as e2:
                    print(f"‚ùå [Auto-Pilot] Final fallback failed: {e2}")
            
            if not images: 
                print("‚ö†Ô∏è [Auto-Pilot] No images generated for thumbnail. Skipping synthesis.")
                return

            now = config.get_kst_time()
            bg_filename = f"thumb_bg_{project_id}_{now.strftime('%H%M%S')}.png"
            bg_path = os.path.join(config.OUTPUT_DIR, bg_filename)
            with open(bg_path, 'wb') as f: f.write(images[0])
            
            # 3. ÌÖçÏä§Ìä∏ Ìï©ÏÑ± (Ï†ÄÏû•Îêú ÏÑ§Ï†ï Î∞òÏòÅ)
            from services.thumbnail_service import thumbnail_service
            final_filename = f"thumbnail_{project_id}_{now.strftime('%H%M%S')}.jpg"
            final_path = os.path.join(config.OUTPUT_DIR, final_filename)
            
            # [PRIORITY 1] Check Autopilot Config / Project Settings for Explicit Style
            project_settings = db.get_project_settings(project_id) or {}
            requested_style = config_dict.get("thumbnail_style") or project_settings.get("thumbnail_style")
            
            text_layers = []
            
            if requested_style:
                text_layers = thumbnail_service.get_style_recipe(requested_style, hook_text)
            
            # [PRIORITY 2] Fallback to Project 1 Template
            elif (saved_thumb_data := db.get_thumbnails(1)) and saved_thumb_data.get("full_settings"):
                layers = saved_thumb_data["full_settings"].get("layers", [])
                
                # Find main text layer (biggest font size)
                main_layer_idx = 0
                max_size = 0
                for i, l in enumerate(layers):
                    fs = int(l.get("font_size", 0))
                    if fs > max_size:
                        max_size = fs
                        main_layer_idx = i
                
                # Copy and Replace Text
                import copy
                text_layers = copy.deepcopy(layers)
                if text_layers and len(text_layers) > main_layer_idx:
                     text_layers[main_layer_idx]["text"] = hook_text
            
            else:
                # [PRIORITY 3] Default Fallback
                text_layers = thumbnail_service.get_style_recipe("mystery", hook_text)

            success = thumbnail_service.create_thumbnail(bg_path, text_layers, final_path)
            
            if success:
                web_path = f"/output/{final_filename}"
                db.update_project_setting(project_id, "thumbnail_url", web_path)
                msg = f"‚úÖ [Auto-Pilot] Ïç∏ÎÑ§Ïùº ÏÉùÏÑ± ÏôÑÎ£å: {web_path}"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.datetime.now()}] {msg}\n")
                except: pass
            else:
                msg = "‚ùå [Auto-Pilot] Ïç∏ÎÑ§Ïùº ÌÖçÏä§Ìä∏ Ìï©ÏÑ± Ïã§Ìå® (create_thumbnail returned False)"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.datetime.now()}] {msg}\n")
                except: pass
            
            try: os.remove(bg_path)
            except: pass
            
        except Exception as e:
            msg = f"‚ùå [Auto-Pilot] Ïç∏ÎÑ§Ïùº ÏÉùÏÑ± ÏòàÏô∏: {e}"
            print(msg)
            try:
                with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                    df.write(f"[{datetime.datetime.now()}] {msg}\n")
            except: pass

    async def _render_video(self, project_id: int):
        images_data = db.get_image_prompts(project_id)
        tts_data = db.get_tts(project_id)
        script_data = db.get_script(project_id)
        settings = db.get_project_settings(project_id) or {}
        
        # 1. Load Subtitles (Prefer Saved)
        # 1. Load Subtitles (Prefer Saved)
        subs = []
        
        # [NEW] Check user preference for subtitles
        use_sub_val = settings.get("use_subtitles")
        use_subtitles = True # Default
        if use_sub_val is not None:
            if isinstance(use_sub_val, str): use_subtitles = (use_sub_val.lower() == 'true' or use_sub_val == '1')
            else: use_subtitles = bool(use_sub_val)

        if use_subtitles and tts_data:
            subtitle_path = settings.get("subtitle_path")
            if subtitle_path and os.path.exists(subtitle_path):
                try:
                    with open(subtitle_path, "r", encoding="utf-8") as f:
                        subs = json.load(f)
                except: pass
                
            if not subs:
                print("üîç [Auto-Pilot] No saved subtitles found. Generating via Whisper...")
                try:
                    audio_path = tts_data["audio_path"]
                    subs = video_service.generate_aligned_subtitles(audio_path, script_data["full_script"])
                except Exception as sub_e: 
                    print(f"‚ö†Ô∏è Subtitle Gen Error: {sub_e}")
            
            if not subs: 
                subs = video_service.generate_smart_subtitles(script_data["full_script"], tts_data["duration"])
        elif not use_subtitles:
            print("üö´ [Auto-Pilot] Subtitles disabled manually.")
        else:
            print("‚ö†Ô∏è [Auto-Pilot] Cannot generate subtitles: TTS data missing.")

        # 2. Load Timeline Images
        # [FIX] Always use fresh DB data from image_prompts (includes video_url from Pass 3)
        # The timeline_images_path JSON file is created during Pass 2 (before video generation)
        # so it may not contain the latest video_url values.
        images = []
        sorted_prompts = sorted(images_data, key=lambda x: x.get('scene_number', 0))
        for img in sorted_prompts:
            # Priority: video_url (motion video) > image_url (static image)
            best_url = img.get("video_url") or img.get("image_url")
            if not best_url: 
                continue
            # Convert web path to absolute path
            if best_url.startswith("/output/"):
                fpath = os.path.join(config.OUTPUT_DIR, best_url.replace("/output/", ""))
            else:
                fpath = os.path.join(config.OUTPUT_DIR, best_url.split("/")[-1])
            
            if os.path.exists(fpath): 
                images.append(fpath)
                print(f"üì∏ [Auto-Pilot] Scene {img.get('scene_number')}: Using {'video' if best_url.endswith('.mp4') else 'image'} - {os.path.basename(fpath)}")
                
        audio_path = tts_data["audio_path"] if tts_data else None
        output_filename = f"autopilot_{project_id}_{config.get_kst_time().strftime('%H%M%S')}.mp4"

        # [IMPROVED] Calculate Durations from Start Timings
        image_durations = 5.0 # Default fallback
        timings_path = settings.get("image_timings_path")
        
        smart_sync_enabled = False
        if tts_data and timings_path and os.path.exists(timings_path):
            try:
                with open(timings_path, "r", encoding="utf-8") as f:
                    loaded_starts = json.load(f)
                
                if loaded_starts:
                    # If the file contains DURATIONS (old format), we need to detect it.
                    # Usually start times begin with 0.0. 
                    # If there are many values and sum is > total_duration, then if it's start times, the last value would be < total_duration.
                    # Best check: Is it monotonically increasing?
                    is_pacing_format = all(x < y for x, y in zip(loaded_starts, loaded_starts[1:])) if len(loaded_starts) > 1 else True
                    
                    if is_pacing_format:
                        # Convert Start Times to Durations
                        total_dur = tts_data["duration"]
                        durations = []
                        for i in range(len(loaded_starts)):
                            if i < len(loaded_starts) - 1:
                                durations.append(loaded_starts[i+1] - loaded_starts[i])
                            else:
                                durations.append(max(2.0, total_dur - loaded_starts[i]))
                        image_durations = durations
                    else:
                        # Old format: Durations
                        image_durations = loaded_starts
                    
                    # Align with images count
                    if len(image_durations) >= len(images):
                        image_durations = image_durations[:len(images)]
                    else:
                        rem_dur = tts_data["duration"] - sum(image_durations) if isinstance(image_durations, list) else 0
                        rem_cnt = len(images) - len(image_durations)
                        if rem_cnt > 0:
                            avg = max(3.0, rem_dur / rem_cnt)
                            image_durations = image_durations + [avg] * rem_cnt

                    print(f"‚úÖ [Auto-Pilot] Start-Time Sync Applied: {len(image_durations)} scenes")
                    smart_sync_enabled = True
            except Exception as e:
                print(f"‚ö†Ô∏è Failed to load smart timings: {e}")

        # 2. Fallback to Simple N-Division
        if not smart_sync_enabled:
            total_dur = tts_data["duration"] if tts_data else (len(images) * 5.0)
            image_durations = total_dur / len(images) if images else 5.0
            print(f"‚ö†Ô∏è [Auto-Pilot] Fallback to N-Division Sync ({image_durations if not isinstance(image_durations, list) else 'list'}s per image)")
        
        # [NEW] Determine Resolution based on App Mode
        app_mode = settings.get("app_mode", "longform")
        resolution = (1920, 1080) if app_mode == "longform" else (1080, 1920)
        print(f"üé¨ [Auto-Pilot] Rendering video with resolution: {resolution} (Mode: {app_mode})")

        # [NEW] Collect SFX Mapping
        sfx_map = {}
        for i, img_obj in enumerate(sorted_prompts):
            s_num = img_obj.get("scene_number")
            sfx_filename = settings.get(f"scene_{s_num}_sfx")
            if sfx_filename:
                # Resolve path
                sfx_abs_path = os.path.join(config.OUTPUT_DIR, str(project_id), "assets", "sound", sfx_filename)
                if os.path.exists(sfx_abs_path):
                    sfx_map[s_num] = sfx_abs_path

        # [NEW] Collect Focal Points
        f_points = [p.get("focal_point_y", 0.5) for p in sorted_prompts]

        final_path = video_service.create_slideshow(
            images=images, audio_path=audio_path, output_filename=output_filename,
            duration_per_image=image_durations, subtitles=subs, project_id=project_id,
            resolution=resolution, subtitle_settings=settings, sfx_map=sfx_map,
            focal_point_ys=f_points
        )

        db.update_project_setting(project_id, "video_path", f"/output/{output_filename}")
        db.update_project(project_id, status="rendered")

    async def _run_topview_workflow(self, project_id: int, config_dict: dict):
        """TopView APIÎ•º Ïù¥Ïö©Ìïú Ïª§Î®∏Ïä§ ÎπÑÎîîÏò§ ÏÉùÏÑ± ÏõåÌÅ¨ÌîåÎ°úÏö∞"""
        product_url = config_dict.get("product_url")
        if not product_url:
            print("‚ö†Ô∏è [TopView] Product URL is missing")
            db.update_project(project_id, status="error")
            return

        print(f"üõçÔ∏è [TopView] Starting Commerce Workflow for {product_url}")
        db.update_project(project_id, status="topview_requested")

        # 1. ÌÉúÏä§ÌÅ¨ ÏãúÏûë
        from services.topview_service import topview_service
        result = await topview_service.create_video_by_url(product_url)
        
        if not result or (isinstance(result, dict) and "id" not in result):
            print(f"‚ùå [TopView] Failed to start task: {result}")
            db.update_project(project_id, status="error")
            return

        task_id = result["id"]
        db.update_project_setting(project_id, "topview_task_id", task_id)
        db.update_project(project_id, status="topview_processing")

        # 2. Ìè¥ÎßÅ (ÏÉÅÌÉú ÌôïÏù∏)
        max_retries = 60 # ÏïΩ 10Î∂Ñ (10Ï¥à Í∞ÑÍ≤©)
        retry_count = 0
        video_url = None

        while retry_count < max_retries:
            await asyncio.sleep(10)
            status_data = await topview_service.get_task_status(task_id)
            
            if not status_data:
                retry_count += 1
                continue

            status = status_data.get("status")
            print(f"‚è≥ [TopView] Processing... ({status})")

            if status == "completed":
                video_url = status_data.get("video_url")
                break
            elif status == "failed":
                print(f"‚ùå [TopView] Task failed: {status_data}")
                db.update_project(project_id, status="error")
                return
            
            retry_count += 1

        if not video_url:
            print("‚ùå [TopView] Task timed out or no video URL received")
            db.update_project(project_id, status="error")
            return

        # 3. ÎπÑÎîîÏò§ Îã§Ïö¥Î°úÎìú Î∞è Ï†ÄÏû•
        db.update_project(project_id, status="topview_downloading")
        target_path = os.path.join(config.OUTPUT_DIR, f"topview_{project_id}.mp4")
        
        try:
            async with httpx.AsyncClient() as client:
                resp = await client.get(video_url, timeout=300)
                with open(target_path, "wb") as f:
                    f.write(resp.content)
            
            # DB ÏóÖÎç∞Ïù¥Ìä∏
            web_path = f"/output/topview_{project_id}.mp4"
            db.update_project_setting(project_id, "video_path", web_path)
            db.update_project(project_id, status="rendered")
            
            print(f"‚úÖ [TopView] Video generated and saved: {target_path}")

            # 4. YouTube ÏóÖÎ°úÎìú (Í∏∞Î≥∏ Î°úÏßÅ ÌôúÏö©)
            await self._upload_video(project_id, target_path)
            
        except Exception as e:
            print(f"‚ùå [TopView] Download/Save Error: {e}")
            db.update_project(project_id, status="error")

    async def _upload_video(self, project_id: int, video_path: str):
        now = config.get_kst_time()
        
        # Load settings
        p_settings = db.get_project_settings(project_id) or {}
        
        # Determine Privacy & Schedule
        privacy = p_settings.get("upload_privacy", "private")
        schedule_at = p_settings.get("upload_schedule_at")
        
        publish_time = None
        if privacy == "scheduled" or schedule_at:
            if schedule_at:
                try:
                    # Validate format or parse
                    # Format expected: 2026-02-12T08:00:00 or ISO
                    if "T" not in schedule_at:
                        # Simple format YYYY-MM-DD HH:MM
                        dt = datetime.strptime(schedule_at, "%Y-%m-%d %H:%M")
                        publish_time = dt.isoformat()
                    else:
                        publish_time = schedule_at
                except:
                    print(f"‚ö†Ô∏è [Upload] Invalid schedule format: {schedule_at}. Falling back to default.")
            
            if not publish_time:
                # Default: Next day 8 AM
                publish_time = (now + timedelta(days=1)).replace(hour=8, minute=0, second=0).isoformat()
            
            # YouTube API requires privacyStatus to be 'private' for scheduled uploads
            privacy = "private" 

        ai_title = p_settings.get("title") or f"AI Auto Video {now.date()}"
        ai_desc = p_settings.get("description") or "#Shorts #AI"
        ai_tags_str = p_settings.get("hashtags") or "ai,shorts"
        ai_tags = [t.strip() for t in ai_tags_str.split(",") if t.strip()]

        # [NEW] Multi-Channel Support: Resolve Token Path
        token_path = None
        channel_id = p_settings.get("youtube_channel_id")
        if channel_id:
            try:
                # get_channel must be implemented in database.py
                channel = db.get_channel(channel_id)
                if channel and channel.get("credentials_path"):
                    cand_path = channel["credentials_path"]
                    if os.path.exists(cand_path):
                        token_path = cand_path
                        print(f"üîë [Upload] Using channel token: {channel.get('name')} ({token_path})")
            except Exception as ce:
                print(f"‚ö†Ô∏è [Upload] Failed to resolve channel {channel_id}: {ce}")

        try:
            # 1. Video Upload
            print(f"üöÄ [Upload] Starting YouTube upload (Privacy: {privacy}, Schedule: {publish_time}, Channel: {channel_id or 'Default'})")
            response = youtube_upload_service.upload_video(
                file_path=video_path, 
                title=ai_title,
                description=ai_desc, 
                tags=ai_tags,
                privacy_status=privacy, 
                publish_at=publish_time,
                token_path=token_path # Pass token path
            )
            
            # 2. Thumbnail Upload (Wait a bit for video to be indexed)
            video_id = response.get("id")
            if video_id:
                print(f"‚úÖ [Auto-Pilot] Video uploaded: https://youtu.be/{video_id}. Waiting 10s for thumbnail upload...")
                await asyncio.sleep(10)
                
                settings = db.get_project_settings(project_id)
                thumb_url = settings.get("thumbnail_url")
                
                if thumb_url:
                    # /output/filename.jpg -> LOCAL_PATH/filename.jpg
                    fname = thumb_url.split("/")[-1]
                    thumb_path = os.path.join(config.OUTPUT_DIR, fname)
                    
                    if os.path.exists(thumb_path):
                        print(f"üñºÔ∏è [Auto-Pilot] Uploading thumbnail: {thumb_path}")
                        try:
                            youtube_upload_service.set_thumbnail(video_id, thumb_path, token_path=token_path)
                            print(f"‚úÖ [Auto-Pilot] Thumbnail set successfully for {video_id}")
                        except Exception as te:
                            print(f"‚ö†Ô∏è Thumbnail upload failed: {te}")
                    else:
                        print(f"‚ö†Ô∏è Thumbnail file not found at {thumb_path}")
                else:
                    print(f"‚ö†Ô∏è No thumbnail_url found for project {project_id}")
            
            db.update_project_setting(project_id, "is_uploaded", 1)
        except Exception as e:
            print(f"‚ùå Upload failed: {e}")

    async def run_batch_workflow(self):
        """queued ÏÉÅÌÉúÏùò ÌîÑÎ°úÏ†ùÌä∏Î•º ÏàúÏ∞®Ï†ÅÏúºÎ°ú Î™®Îëê Ï≤òÎ¶¨"""
        if self.is_batch_running:
            print("‚ö†Ô∏è [Batch] Ïù¥ÎØ∏ ÏßÑÌñâ Ï§ëÏù∏ ÏùºÍ¥Ñ Ï≤òÎ¶¨ ÏûëÏóÖÏù¥ ÏûàÏäµÎãàÎã§.")
            return
            
        self.is_batch_running = True
        print("üö¶ [Batch] ÏùºÍ¥Ñ Ï†úÏûë ÌîÑÎ°úÏÑ∏Ïä§ ÏãúÏûë...")
        import asyncio
        
        try:
            while True:
                projects = db.get_all_projects()
                # FIFO: IDÍ∞Ä ÏûëÏùÄ ÏàúÏÑúÎåÄÎ°ú Ï≤òÎ¶¨
                queue = sorted([p for p in projects if p.get("status") == "queued"], key=lambda x: x['id'])
                
                if not queue:
                    print("üèÅ [Batch] ÎåÄÍ∏∞Ïó¥ ÏûëÏóÖÏùÑ Î™®Îëê ÏôÑÎ£åÌñàÏäµÎãàÎã§.")
                    break
                    
                project = queue[0]
                pid = project['id']
                print(f"‚ñ∂Ô∏è [Batch] ÌîÑÎ°úÏ†ùÌä∏ ÏãúÏûë: {project.get('topic')} (ID: {pid})")
                
                try:
                    # ÏÑ§Ï†ï Î°úÎìú
                    p_settings = db.get_project_settings(pid) or {}
                    
                    # [Logic Fix] ÏàúÏÑúÎåÄÎ°ú ÏßÑÌñâÌïòÍ∏∞ ÏúÑÌï¥ Ï†ÅÏ†àÌïú ÏãúÏûë ÏÉÅÌÉú Í≤∞Ï†ï
                    # 1. Ïù¥ÎØ∏ ÎåÄÎ≥∏Ïù¥ ÏûàÎäî Í≤ΩÏö∞ -> ÏûêÏÇ∞ ÏÉùÏÑ±Î∂ÄÌÑ∞
                    if p_settings.get("script") and len(p_settings.get("script").strip()) > 50:
                        print(f"üìÑ [Batch] Í∏∞Ï°¥ ÎåÄÎ≥∏ Î∞úÍ≤¨ (ID: {pid}). 'scripted' Îã®Í≥ÑÎ∂ÄÌÑ∞ ÏãúÏûëÌï©ÎãàÎã§.")
                        db.update_project(pid, status="scripted")
                    # 2. Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞Îäî ÏûàÎäî Í≤ΩÏö∞ -> Í∏∞Ìöç/ÎåÄÎ≥∏ Îã®Í≥ÑÎ∂ÄÌÑ∞
                    elif db.get_analysis(pid):
                        print(f"üìä [Batch] Î∂ÑÏÑù Îç∞Ïù¥ÌÑ∞ Î∞úÍ≤¨ (ID: {pid}). 'analyzed' Îã®Í≥ÑÎ∂ÄÌÑ∞ ÏãúÏûëÌï©ÎãàÎã§.")
                        db.update_project(pid, status="analyzed")
                    # 3. ÏïÑÎ¨¥Í≤ÉÎèÑ ÏóÜÎäî ÏÉà ÌîÑÎ°úÏ†ùÌä∏Ïù∏ Í≤ΩÏö∞ -> Ï≤òÏùå(Î∂ÑÏÑù)Î∂ÄÌÑ∞
                    else:
                        print(f"üÜï [Batch] Ïã†Í∑ú ÌîÑÎ°úÏ†ùÌä∏ (ID: {pid}). 'created' Îã®Í≥ÑÎ∂ÄÌÑ∞ ÏãúÏûëÌï©ÎãàÎã§.")
                        db.update_project(pid, status="created")
                    
                    config_dict = {
                        "script_style": p_settings.get("script_style", "default"),
                        "duration_seconds": p_settings.get("duration_seconds", 300),
                        "voice_provider": p_settings.get("voice_provider"),
                        "voice_id": p_settings.get("voice_id"),
                        "image_style": p_settings.get("image_style", "realistic"), 
                        "thumbnail_style": p_settings.get("thumbnail_style", "face"), 
                        "all_video": bool(p_settings.get("all_video", 0)),
                        "motion_method": p_settings.get("motion_method", "standard"),
                        "video_scene_count": p_settings.get("video_scene_count", 0),
                        "auto_thumbnail": True,
                        "auto_plan": p_settings.get("auto_plan", True),
                        "video_engine": p_settings.get("video_engine", "wan"),
                        "upload_privacy": p_settings.get("upload_privacy", "private"),
                        "upload_schedule_at": p_settings.get("upload_schedule_at")
                    }
                    
                    # ÏõåÌÅ¨ÌîåÎ°úÏö∞ Ïã§Ìñâ (Wait for completion)
                    await self.run_workflow(project.get('topic'), pid, config_dict)
                    print(f"‚úÖ [Batch] ÌîÑÎ°úÏ†ùÌä∏ ÏôÑÎ£å: {pid}")
                    
                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    print(f"‚ùå [Batch] ÌîÑÎ°úÏ†ùÌä∏ Ïã§Ìå® (ID: {pid}): {e}")
                    db.update_project(pid, status="error")
                    
                await asyncio.sleep(2)
        finally:
            self.is_batch_running = False
            print("üõë [Batch] ÏùºÍ¥Ñ Ï†úÏûë ÌîÑÎ°úÏÑ∏Ïä§ Ï¢ÖÎ£å")
    
    def _alignment_to_subtitles(self, alignments: list, max_chars: int = 40) -> list:
        """
        Îã®Ïñ¥ ÌÉÄÏù¥Î∞ç Ï†ïÎ≥¥Î•º 2Ï§Ñ ÏûêÎßâÏúºÎ°ú Î≥ÄÌôò (Ï†ïÎ∞Ä Ïã±ÌÅ¨)
        
        Args:
            alignments: [{"word": "ÏïàÎÖï", "start": 0.0, "end": 0.3}, ...]
            max_chars: ÏûêÎßâÎãπ ÏµúÎåÄ Í∏ÄÏûê Ïàò (2Ï§Ñ Í∏∞Ï§Ä)
        
        Returns:
            [{"text": "ÏûêÎßâ ÌÖçÏä§Ìä∏", "start": 0.0, "end": 1.5}, ...]
        """
        if not alignments:
            return []
        
        subtitles = []
        current_words = []
        current_text = ""
        block_start = None
        block_end = None
        
        for i, word_info in enumerate(alignments):
            word = word_info.get("word", "").strip()
            if not word:
                continue
            
            start = word_info.get("start", 0)
            end = word_info.get("end", start + 0.1)
            
            # ÏÉà Î∏îÎ°ù ÏãúÏûë
            if block_start is None:
                block_start = start
            
            # ÌÖçÏä§Ìä∏ ÎàÑÏ†Å
            test_text = f"{current_text} {word}".strip() if current_text else word
            
            # ÏµúÎåÄ Í∏ÄÏûê Ïàò Ï≤¥ÌÅ¨ ÎòêÎäî Î¨∏Ïû• Î∂ÄÌò∏Î°ú ÎÅäÍ∏∞
            is_sentence_end = word.endswith(('.', '?', '!', ','))
            should_break = len(test_text) > max_chars or is_sentence_end
            
            if should_break and current_text:
                # ÌòÑÏû¨ Î∏îÎ°ù Ï†ÄÏû•
                subtitles.append({
                    "text": current_text,
                    "start": round(block_start, 2),
                    "end": round(block_end, 2)
                })
                
                # ÏÉà Î∏îÎ°ù ÏãúÏûë
                current_text = word
                block_start = start
                block_end = end
            else:
                current_text = test_text
                block_end = end
        
        # ÎßàÏßÄÎßâ Î∏îÎ°ù
        if current_text:
            subtitles.append({
                "text": current_text,
                "start": round(block_start, 2),
                "end": round(block_end, 2)
            })
        
        return subtitles

    def get_queue_status(self):
        """ÌòÑÏû¨ ÎåÄÍ∏∞Ïó¥ ÏÉÅÌÉú Î∞òÌôò"""
        projects = db.get_all_projects()
        queued_projects = [p for p in projects if p.get("status") == "queued"]
        processing_projects = [p for p in projects if p.get("status") not in ["done", "error", "queued", "draft", "created"]]
        
        return {
            "is_running": self.is_batch_running,
            "queued_count": len(queued_projects),
            "processing_count": len(processing_projects),
            "queued_items": queued_projects[:10],  # ÏÉÅÏúÑ 10Í∞úÎßå
            "current_items": processing_projects
        }

    def add_to_queue(self, project_id: int):
        """ÌîÑÎ°úÏ†ùÌä∏Î•º ÎåÄÍ∏∞Ïó¥Ïóê Ï∂îÍ∞Ä"""
        db.update_project(project_id, status="queued")

    def clear_queue(self):
        """ÎåÄÍ∏∞Ïó¥ ÎπÑÏö∞Í∏∞"""
        projects = db.get_all_projects()
        for p in projects:
            if p.get("status") == "queued":
                db.update_project(p['id'], status="draft")

    async def start_batch_worker(self):
        """[NEW] ÌîÑÎ°úÏ†ùÌä∏ ÎåÄÍ∏∞Ïó¥ÏùÑ Í∞êÏãúÌïòÍ≥† ÏàúÏ∞®Ï†ÅÏúºÎ°ú Ï≤òÎ¶¨ÌïòÎäî ÏõåÏª§"""
        if self.is_batch_running:
            print("üöÄ [Auto-Pilot] Batch worker already running.")
            return

        self.is_batch_running = True
        print("üöÄ [Auto-Pilot] Batch worker started.")

        while True:
            try:
                # 1. 'queued' ÏÉÅÌÉúÏù∏ ÌîÑÎ°úÏ†ùÌä∏ Ï∞æÍ∏∞
                projects = db.get_all_projects()
                queued = [p for p in projects if p.get("status") == "queued"]

                if queued:
                    target = queued[0]
                    target_pid = target['id']
                    target_topic = target.get('topic', 'Auto-Webtoon')

                    print(f"üì¶ [Auto-Pilot] Processing queued project {target_pid} ({target_topic})...")
                    
                    # 2. Ïã§Ìñâ ÏÉÅÌÉúÎ°ú Ï†ÑÏù¥ (run_workflowÍ∞Ä Ïù∏ÏãùÌï† Ïàò ÏûàÍ≤å)
                    p_settings = db.get_project_settings(target_pid) or {}
                    
                    # ÎåÄÎ≥∏Ïù¥ ÏûàÏúºÎ©¥ Î∞îÎ°ú ÏóêÏÖã ÏÉùÏÑ± Îã®Í≥ÑÎ°ú, ÏóÜÏúºÎ©¥ Ï≤òÏùåÎ∂ÄÌÑ∞
                    if p_settings.get("script") and len(p_settings.get("script").strip()) > 10:
                        db.update_project(target_pid, status="scripted")
                    else:
                        db.update_project(target_pid, status="created")

                    # Ensure app_mode compatibility
                    if "mode" not in p_settings and "app_mode" in p_settings:
                        p_settings["mode"] = p_settings["app_mode"]

                    await self.run_workflow(target_topic, project_id=target_pid, config_dict=p_settings)
                    
                    print(f"‚úÖ [Auto-Pilot] Project {target_pid} processing complete.")
                
                await asyncio.sleep(10) # 10Ï¥àÎßàÎã§ ÌôïÏù∏
                
            except Exception as e:
                print(f"‚ùå [Auto-Pilot] Batch worker error: {e}")
                import traceback
                traceback.print_exc()
                await asyncio.sleep(20) # ÏóêÎü¨ Ïãú Ï¢Ä Îçî Í∏∏Í≤å ÎåÄÍ∏∞

autopilot_service = AutoPilotService()

