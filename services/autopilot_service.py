
import asyncio
import json
import os
import random
from datetime import datetime, timedelta
import httpx
from config import config
import database as db
from services.gemini_service import gemini_service
from services.prompts import prompts
from services.tts_service import tts_service
from services.video_service import video_service
from services.youtube_upload_service import youtube_upload_service
from services.topview_service import topview_service


def split_text_to_subtitle_chunks(text: str, max_chars_per_line: int = 20, max_lines: int = 2) -> list:
    """
    ê¸´ í…ìŠ¤íŠ¸ë¥¼ ìë§‰ìš© ì²­í¬ë¡œ ë¶„í• í•©ë‹ˆë‹¤.
    - í•œ ì¤„ë‹¹ ìµœëŒ€ max_chars_per_line ê¸€ì
    - í•œ í™”ë©´ì— ìµœëŒ€ max_lines ì¤„ (ê¸°ë³¸ 2ì¤„)
    - ë¬¸ì¥ ê²½ê³„(. ! ?)ë¥¼ ìš°ì„ ìœ¼ë¡œ ë¶„í• 
    
    Returns: List of subtitle text chunks (each chunk is max 2 lines)
    """
    if not text or not text.strip():
        return []
    
    text = text.strip()
    
    # ë¨¼ì € ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€)
    import re
    sentences = re.split(r'(?<=[.!?])\s+', text)
    
    chunks = []
    current_chunk_lines = []
    
    for sentence in sentences:
        sentence = sentence.strip()
        if not sentence:
            continue
        
        # ë¬¸ì¥ì„ ì¤„ ë‹¨ìœ„ë¡œ ë¶„í•  (max_chars_per_line ê¸°ì¤€)
        words = sentence.split()
        current_line = ""
        lines_from_sentence = []
        
        for word in words:
            test_line = f"{current_line} {word}".strip() if current_line else word
            if len(test_line) <= max_chars_per_line:
                current_line = test_line
            else:
                if current_line:
                    lines_from_sentence.append(current_line)
                current_line = word
        
        if current_line:
            lines_from_sentence.append(current_line)
        
        # í˜„ì¬ ì²­í¬ì— ì´ ë¬¸ì¥ì˜ ì¤„ë“¤ì„ ì¶”ê°€
        for line in lines_from_sentence:
            current_chunk_lines.append(line)
            
            # max_linesì— ë„ë‹¬í•˜ë©´ ì²­í¬ ìƒì„±
            if len(current_chunk_lines) >= max_lines:
                chunks.append("\n".join(current_chunk_lines))
                current_chunk_lines = []
    
    # ë‚¨ì€ ì¤„ë“¤ ì²˜ë¦¬
    if current_chunk_lines:
        chunks.append("\n".join(current_chunk_lines))
    
    return chunks


class AutoPilotService:
    def __init__(self):
        self.search_url = f"{config.YOUTUBE_BASE_URL}/search"
        self.config = {}  # Director Mode Configuration
        self.is_batch_running = False # [NEW] Batch Concurrency Lock

    async def run_workflow(self, keyword: str, project_id: int = None, config_dict: dict = None):
        """ì˜¤í† íŒŒì¼ëŸ¿ ì „ì²´ ì›Œí¬í”Œë¡œìš° ì‹¤í–‰"""
        print(f"ğŸš€ [Auto-Pilot] '{keyword}' ì‘ì—… ì‹œì‘")
        start_dt = datetime.now()
        db.update_project_setting(project_id, "stats_start_time", start_dt.strftime("%Y-%m-%d %H:%M:%S"))
        
        self.config = config_dict or {}
        if "auto_plan" not in self.config:
            self.config["auto_plan"] = True  # Always generate plan data by default
        
        # [NEW] TopView Commerce Mode Check
        creation_mode = self.config.get("creation_mode", "default")
        if creation_mode == "commerce":
            return await self._run_topview_workflow(project_id, self.config)
        
        try:
            # 1~2. ì†Œì¬ ë°œêµ´ ë° í”„ë¡œì íŠ¸ ìƒì„±
            if not project_id:
                video = await self._find_best_material(keyword)
                if not video: return
                project_name = f"[Auto] {keyword} - {video['snippet']['title'][:20]}"
                project_id = db.create_project(name=project_name, topic=keyword)
                db.update_project(project_id, status="created")
                current_status = "created"
            else:
                project = db.get_project(project_id)
                current_status = project.get('status', 'created')

            # 3. AI ë¶„ì„
            if current_status in ["created", "draft"]:
                db.update_project(project_id, status="analyzing") # [NEW] status for UI
                video = await self._find_best_material(keyword)
                analysis_result = await self._analyze_video(video)
                db.save_analysis(project_id, video, analysis_result)
                db.update_project(project_id, status="analyzed")
                current_status = "analyzed"

            # 4. ê¸°íš ë° ëŒ€ë³¸ ì‘ì„±
            if current_status == "analyzed":
                db.update_project(project_id, status="planning") # [NEW] status for UI
                analysis = db.get_analysis(project_id)
                script = await self._generate_script(project_id, analysis.get("analysis_result", {}), self.config)
                db.update_project_setting(project_id, "script", script)
                
                db.update_project(project_id, status="scripting") # [NEW] status for UI
                # [NEW] AI ì œëª© ë° ì„¤ëª… ìƒì„±
                await self._generate_metadata(project_id, script)
                
                db.update_project(project_id, status="scripted")
                current_status = "scripted"

            # 4.5 ìºë¦­í„° ì¶”ì¶œ (ì¼ê´€ì„± ìœ ì§€ìš©)
            if current_status == "scripted":
                script_data = db.get_script(project_id)
                if script_data:
                    await self._extract_characters(project_id, script_data["full_script"], self.config)
                current_status = "characters_ready"

            # 5. ì—ì…‹ ìƒì„± (ì´ë¯¸ì§€ & ì¸ë„¤ì¼ & ì˜¤ë””ì˜¤)
            if current_status == "characters_ready":
                script_data = db.get_script(project_id)
                full_script = script_data["full_script"]
                
                # 5-1. ì˜ìƒ ì†ŒìŠ¤ ìƒì„±
                db.update_project(project_id, status="generating_assets")
                await self._generate_assets(project_id, full_script, self.config)
                
                # [NEW] Ensure Metadata exists (Title, Description) - Re-run if skipped earlier
                settings = db.get_project_settings(project_id) or {}
                if not settings.get('title') or not settings.get('description'):
                    print(f"ğŸ“ [Auto-Pilot] Metadata missing for pid {project_id}. Generating...")
                    await self._generate_metadata(project_id, full_script)

                # 5-2. [NEW] ì¸ë„¤ì¼ ìë™ ìƒì„±
                if self.config.get('auto_thumbnail', True):
                    # Check if already exists to avoid duplicate gen
                    if not settings.get('thumbnail_url'):
                        db.update_project(project_id, status="generating_thumbnail")
                        await self._generate_thumbnail(project_id, full_script, self.config)

                db.update_project(project_id, status="tts_done")
                current_status = "tts_done"

            # 6. ì˜ìƒ ë Œë”ë§
            if current_status == "tts_done":
                await self._render_video(project_id)
                current_status = "rendered"

            # 7. ì—…ë¡œë“œ
            if current_status == "rendered":
                settings = db.get_project_settings(project_id)
                video_path = settings.get("video_path")
                if video_path:
                    abs_video_path = os.path.join(config.OUTPUT_DIR, video_path.replace("/output/", ""))
                    if os.path.exists(abs_video_path):
                        await self._upload_video(project_id, abs_video_path)
                        db.update_project(project_id, status="uploaded")
            
            # [NEW] Save Stats
            end_dt = datetime.now()
            duration_str = str(end_dt - start_dt).split('.')[0]
            db.update_project_setting(project_id, "stats_end_time", end_dt.strftime("%Y-%m-%d %H:%M:%S"))
            db.update_project_setting(project_id, "stats_total_duration", duration_str)
            
            db.update_project(project_id, status="done")
            print(f"âœ¨ [Auto-Pilot] ì‘ì—… ì™„ë£Œ! (ID: {project_id}, Time: {duration_str})")

        except Exception as e:
            print(f"âŒ [Auto-Pilot] ì˜¤ë¥˜ ë°œìƒ: {e}")
            db.update_project(project_id, status="error")

    async def _extract_characters(self, project_id: int, script_text: str, config_dict: dict = None):
        """ëŒ€ë³¸ì—ì„œ ìºë¦­í„° ì¶”ì¶œ ë° ì¼ê´€ì„± ìˆëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„± (ì´ë¯¸ ìˆìœ¼ë©´ ê±´ë„ˆëœ€)"""
        # [NEW] ì´ë¯¸ ìºë¦­í„°ê°€ ìˆ˜ë™ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        existing = db.get_project_characters(project_id)
        if existing:
            print(f"ğŸ‘¥ [Auto-Pilot] ì´ë¯¸ {len(existing)}ëª…ì˜ ìºë¦­í„°ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¶”ì¶œì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        print(f"ğŸ‘¥ [Auto-Pilot] ìºë¦­í„° ì¶”ì¶œ ì‹œì‘...")
        
        # [NEW] ë¹„ì£¼ì–¼ ìŠ¤íƒ€ì¼ ê²°ì •
        style_prefix = "photorealistic"
        if config_dict:
            image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))
            style_presets = db.get_style_presets()
            style_data = style_presets.get(image_style_key, {})
            style_prefix = style_data.get("prompt_value", "photorealistic")
        
        try:
            characters = await gemini_service.generate_character_prompts_from_script(script_text, visual_style=style_prefix)
            if characters:
                db.save_project_characters(project_id, characters)
                print(f"âœ… [Auto-Pilot] {len(characters)}ëª…ì˜ ìºë¦­í„°ë¥¼ ì‹ë³„í•˜ê³  ì €ì¥í–ˆìŠµë‹ˆë‹¤. (Style: {style_prefix})")
                
                # [NEW] ìºë¦­í„° ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ë° ì ìš© (ìµœëŒ€ 3ëª…)
                processed_chars = characters[:3]
                has_applied_reference = False
                
                for idx, char in enumerate(processed_chars):
                    try:
                        print(f"ğŸ‘¤ [Auto-Pilot] ìºë¦­í„° '{char['name']}' ({char['role']}) ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„± ì¤‘...")
                        detailed_style = style_data.get('prompt_value', style_prefix)
                        full_prompt = f"{char['prompt_en']}, {detailed_style}"
                        
                        # Portrait aspect ratio 1:1
                        images_bytes = await gemini_service.generate_image(
                            prompt=full_prompt,
                            num_images=1,
                            aspect_ratio="1:1"
                        )
                        
                        if images_bytes:
                            now = config.get_kst_time()
                            filename = f"char_{project_id}_{idx}_{now.strftime('%H%M%S')}.png"
                            file_path = os.path.join(config.OUTPUT_DIR, filename)
                            web_url = f"/output/{filename}"
                            
                            with open(file_path, "wb") as f:
                                f.write(images_bytes[0])
                            
                            # DB ì—…ë°ì´íŠ¸
                            db.update_character_image(project_id, char['name'], web_url)
                            
                            # [í•µì‹¬] ì£¼ì¸ê³µì´ê±°ë‚˜ ì²« ë²ˆì§¸ ìºë¦­í„°ì¸ ê²½ìš° í”„ë¡œì íŠ¸ ë ˆí¼ëŸ°ìŠ¤ë¡œ ìë™ ì ìš© (Apply ë²„íŠ¼ íš¨ê³¼)
                            is_protagonist = "ì£¼ì¸ê³µ" in char.get("role", "")
                            if not has_applied_reference:
                                if is_protagonist or (idx == len(processed_chars) - 1) or (idx == 0 and len(processed_chars) == 1):
                                    db.update_project_setting(project_id, "character_ref_text", char['prompt_en'])
                                    db.update_project_setting(project_id, "character_ref_image_path", web_url)
                                    has_applied_reference = True
                                    print(f"âœ¨ [Auto-Pilot] ì£¼ì¸ê³µ '{char['name']}'ì„(ë¥¼) ìºë¦­í„° ë ˆí¼ëŸ°ìŠ¤ë¡œ ì ìš©í–ˆìŠµë‹ˆë‹¤.")
                        
                    except Exception as char_e:
                        print(f"âš ï¸ [Auto-Pilot] ìºë¦­í„° '{char['name']}' ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {char_e}")

        except Exception as e:
            print(f"âš ï¸ [Auto-Pilot] ìºë¦­í„° ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    async def _generate_metadata(self, project_id: int, script_text: str):
        """AIë¥¼ ì‚¬ìš©í•˜ì—¬ ì œëª©, ì„¤ëª…, íƒœê·¸ ìƒì„±"""
        print(f"ğŸ“ [Auto-Pilot] ì œëª© ë° ì„¤ëª… ìƒì„± ì‹œì‘...")
        try:
            metadata = await gemini_service.generate_video_metadata(script_text)
            if metadata:
                db.update_project_setting(project_id, "title", metadata.get("title"))
                db.update_project_setting(project_id, "description", metadata.get("description"))
                db.update_project_setting(project_id, "hashtags", ",".join(metadata.get("tags", [])))
                print(f"âœ… [Auto-Pilot] ë©”íƒ€ë°ì´í„° ìƒì„± ì™„ë£Œ: {metadata.get('title')}")
        except Exception as e:
            print(f"âš ï¸ [Auto-Pilot] ë©”íƒ€ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")

    async def _find_best_material(self, keyword: str):
        params = {
            "part": "snippet", "q": keyword, "type": "video",
            "maxResults": 3, "order": "relevance", "videoDuration": "short",
            "key": config.YOUTUBE_API_KEY
        }
        async with httpx.AsyncClient() as client:
            response = await client.get(self.search_url, params=params)
            data = response.json()
            return data["items"][0] if "items" in data and data["items"] else None

    async def _analyze_video(self, video_data: dict):
        video_id = video_data['id']['videoId']
        title = video_data['snippet']['title']
        description = video_data['snippet']['description']
        
        prompt = f"""
        ìœ íŠœë¸Œ ì˜ìƒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒˆë¡œìš´ ì˜ìƒì„ ìœ„í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        [ì˜ìƒ ì •ë³´]
        - ì œëª©: {title}
        - ID: {video_id}
        - ì„¤ëª…: {description[:500]}
        
        ì´ ì˜ìƒì˜ í•µì‹¬ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤, ì£¼ìš” ë‚´ìš©, ê·¸ë¦¬ê³  ì´ë¥¼ ë²¤ì¹˜ë§ˆí‚¹í–ˆì„ ë•Œ ëŒ€ì¤‘ë“¤ì´ ì¢‹ì•„í• ë§Œí•œ 'ê³µê° í¬ì¸íŠ¸'ë¥¼ 3ê°€ì§€ë§Œ ë¶„ì„í•´ì„œ JSONìœ¼ë¡œ ì£¼ì„¸ìš”.
        
        JSON í¬ë§·:
        {{
            "sentiment": "positive/negative/neutral",
            "topics": ["ì£¼ì œ1", "ì£¼ì œ2"],
            "viewer_needs": "ì‹œì²­ìë“¤ì´ ì›í•˜ëŠ” ê²ƒ ì„¤ëª…"
        }}
        JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”.
        """
        result_text = await gemini_service.generate_text(prompt, temperature=0.7)
        try:
            import re
            json_match = re.search(r'\{[\s\S]*\}', result_text)
            return json.loads(json_match.group()) if json_match else {"summary": result_text}
        except: return {"summary": result_text}

    async def _generate_script(self, project_id: int, analysis: dict, config_dict: dict):
        style_key = config_dict.get("script_style", "default")
        # Get script style description from DB presets if exists
        script_presets = db.get_script_style_presets()
        style_desc = script_presets.get(style_key, f"Style: {style_key}")

        # [NEW] Check for Manual Planning (Script Structure)
        manual_plan = db.get_script_structure(project_id)

        # [AUTO-PLAN] If auto_plan is requested AND no manual plan exists, generate one now
        if not (manual_plan and manual_plan.get("structure")) and config_dict.get("auto_plan"):
             print(f"ğŸ¤– [Auto-Pilot] ìë™ ê¸°íš ìƒì„± ì‹œì‘...")
             try:
                  target_duration_min = config_dict.get("duration_seconds", 300) // 60
                  struct_prompt = f"""
Create a structured plan for a YouTube video based on this analysis.
Analysis: {json.dumps(analysis, ensure_ascii=False)}

Context:
- Video Topic: {db.get_project(project_id).get('topic')}
- Script Style: {style_desc}
- Target Duration: {target_duration_min} minutes

Required Format (JSON Only):
{{
  "hook": "Strong opening sentence to grab attention",
  "sections": [
    {{ "title": "Section Title", "key_points": ["point1", "point2"] }}
  ],
  "cta": "Conclusion and call to action",
  "style": "{style_key}",
  "duration": {target_duration_min}
}}
Language: Korean
Style Guide: Narration/Monologue only. NO dialogue between characters.
"""
                  # request_s = type('obj', (object,), {"prompt": struct_prompt, "temperature": 0.7})
                  result_text_s = await gemini_service.generate_text(struct_prompt, temperature=0.7)
                  
                  import re
                  match = re.search(r'\{[\s\S]*\}', result_text_s)
                  if match:
                      new_struct = json.loads(match.group())
                      # Ensure style and duration are set if AI missed them
                      if "style" not in new_struct: new_struct["style"] = style_key
                      if "duration" not in new_struct: new_struct["duration"] = target_duration_min
                      
                      db.save_script_structure(project_id, new_struct)
                      manual_plan = {"structure": new_struct} # Update local var to trigger next block
                      print(f"âœ… [Auto-Pilot] ìë™ ê¸°íš ì™„ë£Œ ë° ì €ì¥. (Duration: {target_duration_min}m)")
             except Exception as e:
                 print(f"âš ï¸ [Auto-Pilot] ìë™ ê¸°íš ì‹¤íŒ¨: {e}")
        
        if manual_plan and manual_plan.get("structure"):
            print(f"ğŸ“„ [Auto-Pilot] ìˆ˜ë™ ê¸°íš ë°ì´í„° ë°œê²¬! ê¸°íš ê¸°ë°˜ ëŒ€ë³¸ ì‘ì„± ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            plan_json = json.dumps(manual_plan.get("structure"), ensure_ascii=False)
            
            prompt = f"""You are a professional YouTube scriptwriter.
Write a full script based strictly on the following USER PLANNED STRUCTURE.

[User Plan & Title]
{plan_json}

[Reference Analysis]
{json.dumps(analysis, ensure_ascii=False)}

[Instructions]
1. You MUST follow the 'User Plan' structure (Hook, Body, Conclusion, etc).
2. The 'structure' contains specific Hooks and plot points selected by the user. Do NOT change them.
3. Use the 'Reference Analysis' only to enrich the content details.
4. Voice: Strictly SINGLE SPEAKER Narration or Monologue. 
5. NO DIALOGUE: Do not write conversations between different people (No "A: Hello, B: Hi").
6. Output the full script in Korean.

[Absolute Rules for TTS]
- NO character names or colons (e.g., "Narrator:", "Me:").
- NO parentheses or situational descriptions (e.g., "(music)", "(laughs)").
- NO special characters or emojis.
"""
            if style_key != "default":
                prompt += f"\n\n[Writing Style Directive]: {style_desc}\nApply this style strictly."
        else:
            # Original Logic
            prompt = prompts.AUTOPILOT_GENERATE_SCRIPT.format(
                analysis_json=json.dumps(analysis, ensure_ascii=False)
            )
            if style_key != "default":
                prompt += f"\n\n[Writing Style Directive]: {style_desc}\nApply this style strictly throughout the script."

        # request = type('obj', (object,), {"prompt": prompt, "temperature": 0.8})
        script = await gemini_service.generate_text(prompt, temperature=0.8)
        
        # [CRITICAL] 4ê°€ì§€ ê¸ˆì§€ í•­ëª© ì •ì œ (ê´„í˜¸, íƒ€ì„ìŠ¤íƒ¬í”„, ì´ëª¨í‹°ì½˜, í™”ì í‘œì‹œ)
        import re
        if script:
            # 1. ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ë‚´ìš© ì‚­ì œ (ì˜ˆ: (ë°°ê²½ìŒì•…), (ì›ƒìŒ))
            script = re.sub(r'\([^)]*\)', '', script)
            # 2. íƒ€ì„ìŠ¤íƒ¬í”„ ë° ì‹œê°„ëŒ€ ì‚­ì œ (ì˜ˆ: [0-5ì´ˆ], [00:15])
            script = re.sub(r'\[[^\]]*\]', '', script)
            # 3. ë³„í‘œ ë° ê¾¸ë°ˆ ê¸°í˜¸ ì‚­ì œ (**)
            script = re.sub(r'\*', '', script)
            # 4. ì´ëª¨í‹°ì½˜ ë° íŠ¹ìˆ˜ ê¸°í˜¸ ì‚­ì œ (ğŸ¤£, âœ¨, ğŸ”¥ ë“±)
            script = re.sub(r'[^\w\s\d,.\?\!\"\'\. ]', '', script)
            # 5. í™”ì í‘œì‹œ ì‚­ì œ (ì˜ˆ: ë‚˜:, ìƒì‚¬:, A:) - ë¬¸ì¥ ì‹œì‘ ë¶€ë¶„ì˜ ì´ë¦„ê³¼ ì½œë¡ 
            script = re.sub(r'^[ê°€-í£\w\s]+[\s]*:[\s]*', '', script, flags=re.MULTILINE)
            # 6. ë¶ˆí•„ìš”í•œ ê³µë°± ë° ë¹ˆ ì¤„ ì •ë¦¬
            script = script.strip()
            script = re.sub(r'\n\s*\n', '\n', script)

        # Save script
        # Calculate approximate duration (char count / 15 chars per sec is rough, usually 5 chars/sec for speech)
        # Using a safer estimate provided by user input usually, but here auto-calc
        target_duration_sec = config_dict.get("duration_seconds", 300) 
        db.save_script(project_id, script, len(script), target_duration_sec)
        
        return script

    async def _generate_assets(self, project_id: int, script: str, config_dict: dict):
        all_video = config_dict.get("all_video", False)
        motion_method = config_dict.get("motion_method", "standard")
        image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))

        
        # Determine sequence duration based on method
        video_duration = 5.0
        if motion_method in ["extend", "slowmo"]:
            video_duration = 8.0

        # Get visual style prompt from presets
        style_presets = db.get_style_presets()
        style_data = style_presets.get(image_style_key, {})

        style_prefix = style_data.get("prompt_value", "photorealistic")
        
        # 1. Image Prompts
        # [CRITICAL FIX] Use actual target duration for image count calculation
        target_duration = config_dict.get("duration_seconds", 300)
        
        image_prompts = db.get_image_prompts(project_id)
        if not image_prompts:
            print(f"ğŸ–¼ï¸ [Auto-Pilot] Generating image prompts for {target_duration}s video...")
            # [NEW] ìºë¦­í„° ì •ë³´ ì¡°íšŒ ë° ì „ë‹¬
            characters = db.get_project_characters(project_id)
            image_prompts = await gemini_service.generate_image_prompts_from_script(script, target_duration, style_prefix, characters=characters)
            db.save_image_prompts(project_id, image_prompts)
            image_prompts = db.get_image_prompts(project_id)
            print(f"ğŸ–¼ï¸ [Auto-Pilot] Generated {len(image_prompts)} image prompts")

        # Determine how many scenes to make as video
        if all_video:
            video_scene_count = len(image_prompts)
            print(f"ğŸ¬ [Auto-Pilot] 'ALL VIDEO' mode enabled. Generating {video_scene_count} video scenes.")
        else:
            video_scene_count = config_dict.get("video_scene_count", 0)
            print(f"ğŸ¬ [Auto-Pilot] Video scene count set to: {video_scene_count}")

        # 2. Assets (Video/Image)
        from services.replicate_service import replicate_service
        async def process_scene(p, is_video: bool):
            scene_num = p.get("scene_number")
            if p.get("image_url") and not (is_video and not p.get("video_url")): 
                # Already has image, and if video requested, check if video exists
                if not (is_video and not p.get("video_url")):
                    return True
            
            prompt_en = p.get("prompt_en", "cinematic scene")
            now = config.get_kst_time()
            try:
                # Generate base image if not exists
                image_abs_path = None
                if p.get("image_url") and p.get("image_url").startswith("/output/"):
                    image_abs_path = os.path.join(config.OUTPUT_DIR, p.get("image_url").replace("/output/", ""))
                
                if not image_abs_path or not os.path.exists(image_abs_path):
                    # [CRITICAL] Determine aspect ratio based on Mode (Shorts vs Longform)
                    duration_sec = config_dict.get("duration_seconds", 300)
                    mode = config_dict.get("mode", "longform")
                    
                    if mode == "shorts":
                        aspect_ratio = "9:16"
                    elif mode == "longform":
                        aspect_ratio = "16:9"
                    else:
                        # Fallback to duration threshold
                        aspect_ratio = "16:9" if (duration_sec and duration_sec >= 60) else "9:16"
                    
                    print(f"ğŸ¨ [Auto-Pilot] Generating image for Scene {scene_num} (Mode: {mode}, Duration: {duration_sec}s, Aspect Ratio: {aspect_ratio})")
                    images = await gemini_service.generate_image(prompt_en, aspect_ratio=aspect_ratio)

                    if not images: return False
                    
                    filename = f"img_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.png"
                    image_abs_path = os.path.join(config.OUTPUT_DIR, filename)
                    with open(image_abs_path, 'wb') as f: f.write(images[0])
                    db.update_image_prompt_url(project_id, scene_num, f"/output/{filename}")
                
                return True # Image only path success
            except Exception as e:
                print(f"âš ï¸ [Auto-Pilot] Scene {scene_num} Asset Gen Error: {e}")
            return False

        # Pass 1: Image Generation (Ensure all scenes have base images)
        print("ğŸ–¼ï¸ [Auto-Pilot] Pass 1: Generating Base Images...")
        for i, p in enumerate(image_prompts):
            db.update_project(project_id, status=f"images_{i+1}/{len(image_prompts)}")
            await process_scene(p, False) # Only images in Pass 1

        # [CRITICAL] Re-fetch image_prompts from DB to get updated image_url paths
        image_prompts = db.get_image_prompts(project_id)

        # Pass 2: TTS Generation (Collected for each scene)
        print("ğŸ™ï¸ [Auto-Pilot] Pass 2: Generating Scene-based TTS...")
        db.update_project(project_id, status="generating_tts")
        provider = config_dict.get("voice_provider")
        voice_id = config_dict.get("voice_id")
        
        if not provider or not voice_id:
             p_settings = db.get_project_settings(project_id) or db.get_project_settings(1) or {}
             if not provider: provider = p_settings.get("voice_provider", "google_cloud")
             if not voice_id: voice_id = p_settings.get("voice_id") or p_settings.get("voice_name", "ko-KR-Neural2-A")
        
        # [NEW] Collect scene audio mappings for Pass 3
        scene_audio_map = {} # scene_number -> local_audio_path
        
        scene_audio_files = []
        scene_durations = []
        all_alignments = []
        cumulative_audio_time = 0.0
        sorted_prompts = sorted(image_prompts, key=lambda x: x.get('scene_number', 0))
        temp_audios = []
        used_voices = set() # [NEW] Track voices
        import uuid

        # [NEW] Load settings for overrides
        p_settings = db.get_project_settings(project_id) or {}

        for i, p in enumerate(sorted_prompts):
            db.update_project(project_id, status=f"tts_{i+1}/{len(sorted_prompts)}")
            text = p.get('scene_text') or p.get('narrative') or p.get('script') or ""
            scene_num = p.get('scene_number')
            
            # [NEW] Voice Override
            scene_voice = p_settings.get(f"scene_{scene_num}_voice")
            current_voice_id = scene_voice if scene_voice else voice_id
            used_voices.add(current_voice_id) # Collect

            if not text:
                scene_durations.append(3.0)
                cumulative_audio_time += 3.0
                continue

            scene_filename = f"temp_tts_{project_id}_{i}_{uuid.uuid4()}.mp3"
            
            try:
                if provider == "elevenlabs":
                    result = await tts_service.generate_elevenlabs(text, current_voice_id, scene_filename)
                    if result and result.get("audio_path"):
                        audio_path = result["audio_path"]
                        duration = result.get("duration", 3.0)
                        alignment = result.get("alignment", [])
                        
                        temp_audios.append(audio_path)
                        scene_audio_files.append(audio_path)
                        scene_audio_map[scene_num] = audio_path
                        scene_durations.append(duration)
                        
                        for word_info in alignment:
                            all_alignments.append({
                                "word": word_info["word"],
                                "start": word_info["start"] + cumulative_audio_time,
                                "end": word_info["end"] + cumulative_audio_time
                            })
                        cumulative_audio_time += duration
                    else:
                        print(f"âš ï¸ Scene {i} ElevenLabs TTS Failed. Using default.")
                        scene_durations.append(3.0)
                        cumulative_audio_time += 3.0
                else:
                    s_out = None
                    if provider == "openai": s_out = await tts_service.generate_openai(text, current_voice_id, model="tts-1", filename=scene_filename)
                    elif provider == "gemini": s_out = await tts_service.generate_gemini(text, current_voice_id, filename=scene_filename)
                    else: s_out = await tts_service.generate_google_cloud(text, current_voice_id, filename=scene_filename)
                    
                    if s_out and os.path.exists(s_out):
                        temp_audios.append(s_out)
                        scene_audio_files.append(s_out)
                        scene_audio_map[scene_num] = s_out
                        
                        try:
                            from moviepy import AudioFileClip
                            ac = AudioFileClip(s_out)
                            dur = ac.duration
                            scene_durations.append(dur)
                            cumulative_audio_time += dur
                            ac.close()
                        except:
                            scene_durations.append(3.0)
                            cumulative_audio_time += 3.0
                    else:
                        scene_durations.append(3.0)
                        cumulative_audio_time += 3.0

            except Exception as e:
                print(f"âš ï¸ Scene {i} TTS Error: {e}")
                scene_durations.append(3.0)
                cumulative_audio_time += 3.0
        
        # All alignments ì €ì¥ (ë‚˜ì¤‘ì— ì •ë°€ ìë§‰ ìƒì„±ì— ì‚¬ìš©)
        if all_alignments:
            alignment_path = os.path.join(config.OUTPUT_DIR, f"tts_alignment_{project_id}.json")
            with open(alignment_path, "w", encoding="utf-8") as f:
                json.dump(all_alignments, f, ensure_ascii=False, indent=2)
            db.update_project_setting(project_id, "tts_alignment_path", alignment_path)
            print(f"âœ… [Auto-Pilot] Saved {len(all_alignments)} word alignments")
        
        # Merge Audios
        final_filename = f"auto_tts_{project_id}.mp3"
        final_audio_path = os.path.join(config.OUTPUT_DIR, final_filename)
        
        total_duration = 0.0
        if scene_audio_files:
            try:
                from moviepy import concatenate_audioclips, AudioFileClip
                clips = [AudioFileClip(f) for f in scene_audio_files]
                final_clip = concatenate_audioclips(clips)
                final_clip.write_audiofile(final_audio_path, logger=None)
                
                total_duration = final_clip.duration
                final_clip.close()
                for c in clips: c.close()
                
                # DB Save
                db.save_tts(project_id, provider, voice_id, final_audio_path, total_duration)
                
                # [CRITICAL] Calculate Cumulative Start Timings for Frontend
                cumulative_starts = []
                current_time = 0.0
                for dur in scene_durations:
                    cumulative_starts.append(current_time)
                    current_time += dur
                
                # 1. Save Image Start Timings (Expects START TIMES for frontend sync)
                timings_path = os.path.join(config.OUTPUT_DIR, f"image_timings_{project_id}.json")
                with open(timings_path, "w", encoding="utf-8") as f:
                     json.dump(cumulative_starts, f)
                db.update_project_setting(project_id, "image_timings_path", timings_path)
                
                # 2. Save Initial Subtitles
                # [NEW] ElevenLabs alignment ì •ë³´ê°€ ìˆìœ¼ë©´ ì •ë°€ ìë§‰ ìƒì„±
                auto_subtitles = []
                
                if all_alignments:
                    # ë‹¨ì–´ íƒ€ì´ë°ì„ 2ì¤„ ìë§‰ìœ¼ë¡œ ë³€í™˜
                    auto_subtitles = self._alignment_to_subtitles(all_alignments, max_chars=40)
                    print(f"ğŸ“ [Auto-Pilot] Generated {len(auto_subtitles)} subtitles from TTS alignment (PRECISE)")
                else:
                    # ê¸°ì¡´ ë¡œì§: Scene ê¸°ë°˜ ê· ë“± ë¶„í• 
                    for i, p in enumerate(sorted_prompts):
                        if i >= len(cumulative_starts): break
                        text = p.get('scene_text') or p.get('narrative') or p.get('script') or ""
                        if not text:
                            continue
                        
                        chunks = split_text_to_subtitle_chunks(text, max_chars_per_line=20, max_lines=2)
                        if not chunks:
                            continue
                        
                        scene_start = cumulative_starts[i]
                        scene_duration = scene_durations[i]
                        chunk_duration = scene_duration / len(chunks)
                        
                        for j, chunk_text in enumerate(chunks):
                            chunk_start = scene_start + (j * chunk_duration)
                            chunk_end = chunk_start + chunk_duration
                            
                            auto_subtitles.append({
                                "text": chunk_text,
                                "start": round(chunk_start, 2),
                                "end": round(chunk_end, 2)
                            })
                    
                    print(f"ğŸ“ [Auto-Pilot] Generated {len(auto_subtitles)} subtitle segments (fallback mode)")
                
                sub_path = os.path.join(config.OUTPUT_DIR, f"subtitles_{project_id}.json")
                with open(sub_path, "w", encoding="utf-8") as f:
                    json.dump(auto_subtitles, f, ensure_ascii=False, indent=2)
                db.update_project_setting(project_id, "subtitle_path", sub_path)

                # 3. Save Timeline Images (Order mapping)
                timeline_images = [p.get('video_url') or p.get('image_url') for p in sorted_prompts]
                # Filter out None/Empty
                timeline_images = [img for img in timeline_images if img]
                
                tl_images_path = os.path.join(config.OUTPUT_DIR, f"timeline_images_{project_id}.json")
                with open(tl_images_path, "w", encoding="utf-8") as f:
                    json.dump(timeline_images, f, ensure_ascii=False, indent=2)
                db.update_project_setting(project_id, "timeline_images_path", tl_images_path)
                
                print(f"âœ… [Auto-Pilot] Scene-based TTS & Subtitles Complete. Total: {total_duration:.2f}s, Scenes: {len(scene_durations)}")
                
                # [NEW] Save Stats
                db.update_project_setting(project_id, "stats_audio_duration_sec", f"{total_duration:.2f}")
                db.update_project_setting(project_id, "stats_used_voices", json.dumps(list(used_voices), ensure_ascii=False))
                
            except Exception as e:
                import traceback
                traceback.print_exc()
                print(f"âŒ Audio Merge Failed: {e}")
                # Fallback to single file gen logic if merge fails?
        else:
             print("âŒ No audio generated.")
        
        # Cleanup temps
        for f in temp_audios:
            try: os.remove(f)
            except: pass

        # [NEW] Pass 3: Video Generation (Now we have both Images and Audio)
        print("ğŸ“¹ [Auto-Pilot] Pass 3: Generating Video Components...")
        video_engine = config_dict.get("video_engine", "wan")
        from services.akool_service import akool_service

        # Re-fetch prompts to get latest image/audio URLs
        image_prompts = db.get_image_prompts(project_id)
        p_settings = db.get_project_settings(project_id) or {} # [NEW] Load settings
        
        for i, p in enumerate(image_prompts):
            is_vid = i < video_scene_count
            if not is_vid: continue
            
            scene_num = p.get("scene_number")
            db.update_project(project_id, status=f"videos_{i+1}/{video_scene_count}")
            
            image_url = p.get("image_url")
            if not image_url: continue
            image_abs_path = os.path.join(config.OUTPUT_DIR, image_url.replace("/output/", ""))
            
            now = config.get_kst_time()
            
            # [Smart Engine Switch]
            scene_text = p.get("scene_text", "").strip()
            has_dialogue = bool(scene_text and len(scene_text) > 1 and scene_text != "None")
            
            # [NEW] Check LipSync Preference
            use_lipsync_val = p_settings.get("use_lipsync")
            use_lipsync = True
            if use_lipsync_val is not None:
                if isinstance(use_lipsync_val, str): use_lipsync = (use_lipsync_val.lower() == 'true' or use_lipsync_val == '1')
                else: use_lipsync = bool(use_lipsync_val)

            # "ë§í• ë•ŒëŠ” akool (if enabled), ì›€ì§ì¼ë• wan"
            local_engine = "akool" if (has_dialogue and use_lipsync) else "wan"
            
            print(f"ğŸ¤– [Auto-Switch] Scene {scene_num}: Dialogue={has_dialogue} -> Engine={local_engine}")

            try:
                if local_engine == "akool":
                    audio_abs_path = scene_audio_map.get(scene_num)
                    if not audio_abs_path: 
                        print(f"âš ï¸ [Akool] No audio found for scene {scene_num}. Switching to Wan.")
                        local_engine = "wan" # Fallback if no audio
                    else:
                        video_bytes = await akool_service.generate_talking_avatar(image_abs_path, audio_abs_path)
                        if video_bytes:
                            filename = f"vid_akool_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                            out = os.path.join(config.OUTPUT_DIR, filename)
                            with open(out, 'wb') as f: f.write(video_bytes)
                            db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
                
                if local_engine == "wan":
                    # Wan / Replicate (Original logic)
                    # Wan / Replicate (Original logic)
                    print(f"ğŸ“¹ [Auto-Pilot] Generating Wan Video for Scene {scene_num}")
                    video_data = await replicate_service.generate_video_from_image(
                        image_abs_path, 
                        prompt=f"Cinematic motion, {p.get('prompt_en', '')}",
                        duration=video_duration,
                        method=motion_method
                    )
                    if video_data:
                        filename = f"vid_wan_{project_id}_{scene_num}_{now.strftime('%H%M%S')}.mp4"
                        out = os.path.join(config.OUTPUT_DIR, filename)
                        with open(out, 'wb') as f: f.write(video_data)
                        db.update_image_prompt_video_url(project_id, scene_num, f"/output/{filename}")
            except Exception as ve:
                print(f"âš ï¸ [Auto-Pilot] Video generation failed for Scene {scene_num}: {ve}")

    async def _generate_thumbnail(self, project_id: int, script: str, config_dict: dict):
        """ëŒ€ë³¸ ê¸°ë°˜ ì¸ë„¤ì¼ ìë™ ê¸°íš ë° ìƒì„±"""
        print(f"ğŸ¨ [Auto-Pilot] ì¸ë„¤ì¼ ìë™ ìƒì„± ì¤‘... Project: {project_id}")
        
        # 1. ì¸ë„¤ì¼ ê¸°íš (Hook & Visual Concept)
        hook_text = "Must Watch"
        visual_concept = "A high quality dramatic scene"
        
        try:
            # [NEW] Use the better prompt for hook text
            project_settings = db.get_project_settings(project_id) or {}
            image_style = config_dict.get("image_style") or project_settings.get("image_style", "realistic")
            thumb_style = config_dict.get("thumbnail_style") or project_settings.get("thumbnail_style", "face")
            
            # Get character info for better context
            characters = db.get_project_characters(project_id)
            char_context = ""
            if characters:
                char_names = [c.get("name") for c in characters if c.get("name")]
                char_context = f"\n[Featured Characters]: {', '.join(char_names)}"

            hook_prompt = prompts.GEMINI_THUMBNAIL_HOOK_TEXT.format(
                script=f"{script[:2000]}{char_context}",
                thumbnail_style=thumb_style,
                image_style=image_style,
                target_language="ko" # Default for now
            )
            
            hook_result = await gemini_service.generate_text(hook_prompt, temperature=0.7)
            import re
            json_match = re.search(r'\{[\s\S]*\}', hook_result)
            if json_match:
                hook_data = json.loads(json_match.group())
                candidates = hook_data.get("texts", [])
                if candidates:
                    hook_text = candidates[0] # Pick the strongest hook
            
            # [NEW] Generate a matching visual concept (Image Prompt)
            # Use THUMBNAIL_IDEA_PROMPT as a secondary pass or merge logic
            idea_prompt = prompts.THUMBNAIL_IDEA_PROMPT.format(
                topic=project_settings.get("topic", "AI Video"),
                script_summary=script[:1000]
            )
            idea_result = await gemini_service.generate_text(idea_prompt, temperature=0.7)
            json_match_idea = re.search(r'\{[\s\S]*\}', idea_result)
            if json_match_idea:
                idea_data = json.loads(json_match_idea.group())
                visual_concept = idea_data.get("image_prompt", visual_concept)
                
        except Exception as e:
            print(f"âš ï¸ [Auto-Pilot] Thumbnail Planning Error: {e}")
            # Fallback to project title if hook fails
            hook_text = project_settings.get("title", "Must Watch") if project_id else "Must Watch"

        # 2. ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        try:
            # [NEW] Art Style & Layout Inheritance
            image_style_key = config_dict.get("image_style", config_dict.get("visual_style", "realistic"))
            style_presets = db.get_style_presets()
            style_data = style_presets.get(image_style_key, {})
            style_prefix = style_data.get("prompt_value", "photorealistic")

            # [NEW] Layout Style
            thumbnail_style_key = config_dict.get("thumbnail_style", "face")
            thumb_presets = db.get_thumbnail_style_presets()
            thumb_preset = thumb_presets.get(thumbnail_style_key, {})
            layout_desc = thumb_preset.get("prompt", "")
            
            # [NEW] Character Incorporation
            characters = db.get_project_characters(project_id)
            char_desc = ""
            if characters:
                # Use the first 1-2 characters to keep prompt focused
                char_lines = []
                for c in characters[:2]:
                    char_lines.append(c.get("prompt_en", ""))
                char_desc = " Featuring: " + ", ".join(char_lines)
            
            # Combine everything for a consistent look
            final_thumb_prompt = f"ABSOLUTELY NO TEXT. Style: {style_prefix}. Composition: {layout_desc}. Subjects: {visual_concept}.{char_desc}. 8k, high quality."

            # [CRITICAL] Determine aspect ratio based on duration (Long-form vs Shorts)
            duration_sec = config_dict.get("duration_seconds", 300)
            aspect_ratio = "16:9" if duration_sec > 60 else "9:16"
            
            print(f"ğŸ¨ [Auto-Pilot] Generating thumbnail background. Style: {image_style_key}, Aspect: {aspect_ratio}")
            print(f"ğŸ“ Prompt: {final_thumb_prompt[:120]}...")
            
            images = None
            try:
                images = await gemini_service.generate_image(final_thumb_prompt, aspect_ratio=aspect_ratio)
            except Exception as e:
                msg = f"âŒ [Auto-Pilot] Thumbnail Image Gen Failed: {e}"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.datetime.now()}] {msg}\n")
                except: pass
                
                # [FALLBACK] Try a safe, generic prompt if the specific one was blocked
                print("ğŸ”„ [Auto-Pilot] Retrying with generic thumbnail prompt due to safety/filter...")
                generic_prompt = f"Minimal aesthetic abstract background, Style: {style_prefix}, 8k, high quality"
                try:
                    images = await gemini_service.generate_image(generic_prompt, aspect_ratio=aspect_ratio)
                except Exception as e2:
                    print(f"âŒ [Auto-Pilot] Final fallback failed: {e2}")
            
            if not images: 
                print("âš ï¸ [Auto-Pilot] No images generated for thumbnail. Skipping synthesis.")
                return

            now = config.get_kst_time()
            bg_filename = f"thumb_bg_{project_id}_{now.strftime('%H%M%S')}.png"
            bg_path = os.path.join(config.OUTPUT_DIR, bg_filename)
            with open(bg_path, 'wb') as f: f.write(images[0])
            
            # 3. í…ìŠ¤íŠ¸ í•©ì„± (ì €ì¥ëœ ì„¤ì • ë°˜ì˜)
            from services.thumbnail_service import thumbnail_service
            final_filename = f"thumbnail_{project_id}_{now.strftime('%H%M%S')}.jpg"
            final_path = os.path.join(config.OUTPUT_DIR, final_filename)
            
            # [PRIORITY 1] Check Autopilot Config / Project Settings for Explicit Style
            project_settings = db.get_project_settings(project_id) or {}
            requested_style = config_dict.get("thumbnail_style") or project_settings.get("thumbnail_style")
            
            text_layers = []
            
            if requested_style:
                text_layers = thumbnail_service.get_style_recipe(requested_style, hook_text)
            
            # [PRIORITY 2] Fallback to Project 1 Template
            elif (saved_thumb_data := db.get_thumbnails(1)) and saved_thumb_data.get("full_settings"):
                layers = saved_thumb_data["full_settings"].get("layers", [])
                
                # Find main text layer (biggest font size)
                main_layer_idx = 0
                max_size = 0
                for i, l in enumerate(layers):
                    fs = int(l.get("font_size", 0))
                    if fs > max_size:
                        max_size = fs
                        main_layer_idx = i
                
                # Copy and Replace Text
                import copy
                text_layers = copy.deepcopy(layers)
                if text_layers and len(text_layers) > main_layer_idx:
                     text_layers[main_layer_idx]["text"] = hook_text
            
            else:
                # [PRIORITY 3] Default Fallback
                text_layers = thumbnail_service.get_style_recipe("mystery", hook_text)

            success = thumbnail_service.create_thumbnail(bg_path, text_layers, final_path)
            
            if success:
                web_path = f"/output/{final_filename}"
                db.update_project_setting(project_id, "thumbnail_url", web_path)
                msg = f"âœ… [Auto-Pilot] ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ: {web_path}"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.datetime.now()}] {msg}\n")
                except: pass
            else:
                msg = "âŒ [Auto-Pilot] ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ í•©ì„± ì‹¤íŒ¨ (create_thumbnail returned False)"
                print(msg)
                try:
                    with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                        df.write(f"[{datetime.datetime.now()}] {msg}\n")
                except: pass
            
            try: os.remove(bg_path)
            except: pass
            
        except Exception as e:
            msg = f"âŒ [Auto-Pilot] ì¸ë„¤ì¼ ìƒì„± ì˜ˆì™¸: {e}"
            print(msg)
            try:
                with open(config.DEBUG_LOG_PATH, "a", encoding="utf-8") as df:
                    df.write(f"[{datetime.datetime.now()}] {msg}\n")
            except: pass

    async def _render_video(self, project_id: int):
        images_data = db.get_image_prompts(project_id)
        tts_data = db.get_tts(project_id)
        script_data = db.get_script(project_id)
        settings = db.get_project_settings(project_id) or {}
        
        # 1. Load Subtitles (Prefer Saved)
        # 1. Load Subtitles (Prefer Saved)
        subs = []
        
        # [NEW] Check user preference for subtitles
        use_sub_val = settings.get("use_subtitles")
        use_subtitles = True # Default
        if use_sub_val is not None:
            if isinstance(use_sub_val, str): use_subtitles = (use_sub_val.lower() == 'true' or use_sub_val == '1')
            else: use_subtitles = bool(use_sub_val)

        if use_subtitles:
            subtitle_path = settings.get("subtitle_path")
            if subtitle_path and os.path.exists(subtitle_path):
                try:
                    with open(subtitle_path, "r", encoding="utf-8") as f:
                        subs = json.load(f)
                except: pass
                
            if not subs:
                print("ğŸ” [Auto-Pilot] No saved subtitles found. Generating via Whisper...")
                try:
                    audio_path = tts_data["audio_path"]
                    subs = video_service.generate_aligned_subtitles(audio_path, script_data["full_script"])
                except Exception as sub_e: 
                    print(f"âš ï¸ Subtitle Gen Error: {sub_e}")
            
            if not subs: 
                subs = video_service.generate_smart_subtitles(script_data["full_script"], tts_data["duration"])
        else:
            print("ğŸš« [Auto-Pilot] Subtitles disabled manually.")

        # 2. Load Timeline Images
        # [FIX] Always use fresh DB data from image_prompts (includes video_url from Pass 3)
        # The timeline_images_path JSON file is created during Pass 2 (before video generation)
        # so it may not contain the latest video_url values.
        images = []
        sorted_prompts = sorted(images_data, key=lambda x: x.get('scene_number', 0))
        for img in sorted_prompts:
            # Priority: video_url (motion video) > image_url (static image)
            best_url = img.get("video_url") or img.get("image_url")
            if not best_url: 
                continue
            # Convert web path to absolute path
            if best_url.startswith("/output/"):
                fpath = os.path.join(config.OUTPUT_DIR, best_url.replace("/output/", ""))
            else:
                fpath = os.path.join(config.OUTPUT_DIR, best_url.split("/")[-1])
            
            if os.path.exists(fpath): 
                images.append(fpath)
                print(f"ğŸ“¸ [Auto-Pilot] Scene {img.get('scene_number')}: Using {'video' if best_url.endswith('.mp4') else 'image'} - {os.path.basename(fpath)}")
                
        audio_path = tts_data["audio_path"]
        output_filename = f"autopilot_{project_id}_{config.get_kst_time().strftime('%H%M%S')}.mp4"

        # [IMPROVED] Calculate Durations from Start Timings
        image_durations = 5.0 # Default fallback
        timings_path = settings.get("image_timings_path")
        
        smart_sync_enabled = False
        if timings_path and os.path.exists(timings_path):
            try:
                with open(timings_path, "r", encoding="utf-8") as f:
                    loaded_starts = json.load(f)
                
                if loaded_starts:
                    # If the file contains DURATIONS (old format), we need to detect it.
                    # Usually start times begin with 0.0. 
                    # If there are many values and sum is > total_duration, then if it's start times, the last value would be < total_duration.
                    # Best check: Is it monotonically increasing?
                    is_pacing_format = all(x < y for x, y in zip(loaded_starts, loaded_starts[1:])) if len(loaded_starts) > 1 else True
                    
                    if is_pacing_format:
                        # Convert Start Times to Durations
                        total_dur = tts_data["duration"]
                        durations = []
                        for i in range(len(loaded_starts)):
                            if i < len(loaded_starts) - 1:
                                durations.append(loaded_starts[i+1] - loaded_starts[i])
                            else:
                                durations.append(max(2.0, total_dur - loaded_starts[i]))
                        image_durations = durations
                    else:
                        # Old format: Durations
                        image_durations = loaded_starts
                    
                    # Align with images count
                    if len(image_durations) >= len(images):
                        image_durations = image_durations[:len(images)]
                    else:
                        rem_dur = tts_data["duration"] - sum(image_durations) if isinstance(image_durations, list) else 0
                        rem_cnt = len(images) - len(image_durations)
                        if rem_cnt > 0:
                            avg = max(3.0, rem_dur / rem_cnt)
                            image_durations = image_durations + [avg] * rem_cnt

                    print(f"âœ… [Auto-Pilot] Start-Time Sync Applied: {len(image_durations)} scenes")
                    smart_sync_enabled = True
            except Exception as e:
                print(f"âš ï¸ Failed to load smart timings: {e}")

        # 2. Fallback to Simple N-Division
        if not smart_sync_enabled:
            image_durations = tts_data["duration"] / len(images) if images else 5.0
            print(f"âš ï¸ [Auto-Pilot] Fallback to N-Division Sync ({image_durations if not isinstance(image_durations, list) else 'list'}s per image)")
        
        # [NEW] Determine Resolution based on App Mode
        app_mode = settings.get("app_mode", "longform")
        resolution = (1920, 1080) if app_mode == "longform" else (1080, 1920)
        print(f"ğŸ¬ [Auto-Pilot] Rendering video with resolution: {resolution} (Mode: {app_mode})")

        final_path = video_service.create_slideshow(
            images=images, audio_path=audio_path, output_filename=output_filename,
            duration_per_image=image_durations, subtitles=subs, project_id=project_id,
            resolution=resolution
        )

        db.update_project_setting(project_id, "video_path", f"/output/{output_filename}")
        db.update_project(project_id, status="rendered")

    async def _run_topview_workflow(self, project_id: int, config_dict: dict):
        """TopView APIë¥¼ ì´ìš©í•œ ì»¤ë¨¸ìŠ¤ ë¹„ë””ì˜¤ ìƒì„± ì›Œí¬í”Œë¡œìš°"""
        product_url = config_dict.get("product_url")
        if not product_url:
            print("âš ï¸ [TopView] Product URL is missing")
            db.update_project(project_id, status="error")
            return

        print(f"ğŸ›ï¸ [TopView] Starting Commerce Workflow for {product_url}")
        db.update_project(project_id, status="topview_requested")

        # 1. íƒœìŠ¤í¬ ì‹œì‘
        from services.topview_service import topview_service
        result = await topview_service.create_video_by_url(product_url)
        
        if not result or (isinstance(result, dict) and "id" not in result):
            print(f"âŒ [TopView] Failed to start task: {result}")
            db.update_project(project_id, status="error")
            return

        task_id = result["id"]
        db.update_project_setting(project_id, "topview_task_id", task_id)
        db.update_project(project_id, status="topview_processing")

        # 2. í´ë§ (ìƒíƒœ í™•ì¸)
        max_retries = 60 # ì•½ 10ë¶„ (10ì´ˆ ê°„ê²©)
        retry_count = 0
        video_url = None

        while retry_count < max_retries:
            await asyncio.sleep(10)
            status_data = await topview_service.get_task_status(task_id)
            
            if not status_data:
                retry_count += 1
                continue

            status = status_data.get("status")
            print(f"â³ [TopView] Processing... ({status})")

            if status == "completed":
                video_url = status_data.get("video_url")
                break
            elif status == "failed":
                print(f"âŒ [TopView] Task failed: {status_data}")
                db.update_project(project_id, status="error")
                return
            
            retry_count += 1

        if not video_url:
            print("âŒ [TopView] Task timed out or no video URL received")
            db.update_project(project_id, status="error")
            return

        # 3. ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ë° ì €ì¥
        db.update_project(project_id, status="topview_downloading")
        target_path = os.path.join(config.OUTPUT_DIR, f"topview_{project_id}.mp4")
        
        try:
            async with httpx.AsyncClient() as client:
                resp = await client.get(video_url, timeout=300)
                with open(target_path, "wb") as f:
                    f.write(resp.content)
            
            # DB ì—…ë°ì´íŠ¸
            web_path = f"/output/topview_{project_id}.mp4"
            db.update_project_setting(project_id, "video_path", web_path)
            db.update_project(project_id, status="rendered")
            
            print(f"âœ… [TopView] Video generated and saved: {target_path}")

            # 4. YouTube ì—…ë¡œë“œ (ê¸°ë³¸ ë¡œì§ í™œìš©)
            await self._upload_video(project_id, target_path)
            
        except Exception as e:
            print(f"âŒ [TopView] Download/Save Error: {e}")
            db.update_project(project_id, status="error")

    async def _upload_video(self, project_id: int, video_path: str):
        now = config.get_kst_time()
        
        # Load settings
        p_settings = db.get_project_settings(project_id) or {}
        
        # Determine Privacy & Schedule
        privacy = p_settings.get("upload_privacy", "private")
        schedule_at = p_settings.get("upload_schedule_at")
        
        publish_time = None
        if privacy == "scheduled" or schedule_at:
            if schedule_at:
                try:
                    # Validate format or parse
                    # Format expected: 2026-02-12T08:00:00 or ISO
                    if "T" not in schedule_at:
                        # Simple format YYYY-MM-DD HH:MM
                        dt = datetime.strptime(schedule_at, "%Y-%m-%d %H:%M")
                        publish_time = dt.isoformat()
                    else:
                        publish_time = schedule_at
                except:
                    print(f"âš ï¸ [Upload] Invalid schedule format: {schedule_at}. Falling back to default.")
            
            if not publish_time:
                # Default: Next day 8 AM
                publish_time = (now + timedelta(days=1)).replace(hour=8, minute=0, second=0).isoformat()
            
            # YouTube API requires privacyStatus to be 'private' for scheduled uploads
            privacy = "private" 

        ai_title = p_settings.get("title") or f"AI Auto Video {now.date()}"
        ai_desc = p_settings.get("description") or "#Shorts #AI"
        ai_tags_str = p_settings.get("hashtags") or "ai,shorts"
        ai_tags = [t.strip() for t in ai_tags_str.split(",") if t.strip()]

        # [NEW] Multi-Channel Support: Resolve Token Path
        token_path = None
        channel_id = p_settings.get("youtube_channel_id")
        if channel_id:
            try:
                # get_channel must be implemented in database.py
                channel = db.get_channel(channel_id)
                if channel and channel.get("credentials_path"):
                    cand_path = channel["credentials_path"]
                    if os.path.exists(cand_path):
                        token_path = cand_path
                        print(f"ğŸ”‘ [Upload] Using channel token: {channel.get('name')} ({token_path})")
            except Exception as ce:
                print(f"âš ï¸ [Upload] Failed to resolve channel {channel_id}: {ce}")

        try:
            # 1. Video Upload
            print(f"ğŸš€ [Upload] Starting YouTube upload (Privacy: {privacy}, Schedule: {publish_time}, Channel: {channel_id or 'Default'})")
            response = youtube_upload_service.upload_video(
                file_path=video_path, 
                title=ai_title,
                description=ai_desc, 
                tags=ai_tags,
                privacy_status=privacy, 
                publish_at=publish_time,
                token_path=token_path # Pass token path
            )
            
            # 2. Thumbnail Upload (Wait a bit for video to be indexed)
            video_id = response.get("id")
            if video_id:
                print(f"âœ… [Auto-Pilot] Video uploaded: https://youtu.be/{video_id}. Waiting 10s for thumbnail upload...")
                await asyncio.sleep(10)
                
                settings = db.get_project_settings(project_id)
                thumb_url = settings.get("thumbnail_url")
                
                if thumb_url:
                    # /output/filename.jpg -> LOCAL_PATH/filename.jpg
                    fname = thumb_url.split("/")[-1]
                    thumb_path = os.path.join(config.OUTPUT_DIR, fname)
                    
                    if os.path.exists(thumb_path):
                        print(f"ğŸ–¼ï¸ [Auto-Pilot] Uploading thumbnail: {thumb_path}")
                        try:
                            youtube_upload_service.set_thumbnail(video_id, thumb_path, token_path=token_path)
                            print(f"âœ… [Auto-Pilot] Thumbnail set successfully for {video_id}")
                        except Exception as te:
                            print(f"âš ï¸ Thumbnail upload failed: {te}")
                    else:
                        print(f"âš ï¸ Thumbnail file not found at {thumb_path}")
                else:
                    print(f"âš ï¸ No thumbnail_url found for project {project_id}")
            
            db.update_project_setting(project_id, "is_uploaded", 1)
        except Exception as e:
            print(f"âŒ Upload failed: {e}")

    async def run_batch_workflow(self):
        """queued ìƒíƒœì˜ í”„ë¡œì íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ëª¨ë‘ ì²˜ë¦¬"""
        if self.is_batch_running:
            print("âš ï¸ [Batch] ì´ë¯¸ ì§„í–‰ ì¤‘ì¸ ì¼ê´„ ì²˜ë¦¬ ì‘ì—…ì´ ìˆìŠµë‹ˆë‹¤.")
            return
            
        self.is_batch_running = True
        print("ğŸš¦ [Batch] ì¼ê´„ ì œì‘ í”„ë¡œì„¸ìŠ¤ ì‹œì‘...")
        import asyncio
        
        try:
            while True:
                projects = db.get_all_projects()
                # FIFO: IDê°€ ì‘ì€ ìˆœì„œëŒ€ë¡œ ì²˜ë¦¬
                queue = sorted([p for p in projects if p.get("status") == "queued"], key=lambda x: x['id'])
                
                if not queue:
                    print("ğŸ [Batch] ëŒ€ê¸°ì—´ ì‘ì—…ì„ ëª¨ë‘ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤.")
                    break
                    
                project = queue[0]
                pid = project['id']
                print(f"â–¶ï¸ [Batch] í”„ë¡œì íŠ¸ ì‹œì‘: {project.get('topic')} (ID: {pid})")
                
                try:
                    # ì„¤ì • ë¡œë“œ
                    p_settings = db.get_project_settings(pid) or {}
                    
                    # [Logic Fix] ìˆœì„œëŒ€ë¡œ ì§„í–‰í•˜ê¸° ìœ„í•´ ì ì ˆí•œ ì‹œì‘ ìƒíƒœ ê²°ì •
                    # 1. ì´ë¯¸ ëŒ€ë³¸ì´ ìˆëŠ” ê²½ìš° -> ìì‚° ìƒì„±ë¶€í„°
                    if p_settings.get("script") and len(p_settings.get("script").strip()) > 50:
                        print(f"ğŸ“„ [Batch] ê¸°ì¡´ ëŒ€ë³¸ ë°œê²¬ (ID: {pid}). 'scripted' ë‹¨ê³„ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                        db.update_project(pid, status="scripted")
                    # 2. ë¶„ì„ ë°ì´í„°ëŠ” ìˆëŠ” ê²½ìš° -> ê¸°íš/ëŒ€ë³¸ ë‹¨ê³„ë¶€í„°
                    elif db.get_analysis(pid):
                        print(f"ğŸ“Š [Batch] ë¶„ì„ ë°ì´í„° ë°œê²¬ (ID: {pid}). 'analyzed' ë‹¨ê³„ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                        db.update_project(pid, status="analyzed")
                    # 3. ì•„ë¬´ê²ƒë„ ì—†ëŠ” ìƒˆ í”„ë¡œì íŠ¸ì¸ ê²½ìš° -> ì²˜ìŒ(ë¶„ì„)ë¶€í„°
                    else:
                        print(f"ğŸ†• [Batch] ì‹ ê·œ í”„ë¡œì íŠ¸ (ID: {pid}). 'created' ë‹¨ê³„ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                        db.update_project(pid, status="created")
                    
                    config_dict = {
                        "script_style": p_settings.get("script_style", "default"),
                        "duration_seconds": p_settings.get("duration_seconds", 300),
                        "voice_provider": p_settings.get("voice_provider"),
                        "voice_id": p_settings.get("voice_id"),
                        "image_style": p_settings.get("image_style", "realistic"), 
                        "thumbnail_style": p_settings.get("thumbnail_style", "face"), 
                        "all_video": bool(p_settings.get("all_video", 0)),
                        "motion_method": p_settings.get("motion_method", "standard"),
                        "video_scene_count": p_settings.get("video_scene_count", 0),
                        "auto_thumbnail": True,
                        "auto_plan": p_settings.get("auto_plan", True),
                        "video_engine": p_settings.get("video_engine", "wan"),
                        "upload_privacy": p_settings.get("upload_privacy", "private"),
                        "upload_schedule_at": p_settings.get("upload_schedule_at")
                    }
                    
                    # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰ (Wait for completion)
                    await self.run_workflow(project.get('topic'), pid, config_dict)
                    print(f"âœ… [Batch] í”„ë¡œì íŠ¸ ì™„ë£Œ: {pid}")
                    
                except Exception as e:
                    import traceback
                    traceback.print_exc()
                    print(f"âŒ [Batch] í”„ë¡œì íŠ¸ ì‹¤íŒ¨ (ID: {pid}): {e}")
                    db.update_project(pid, status="error")
                    
                await asyncio.sleep(2)
        finally:
            self.is_batch_running = False
            print("ğŸ›‘ [Batch] ì¼ê´„ ì œì‘ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ")
    
    def _alignment_to_subtitles(self, alignments: list, max_chars: int = 40) -> list:
        """
        ë‹¨ì–´ íƒ€ì´ë° ì •ë³´ë¥¼ 2ì¤„ ìë§‰ìœ¼ë¡œ ë³€í™˜ (ì •ë°€ ì‹±í¬)
        
        Args:
            alignments: [{"word": "ì•ˆë…•", "start": 0.0, "end": 0.3}, ...]
            max_chars: ìë§‰ë‹¹ ìµœëŒ€ ê¸€ì ìˆ˜ (2ì¤„ ê¸°ì¤€)
        
        Returns:
            [{"text": "ìë§‰ í…ìŠ¤íŠ¸", "start": 0.0, "end": 1.5}, ...]
        """
        if not alignments:
            return []
        
        subtitles = []
        current_words = []
        current_text = ""
        block_start = None
        block_end = None
        
        for i, word_info in enumerate(alignments):
            word = word_info.get("word", "").strip()
            if not word:
                continue
            
            start = word_info.get("start", 0)
            end = word_info.get("end", start + 0.1)
            
            # ìƒˆ ë¸”ë¡ ì‹œì‘
            if block_start is None:
                block_start = start
            
            # í…ìŠ¤íŠ¸ ëˆ„ì 
            test_text = f"{current_text} {word}".strip() if current_text else word
            
            # ìµœëŒ€ ê¸€ì ìˆ˜ ì²´í¬ ë˜ëŠ” ë¬¸ì¥ ë¶€í˜¸ë¡œ ëŠê¸°
            is_sentence_end = word.endswith(('.', '?', '!', ','))
            should_break = len(test_text) > max_chars or is_sentence_end
            
            if should_break and current_text:
                # í˜„ì¬ ë¸”ë¡ ì €ì¥
                subtitles.append({
                    "text": current_text,
                    "start": round(block_start, 2),
                    "end": round(block_end, 2)
                })
                
                # ìƒˆ ë¸”ë¡ ì‹œì‘
                current_text = word
                block_start = start
                block_end = end
            else:
                current_text = test_text
                block_end = end
        
        # ë§ˆì§€ë§‰ ë¸”ë¡
        if current_text:
            subtitles.append({
                "text": current_text,
                "start": round(block_start, 2),
                "end": round(block_end, 2)
            })
        
        return subtitles

    def get_queue_status(self):
        """í˜„ì¬ ëŒ€ê¸°ì—´ ìƒíƒœ ë°˜í™˜"""
        projects = db.get_all_projects()
        queued_projects = [p for p in projects if p.get("status") == "queued"]
        processing_projects = [p for p in projects if p.get("status") not in ["done", "error", "queued", "draft", "created"]]
        
        return {
            "is_running": self.is_batch_running,
            "queued_count": len(queued_projects),
            "processing_count": len(processing_projects),
            "queued_items": queued_projects[:10],  # ìƒìœ„ 10ê°œë§Œ
            "current_items": processing_projects
        }

    def add_to_queue(self, project_id: int):
        """í”„ë¡œì íŠ¸ë¥¼ ëŒ€ê¸°ì—´ì— ì¶”ê°€"""
        db.update_project(project_id, status="queued")

    def clear_queue(self):
        """ëŒ€ê¸°ì—´ ë¹„ìš°ê¸°"""
        projects = db.get_all_projects()
        for p in projects:
            if p.get("status") == "queued":
                db.update_project(p['id'], status="draft")

autopilot_service = AutoPilotService()

